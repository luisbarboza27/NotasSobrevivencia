<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Análisis de Sobrevivencia - 6&nbsp; Modelos de Regresión Paramétricos</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./references.html" rel="next">
<link href="./DRSP.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Modelos de Regresión Paramétricos</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Análisis de Sobrevivencia</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Introducción</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Preliminares.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Preliminares</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./estNP.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Estimación No-Paramétrica</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PH.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Pruebas de Hipótesis</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./RSP.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Regresión Semiparamétrica con Riesgos Proporcionales</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./DRSP.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Análisis de Diagnósticos en el Modelo de Cox</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./MRP.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Modelos de Regresión Paramétricos</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">Referencias</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#modelo-de-weibull" id="toc-modelo-de-weibull" class="nav-link active" data-scroll-target="#modelo-de-weibull"><span class="toc-section-number">6.1</span>  Modelo de Weibull</a></li>
  <li><a href="#modelo-log-logístico" id="toc-modelo-log-logístico" class="nav-link" data-scroll-target="#modelo-log-logístico"><span class="toc-section-number">6.2</span>  Modelo Log-logístico</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="MRP" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Modelos de Regresión Paramétricos</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>Los modelos paramétricos que se van a estudiar admiten dos representaciones:</p>
<p><strong>Modelos de tiempo acelerado de fallo</strong></p>
<p>Sea <span class="math inline">\(X\)</span>: tiempo al evento de riesgo y <span class="math inline">\(Z\)</span>: vector de covariables fijas. Un modelo de tiempo acelerado se define:</p>
<p><span class="math display">\[S(x|Z)=S_0[x\exp(\theta^TZ)]\]</span> donde <span class="math inline">\(S_0\)</span> es la función de sobrevivencia base y <span class="math inline">\(\theta\)</span> es un vector de parámetros. A <span class="math inline">\(\exp(\theta^TZ)\)</span> se le llama factor de aceleración.</p>
<p>Implicaciones (ejercicios):</p>
<ol type="1">
<li><p><span class="math inline">\(h(x|Z)=\exp(\theta^T)h_0[x\exp(\theta^TZ)]\)</span></p></li>
<li><p><span class="math inline">\(x_{0.5}|Z=\frac{x_{0.5}|(Z=0)}{\exp(\theta^TZ)}\)</span></p></li>
</ol>
<p><strong>Representación como modelo lineal en log-tiempo</strong></p>
<p><span class="math display">\[Y=\log X=\mu+\gamma^TZ+\sigma W\]</span> donde <span class="math inline">\(\gamma^T=(\gamma_1,\ldots,\gamma_p)\)</span> y <span class="math inline">\(W\)</span> es una variable aleatoria de error. <em>Nota</em>: las dos representaciones se relacionan, ya que si <span class="math inline">\(S_0(x)\)</span> es la función de sobrevivencia de <span class="math inline">\(\exp(\mu+\sigma W)\)</span> entonces las dos representaciones son equivalentes con <span class="math inline">\(\theta=-\gamma\)</span>.</p>
<section id="modelo-de-weibull" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="modelo-de-weibull"><span class="header-section-number">6.1</span> Modelo de Weibull</h2>
<p>Único modelo paramétrico que tiene una representación de riesgos proporcionales y de tiempo acelerado de fallo.</p>
<p><strong>Función de sobrevivencia</strong></p>
<p><span class="math display">\[S_X(x)=\exp(-\lambda x^\alpha)\]</span> <strong>Tasa de riesgo</strong></p>
<p><span class="math display">\[h_X(x)=\lambda \alpha x^{\alpha-1}\]</span> la cual puede ser monótona creciente/decreciente o constante dependiendo de <span class="math inline">\(\alpha\)</span>.</p>
<p>Si <span class="math inline">\(Y=\log X\)</span> entonces <span class="math inline">\(S_Y(y)=\exp(-\lambda e^{\alpha y})\)</span>. Sea <span class="math inline">\(\lambda=\exp(-\mu/\sigma)\)</span> y <span class="math inline">\(\sigma=1/\alpha\)</span> entonces <span class="math inline">\(Y\)</span> se puede escribir como un modelo log-lineal:</p>
<p><span class="math display">\[Y=\log X=\mu+\sigma W\]</span> donde <span class="math inline">\(W\sim \text{EVD estándar}\)</span> (Distribución de Valor Extremo):</p>
<p><span class="math display">\[f_W(w)=\exp(w-\exp(w))\]</span> y función de sobrevivencia:</p>
<p><span class="math display">\[S_W(w)=\exp(-\exp(w))\]</span> <em>Nota</em>: si <span class="math inline">\(\alpha=1\)</span> (<span class="math inline">\(\sigma=1\)</span>) entonces la distribución de Weibull se reduce a una distribución exponencial.</p>
<p>Asumiendo datos censurados por la derecha, la verosimilitud es:</p>
<span class="math display">\[\begin{align*}
    L&amp;=\prod_{j=1}^n[f_Y(y_j)]^{\delta_j}[S_Y(y_j)]^{1-\delta_j}\\
    &amp;=\prod_{j=1}^n \left[\frac{1}{\sigma}f_w\left(\frac{y_j-\mu}{\sigma}\right)\right]^{\delta_j}\left[S_W\left(\frac{y_j-\mu}{\sigma}\right)\right]^{1-\delta_j}
\end{align*}\]</span>
<p>y es función de <span class="math inline">\(\mu\)</span> y de <span class="math inline">\(\sigma\)</span>. Una vez que se estiman esos parámetros, se puede usar invarianza del MLE para calcular:</p>
<p><span class="math display">\[\hat \lambda=\exp(-\hat \mu/\hat \sigma)\quad \text{y} \quad \hat \alpha=1/\hat \sigma\]</span></p>
<p>y usando el método Delta (ver página 401, Klein)</p>
<span class="math display">\[\begin{align*}
    \text{Var}(\hat \lambda)&amp;=\exp(-2\hat \mu/\hat \sigma)\left[\text{Var}(\hat \mu)/\hat \sigma^2+\hat \mu^2\text{Var}(\hat \sigma)/\hat \sigma^4-2\frac{\hat \mu}{\hat \sigma^3}\text{Cov}(\hat \mu,\hat \sigma)\right]\\
    \text{Var}(\hat \alpha)&amp;=\frac{\text{Var}(\hat \sigma)}{\hat \sigma^4}\\
    \text{Cov}(\hat \lambda,\hat \alpha)&amp;=\exp(-\hat \mu/\hat \sigma)[\text{Cov}(\hat \mu,\hat \sigma)/\hat \sigma^3-\hat \mu\text{Var}(\hat \sigma)/\hat \sigma^4]
\end{align*}\]</span>
<p>Si queremos incorporar covariables al modelo Weibull se modifica el modelo log-lineal:</p>
<p><span class="math display">\[Y=\mu+\gamma^TZ+\sigma W\]</span> donde <span class="math inline">\(W\sim \text{EVD(estándar)}\)</span>. La tasa de riesgo satisface:</p>
<p><span class="math display">\[h(x|Z)=(\alpha\lambda x^{\alpha-1})\exp(\beta^TZ)\]</span> con <span class="math inline">\(\alpha=\frac 1 \sigma\)</span>, <span class="math inline">\(\lambda=\exp(-\mu/\sigma)\)</span> y <span class="math inline">\(\beta_j=-\frac{\gamma_j}{\sigma}\)</span> para <span class="math inline">\(j=1,\ldots,p\)</span> en donde se ve claramente que el supuesto de riesgos proporcionales es verdadero.</p>
<p>Además, si <span class="math inline">\(\theta=\beta/\alpha\)</span> (<span class="math inline">\(\theta=-\gamma\)</span>) la tasa de riesgo es:</p>
<p><span class="math display">\[h(x|Z)=\exp(\theta^TZ)h_0[x\exp(\theta^TZ)]\]</span> donde la tasa de riesgo base es:</p>
<p><span class="math display">\[h_0(x)=\lambda \alpha x^{\alpha-1}\]</span> (tasa de una Weibull) y el factor <span class="math inline">\(\exp(\theta^TZ)\)</span> es el factor de aceleración. Por lo tanto el modelo también satisface el supuesto de tiempo acelerado de fallo:</p>
<p><span class="math display">\[S(x|Z)=S_0(x\exp(\theta^TZ))\]</span> Si <span class="math inline">\(x_m^0\)</span> es la mediana para la distribución base:</p>
<p><span class="math display">\[S_0(x_m^0)=\frac 1 2\]</span> y si <span class="math inline">\(x_m^Z\)</span> es la mediana con <span class="math inline">\(Z=z\)</span> entonces:</p>
<p><span class="math display">\[\frac 1 2=S(x_m^Z|z)=S_0(x_m^Z\exp(\theta Z))\]</span> entonces: <span class="math inline">\(x_m^Z=\frac{x_m^0}{\exp(\theta Z)}\)</span></p>
<p><strong>Estimación</strong>: a través del MLE y usando invarianza sobre los estimadores del modelo log-lineal. El método delta permite calcular la covarianza entre los distintos parámetros <span class="math inline">\((\alpha,\lambda,\vec \beta)\)</span>.</p>
</section>
<section id="modelo-log-logístico" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="modelo-log-logístico"><span class="header-section-number">6.2</span> Modelo Log-logístico</h2>
<p><em>Ventaja</em>: tasa de riesgo que crece inicialmente y después decrece.</p>
<p><strong>Función de sobrevivencia</strong></p>
<p><span class="math display">\[S_X(x)=\frac{1}{1+\lambda x^\alpha}\]</span> <strong>Tasa de riesgo acumulada</strong></p>
<p><span class="math display">\[H_X(x)=\log(1+\lambda x^\alpha)\]</span> Tomando la transformación <span class="math inline">\(Y=\log X\)</span>:</p>
<p><span class="math display">\[S_Y(y)=\frac{1}{1+\lambda \exp(\alpha y)}\]</span> y se puede probar que:</p>
<p><span class="math display">\[Y=\log X=\mu+\sigma W\]</span> donde <span class="math inline">\(W\sim \text{logistica(Estándar)}\)</span>:</p>
<p><span class="math display">\[f_W(w)=\frac{e^w}{(1+e^w)^2},\qquad S_W(w)=\frac{1}{1+e^w}\]</span></p>
<p>y <span class="math inline">\(\alpha=\frac 1 \sigma\)</span>, <span class="math inline">\(\lambda=\exp(-\mu/\sigma)\)</span>, la cual es la misma reparametrización del caso Weibull.</p>
<p>Entonces aplican las mismas fórmulas de la <span class="math inline">\(\text{Cov}(\hat \lambda,\hat \alpha)\)</span> del caso Weibull (usando el método Delta).</p>
<p>Hay tres posibles formas de incorporar covariables en un modelo log-logístico:</p>
<p><strong>Modelo log-lineal</strong></p>
<p><span class="math display">\[Y=\log X = \mu+\gamma^TZ+\sigma W\]</span> donde <span class="math inline">\(W\sim \text{logistica(Estándar)}\)</span>.</p>
<p><strong>Sobrevivencia condicional:</strong></p>
<p><span class="math display">\[S_X(x|Z)=\frac{1}{1+\lambda\exp(\beta^TZ)x^\alpha}\]</span></p>
<p>que se relaciona con la primera forma de incorporar a través de la parametrización:</p>
<p><span class="math display">\[\beta=-\frac{\gamma}{\sigma},\qquad \lambda=\exp[-\mu/\sigma],\qquad \alpha=\frac 1  \sigma\]</span> donde de nuevo, si se tiene MLE’s para <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\gamma\)</span> y <span class="math inline">\(\sigma\)</span> entonces usando invarianza y el método Delta se puede hacer inferencia sobre <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span> y <span class="math inline">\(\lambda\)</span>.</p>
<p>Interpretación de <span class="math inline">\(\exp(\beta^TZ)\)</span>:</p>
<p><span class="math display">\[\frac{S_X(x|Z)}{1-S_X(x|Z)}=\frac{1}{\lambda\exp(\beta^TZ)x^\alpha}=\exp(-\beta^TZ)\frac{S_X(x|Z=0)}{1-S_X(x|Z=0)}\]</span> entonces:</p>
<p><span class="math display">\[\exp(-\beta^TZ)=\frac{\text{Odds}(Z=z)}{\text{Odds}(Z=0)}\]</span> <strong>Modelo de tiempo acelerado de fallo</strong></p>
<p><span class="math display">\[S(x|Z)=S_0[\exp(\theta^TZ)x]\]</span> donde <span class="math inline">\(S_0(x)=\frac{1}{1+\lambda x^\alpha}\)</span>.</p>
<!-- ## Otros modelos paramétricos -->
<!-- **Modelo lognormal** -->
<!-- Si $Z=(Z_1,\ldots,Z_p)^T$ entonces: -->
<!-- $$Y=\log X=\mu+\gamma^TZ+\sigma W$$ donde $W\sim N(0,1)$. -->
<!-- *Nota*: resultados muy parecidos a los del modelo log-logístico. En este -->
<!-- caso: -->
<!-- $$S(x)=1-\Phi\left\{\frac{\log x-(\mu+\gamma^TZ)}{\sigma}\right\}$$ -->
<!-- ($\Phi$: cdf de una $N(0,1)$) -->
<!-- **Modelo con gamma generalizada** -->
<!-- Incluye Weibull, exponencial y lognormal: -->
<!-- $$Y=\log X=\mu+\gamma^TZ+\sigma W$$ donde $W\sim f(w)$ y: -->
<!-- $$f(w)=\frac{|\theta|[\exp(\theta w)/\theta^2]^{1/\theta^2}\exp[-\exp(\theta w)/\theta^2]}{\Gamma(1/\theta^2)}$$ -->
<!-- Si $\theta=1$ (Weibull), si $\theta=0$ (log-normal) y $\theta=\sigma=1$ -->
<!-- (exponencial). -->
<!-- Métodos de selección de modelos: -->
<!-- -   AIC -->
<!-- -   BIC -->
<!-- -   LRT (caso de modelos anidados). -->
<!-- ## Análisis de diagnósticos -->
<!-- Para verificar la bondad de ajuste de un modelo paramétrico se puede -->
<!-- graficar transformaciones de $\hat H(x)$ (usando el estimador de -->
<!-- Nelson-Aalen) versus transformaciones de $x$. Por ejemplo para el caso -->
<!-- log-logístico: -->
<!-- ```{=tex} -->
<!-- \begin{align*} -->
<!--     H(x)&=\log[1+\lambda x^\alpha]\\ -->
<!--     \Longrightarrow \log[\exp(H(x))-1]&=\log \lambda+\alpha \log x -->
<!-- \end{align*} -->
<!-- ``` -->
<!-- Por lo tanto, asumiendo un modelo log-logístico: -->
<!-- ```{r, echo=FALSE, out.width='70%', fig.align='center', fig.cap='Bondad de Ajuste'} -->
<!-- knitr::include_graphics("images/BAjusteparam.png") -->
<!-- ``` -->
<!-- En el caso exponencial: -->
<!-- $$H(x)=\lambda x$$ y por lo tanto el gráfico sugerido es $\hat H$ vs -->
<!-- $x$. -->
<!-- En el caso Weibull: -->
<!-- $$H(x)=\lambda x^\alpha$$ entonces -->
<!-- $\log \hat H(x)=\log \lambda+\alpha \log x$. El gráfico sugerido sería -->
<!-- $\log \hat H(x)$ vs $\log x$. -->
<!-- En el caso log-normal: -->
<!-- $$H(x)=-\log\left[1-\Phi\left[\frac{\log x-\mu}{\sigma}\right]\right]$$ -->
<!-- entonces $\frac{1}{\sigma}(\log x-\mu)=\Phi^{-1}(1-\exp(-H(x)))$. El -->
<!-- gráfico sugerido en este caso es: -->
<!-- $$\Phi^{-1}(1-\exp(-\hat H(x)))\quad \text{vs} \quad \log x$$ Si -->
<!-- queremos comparar 2 grupos a través de un modelo de tiempo acelerado de -->
<!-- fallo, se puede verificar la bondad de ajuste de este modelo usando el -->
<!-- hecho de que: -->
<!-- $$S_1(x):=S(x|Z=1)=S_0(x\exp(\beta^T\cdot 1))=S_0(\theta x)$$ donde -->
<!-- $\theta$ es el factor de aceleración. -->
<!-- Sea $t_{0p}$ y $t_{1p}$ los p-cuantiles de los grupos 0 y 1 -->
<!-- respectivamente, es decir: -->
<!-- $$t_{kp}=S_k^{-1}(1-p),\qquad k=0,1$$ entonces: -->
<!-- $$S_0(t_{0p})=1-p=S_1(t_{1p})=S_0(\theta t_{1p})$$ Por lo tanto, bajo el -->
<!-- supuesto de tiempo acelerado: -->
<!-- $$t_{0p}=\theta t_{1p}$$ **Herramienta gráfica**: -->
<!-- -   Calcule los estimadores de Kaplan-Meier para cada grupo. -->
<!-- -   Calcule estimadores de $t_{0p}$ y $t_{1p}$ para varios valores de -->
<!--     $p$. -->
<!-- -   Grafique $\hat t_{1p}$ vs $\hat t_{0p}$. La pendiente del gráfico -->
<!--     estima el factor de aceleración y la linealidad por el origen ocurre -->
<!--     bajo el supuesto de tiempo acelerado de fallo. -->
<!-- ### Residuos de Cox-Snell -->
<!-- Mismo principio que en la regresión de Cox: bajo el supuesto de bondad -->
<!-- de ajuste $\{r_j\}\sim \text{Exp}(1)$ donde $r_j=\hat H(T_j|Z_j)$. La -->
<!-- herramienta gráfica es la misma que en el caso de la regresión de Cox: -->
<!-- estimador de Nelson-Aalen $\hat H(r_j)$ versus $r_j$. Los residuos para -->
<!-- cada caso son: -->
<!-- -   Exponencial: -->
<!-- $$r_i=\hat \lambda t_i\exp\left[\hat \beta^TZ_i\right]$$ - Weibull: -->
<!-- $$r_i=\hat \lambda t_i^{\alpha}\exp\left[\hat \beta^TZ_i\right]$$ - -->
<!-- Log-logística: -->
<!-- $$r_i=\log\left[\frac{1}{1+\hat \lambda t_i^{\alpha}\exp\left[\hat \beta^TZ_i\right]}\right]$$ -->
<!-- -   Log-normal: -->
<!-- $$r_i=\log\left[1-\Phi\left(\frac{\log T_i-\hat \mu-\hat \gamma^TZ_i}{\hat \sigma}\right)\right]$$ -->
<!-- *Nota*: el análisis de residuos de Cox-Snell es equivalente a analizar -->
<!-- residuos estandarizados: -->
<!-- $$s_j=\frac{\log T_j-\hat \mu-\hat \gamma^TZ_j}{\hat \sigma}$$ a través -->
<!-- de la comparación de su distribución empírica con respecto a la -->
<!-- distribución de $W$. (Usando un qqplot, por ejemplo) -->
<!-- El uso de residuos martingala o de devianza es análogo al uso que le -->
<!-- dimos en modelos de Cox. -->
<!-- ## Análisis Multivariado de Sobrevivencia -->
<!-- *Problema*: en los modelos anteriores se asume que los tiempos de -->
<!-- sobrevivencia de distintos individuos son independientes. Este es un -->
<!-- supuesto poco realista, ya que por ejemplo el riesgo de un grupo no -->
<!-- necesariamente representa la suma de los riesgos individuales e -->
<!-- independientes. -->
<!-- *Solución*: modelar la asociación entre tiempos de sobrevivencia entre -->
<!-- distintos grupos. -->
<!-- **Modelo de Fragilidad** -->
<!-- Definición de fragilidad o debilidad en riesgo: efecto aleatorio no -->
<!-- observable que es compartido por los sujetos de un subgrupo. -->
<!-- Los grupos con mayor debilidad experimentan el evento antes que otros -->
<!-- grupos con menor debilidad. Otra ventaja que presentan los modelos con -->
<!-- fragilidad es que permiten mejorar el ajuste ante la presencia de -->
<!-- sobredispersión en los datos, debido a errores no contabilizados en el -->
<!-- modelo. -->
<!-- **Modelo de Fragilidad Compartida** -->
<!-- Se asume que la tasa de riesgo para el $j$-ésimo individuo en el grupo -->
<!-- $i$-ésimo tiene la forma: -->
<!-- $$h_{ij}(t)=h_0(t)\exp[\beta^TZ_{ij}+\sigma w_i]$$ donde $i=1,\ldots,G$, -->
<!-- $j=1,\ldots,n_i$, bajo la notación usual y asumiendo que -->
<!-- $w_1,\ldots,w_G$ son las fragilidades, es decir $\{w_i\}$ son variables -->
<!-- aleatorias independientes e identicamente distribuidas con media 0 y -->
<!-- varianza 1. Algunas veces es más conveniente escribir el modelo: -->
<!-- $$h_{ij}(t)=h_0(t)u_i\exp[\beta^TZ_{ij}]$$ con $u_i$ variables -->
<!-- aleatorias independientes, $E[u_i]=1$, $\text{Var}(u_i)<\infty$. -->
<!-- -   Si $u_i>1$, entonces el grupo $i$-ésimo es de más riesgo que en el -->
<!--     caso de riesgos proporcionales. -->
<!-- -   Si $u_i<1$, entonces el grupo $i$-ésimo es de menos riesgo que en el -->
<!--     caso de riesgos proporcionales. -->
<!-- Consecuencia: como $w_i$ no son variables observables entonces: -->
<!-- ```{=tex} -->
<!-- \begin{align*} -->
<!-- S(x_{i1},\ldots,x_{in_i})&=P[X_{i1}>1,\ldots,X_{in_i}>x_{in_i}]\\ -->
<!-- &=E\left[\exp\left(-\sum_{j=1}^{n_i}H_{ij}(X_{ij})\right)\right]\\ -->
<!-- &=LP\left[\sum_{j=1}^{n_i}H_0(x_{ij})\exp(\beta^TZ_{ij})\right] -->
<!-- \end{align*} -->
<!-- ``` -->
<!-- donde $LP(v)=E_v[\exp(-Uv)]$ (transformada de Laplace de la fragilidad -->
<!-- U) -->
<!-- Posibles escogencias para U: -->
<!-- -   Distribución gamma univariada. -->
<!-- -   Distribución normal inversa. -->
<!-- -   Distribución log-normal. -->

<!-- -   Distribución estable positiva. -->
<!-- -   Distribución Uniforme -->
<!-- -   ... -->
<!-- **Prueba Score de Asociación** -->
<!-- Objetivo: Probar la hipótesis nula de no fragilidad ($\sigma=0$) -->
<!-- Herramienta metodológica: Prueba de Commenges y Andersen (1995) -->
<!-- *Caso particular*: ($G=n$, $n_i=1$) se busca probar la existencia de -->
<!-- sobredispersión en el modelo. -->
<!-- Se busca probar la hipótesis nula: -->
<!-- $$H_0: \sigma=0 \qquad \text{vs}\qquad H_1: \sigma\neq 0$$ Usamos la -->
<!-- notación ya definida, para $i=1,\ldots,G$ y $j=1,\ldots,n_i$: -->
<!-- -   $T_{ij}$: tiempo -->
<!-- -   $\delta_{ij}$: indicador de riesgo -->
<!-- -   $Z_{ij}$: covariable -->
<!-- -   $Y_{ij}(t)$: indicadora de exposición al riesgo al tiempo $t$. -->
<!-- Se ajusta el modelo de Cox con riesgos proporcionales: -->
<!-- $$h(t|Z_{ij})=h_0(t)\exp[\beta^TZ_{ij}]$$ y se obtiene $b$: estimador de -->
<!-- verosimilitud parcial y $\hat H_0(t)$: estimador de Breslow. -->
<!-- Sea: -->
<!-- $$S^{(0)}(t)=\sum_{i=1}^G\sum_{j=1}^{n_i}Y_{ij}(t)\exp[b^TZ_{ij}]$$ y -->
<!-- $$M_{ij}=\delta_{ij}-\hat H_0(t)\exp[b^TZ_{ij}]$$ es el residuo -->
<!-- martingala para el individuo $ij$. Calculamos el siguiente estadístico\* -->
<!-- score: -->
<!-- ```{=tex} -->
<!-- \begin{align*} -->
<!-- T&=\sum_{i=1}^G\left[\sum_{j=1}^{n_i}M_{ij}\right]^2-D+C\\ -->
<!-- &=\sum_{i=1}^G \sum_{j=1}^{n_i}\sum_{\underset{k\neq j}{k=1}}^{n_j}M_{ij}M_{ik}+\left(\sum_{i=1}^G \sum_{j=1}^{n_i}M_{ij}^2-N\right)+C -->
<!-- \end{align*} -->
<!-- ``` -->
<!-- donde: -->
<!-- -   $D$: número total de ocurrencias del riesgo. -->
<!-- -   $N$: tamaño de muestra total. -->
<!-- -   El primer término en la última expresión corresponde a las -->
<!--     correlaciones entre individuos para cada grupo. -->
<!-- -   El segundo término es una medida de sobredispersión. -->
<!-- -   $C$ es un factor de corrección que tiende a 0 conforme -->
<!--     $N\longrightarrow 0$: -->
<!-- $$C=\sum_{i=1}^n\sum_{j=1}^{n_i}\frac{\delta_{ij}}{S^{(0)}(T_{ij})^2}\sum_{b=1}^G\left[\sum_{k=1}^{n_i}Y_{bk}(T_{ij})\exp[b^TZ_{bk}]\right]^2$$ -->
<!-- La varianza de $T$ se calcula usando la matriz de información de Fisher -->
<!-- (de $b$) y residuos martingala $M_{ij}$ (ver fórmula 13.2.9 del Klein). -->
<!-- Bajo la hipótesis nula de no asociación: -->
<!-- $$\frac{T}{V^{1/2}}\underset{n \text{ grande}}{\longrightarrow}N(0,1)$$ -->
<!-- ## Estimación de un modelo de fragilidad gamma -->
<!-- Asuma que la tasa de riesgo para el individuo $i$ del grupo $j$ es: -->
<!-- $$h_{ij}(t)=h_0(t)u_i\exp[\beta^TZ_{ij}]$$ donde $i=1,\ldots,G$, -->
<!-- $j=1,\ldots,n_i$ y $u_i\overset{iid}{\sim}\Gamma(1/\theta,\theta)$. Note -->
<!-- que la función de densidad de $u_i$ es: -->
<!-- $$g(u)=\frac{u^{1/\theta-1}\exp(-u/\theta)}{\Gamma(1/\theta)\theta^{1/\theta}}$$ -->
<!-- Note que $E[U]=1$ y $\text{Var}(U)=\theta$ (Valores grandes de $\theta$ -->
<!-- reflejan mayor heterogeneidad entre grupos y una asociación más alta -->
<!-- dentro de cada grupo). -->
<!-- Distribución conjunta de los $n_i$ individuos (para el grupo $i$-ésimo) -->
<!-- ```{=tex} -->
<!-- \begin{align*} -->
<!--     S[x_{i1},\ldots,x_{in_i}]&=P[X_{i1}>x_{i1},\ldots,X_{in_i}>x_{in_i}]\\ -->
<!--     &=\left[1+\theta \sum_{j=1}^{n_i}H_0(x_{ij})\exp[\beta^TZ_{ij}]\right]^{-1/\theta} -->
<!-- \end{align*} -->
<!-- ``` -->
<!-- Usando los datos $(T_{ij},Z_{ij},\delta_{ij})$ para $i=1,\ldots,G$ y -->
<!-- $j=1,\ldots,n_i$ se puede calcular la verosimilitud como: -->
<!-- $$L(\theta,\beta)=L_1(\theta)+L_2(\beta,H_0)$$ donde -->
<!-- $$L_1(\theta)=-G\left[\frac{\log \theta}{\theta}+\log \Gamma(1/\theta)\right]+\sum_{i=1}^G[1/\theta+D_i-1]\log u_i-\frac{u_i}{\theta}$$ -->
<!-- y -->
<!-- $$L_2(\beta,H_0)=\sum_{i=1}^G\sum_{j=1}^{n_i} \delta_{ij}[\beta^TZ_{ij}+\log h_0(T_{ij})]-u_iH_0(T_{ij})\exp[\beta^TZ_{ij}]$$ -->
<!-- 2 posibles soluciones: -->
<!-- -   Maximizar $L(\theta,\beta)$ asumiendo una forma paramétrica para -->
<!--     $h_0(t)$. -->
<!-- -   Maximizar $L(\theta,\beta)$ asumiendo un modelo semiparamétrico para -->
<!--     $h(t)$. -->
<!-- Solución: Algoritmo EM (Esperanza-Maximización) en el segundo caso (ver -->
<!-- pags. 432-435 del Klein) -->
<!-- ## Modelo Marginal de sobrevivencia multivariada -->
<!-- Inconveniente del modelo de fragilidad: las distribuciones marginales no -->
<!-- siguen la estructura de un modelo de Cox (no se satisface el principio -->
<!-- de riesgos proporcionales) -->
<!-- *Modelo de Lee et al (1992):* -->
<!-- Para cada individuo se asume un modelo de Cox condicional en $Z_{ij}$: -->
<!-- $$h_{ij}(t|Z_{ij})=h_0(t)\exp[\beta^TZ_{ij}]$$ y se construye la -->
<!-- verosimilitud parcial asumiendo que todas las observaciones son -->
<!-- independientes (modelo independiente de trabajo) -->
<!-- A partir del estimador de $\beta$ obtenido con la verosimilitud anterior -->
<!-- se ajusta la matriz de covarianza de $b$ con los residuos score (ver -->
<!-- ecuaciones 13.4.2 y 13.4.3 del Klein) para tomar en cuenta la relación -->
<!-- de observaciones en cada grupo. -->
<!-- Además, si $\hat V$ es la matriz de varianza ajustada: -->
<!-- $$b\underset{n\text{ grande}}{\longrightarrow} N_p(\beta,\hat V)$$ -->
<!-- ## Laboratorio -->
<!-- ### Modelos Paramétricos -->
<!-- En este ejemplo usamos como base los datos de 90 hombres diagnosticados -->
<!-- con cáncer de laringe con su edad de diagnóstico (age), tiempo de muerte -->
<!-- o censura en meses (time), indicador de censura (delta) y etapa de la -->
<!-- enfermedad (stage). Carga de datos: -->
<!-- ```{r} -->
<!-- library(survival) -->
<!-- library(KMsurv) -->
<!-- library(survMisc) -->
<!-- library(survminer) -->
<!-- library(tidyverse) -->
<!-- data(larynx) -->
<!-- head(larynx) -->
<!-- ``` -->
<!-- Preliminarmente, se puede verificar la capacidad de un modelo bajo el -->
<!-- supuesto de Weibull: -->
<!-- ```{r} -->
<!-- NA_prelim <- coxph(Surv(time,delta)~1,data = larynx,ties = 'breslow') -->
<!-- hatH0_prelim <- basehaz(NA_prelim,centered = FALSE) -->
<!-- hatH0_prelim <- hatH0_prelim %>% mutate(logtime=log(time),logH=log(hazard)) -->
<!-- ggplot(data = hatH0_prelim,mapping = aes(x = logtime,y = logH))+ -->
<!--   geom_point()+ -->
<!--   geom_smooth(method = 'lm')+ -->
<!--   theme_bw() -->
<!-- summary(lm(logtime~logH,data = hatH0_prelim)) -->
<!-- ``` -->
<!-- Se ajusta un modelo de Weibull donde las covariables son los estadíos de -->
<!-- la enfermedad *stage* y la edad del paciente *age*. -->
<!-- ```{r} -->
<!-- larynx <- larynx %>% mutate(stage=factor(stage)) -->
<!-- modelo1 <- survreg(Surv(time,delta)~stage+age,data = larynx,dist = 'weibull') -->
<!-- summary(modelo1) -->
<!-- ``` -->
<!-- Si queremos calcular el riesgo relativo de un paciente en etapa 4 -->
<!-- comparado con uno en etapa 1 tenemos que usar la reparametrización del -->
<!-- modelo de Weibull como modelo de riesgos proporcionales: -->
<!-- ```{r} -->
<!-- alpha <- 1/modelo1$scale -->
<!-- lambda <- exp(-coefficients(modelo1)[1]/modelo1$scale) -->
<!-- betas <- -coefficients(modelo1)[-1]/modelo1$scale -->
<!-- c(alpha,lambda,betas) -->
<!-- exp(betas[3]) -->
<!-- ``` -->
<!-- por lo tanto el riesgo relativo de un paciente en el cuarto estadío es -->
<!-- casi seis veces mayor que uno en estadío 1. El factor de aceleración de -->
<!-- un paciente en etapa 4 sería: -->
<!-- ```{r} -->
<!-- exp(-coefficients(modelo1)[4]) -->
<!-- ``` -->
<!-- por lo tanto el tiempo mediano de sobrevivencia para un paciente en -->
<!-- estadío 1 es 4.68 veces mayor que el de un paciente en estadío 4. -->
<!-- Ahora ajustamos un modelo log-logístico a las mismas covariables: -->
<!-- ```{r} -->
<!-- modelo1_ll <- survreg(Surv(time,delta)~stage+age,data = larynx,dist = 'loglogistic') -->
<!-- summary(modelo1_ll) -->
<!-- ``` -->
<!-- con sus parámetros en representación de riesgos proporcionales: -->
<!-- ```{r} -->
<!-- alpha <- 1/modelo1_ll$scale -->
<!-- lambda <- exp(-coefficients(modelo1_ll)[1]/modelo1_ll$scale) -->
<!-- betas <- -coefficients(modelo1_ll)[-1]/modelo1_ll$scale -->
<!-- c(alpha,lambda,betas) -->
<!-- ``` -->
<!-- En este caso podemos hacer comparaciones en términos de odds relativos -->
<!-- (oportunidad relativa). Los odds relativos de sobrevivencia de un -->
<!-- paciente en estadío 3 con respecto a uno de estadío 1 es: -->
<!-- ```{r} -->
<!-- exp(-betas[2]) -->
<!-- ``` -->
<!-- es decir un paciente en estadío 3 tiene aproximadamente 70% menos -->
<!-- posibilidades de sobrevivir que uno en estadío 1. -->
<!-- Ahora comparamos el ajuste bajo cinco modelos: Exponencial, Weibull, -->
<!-- Log-logístico, Log-Normal y Gamma Generalizada: -->
<!-- ```{r} -->
<!-- library(flexsurv) -->
<!-- modelo_exp <- survreg(Surv(time,delta)~stage+age,data = larynx,dist = 'exponential',x = T) -->
<!-- modelo_weibull <- survreg(Surv(time,delta)~stage+age,data = larynx,dist = 'weibull') -->
<!-- modelo_loglog <- survreg(Surv(time,delta)~stage+age,data = larynx,dist = 'loglogistic') -->
<!-- modelo_lognor <- survreg(Surv(time,delta)~stage+age,data = larynx,dist = 'lognormal') -->
<!-- modelo_gg <- flexsurvreg(Surv(time,delta)~stage+age,data = larynx,dist = 'gengamma') -->

<!-- AIC_table <- data.frame(Modelos=c('Exponencial','Weibull','Log-logistico','Log-Normal','GammaGen'),AIC=c(AIC(modelo_exp),AIC(modelo_weibull),AIC(modelo_loglog),AIC(modelo_lognor),AIC(modelo_gg))) -->
<!-- BIC_table <- data.frame(Modelos=c('Exponencial','Weibull','Log-logistico','Log-Normal','GammaGen'),BIC=c(BIC(modelo_exp),BIC(modelo_weibull),BIC(modelo_loglog),BIC(modelo_lognor),BIC(modelo_gg))) -->
<!-- AIC_table -->
<!-- BIC_table -->
<!-- ``` -->
<!-- por lo tanto el modelo con el mejor ajuste es el Exponencial. Ahora -->
<!-- analizamos la bondad de ajuste de cada uno de los modelos anteriores -->
<!-- usando los residuos de Cox-Snell: -->
<!-- ```{r} -->
<!-- lambda <- exp(-coefficients(modelo_exp)[1]/modelo_exp$scale) -->
<!-- betas <- as.matrix(-coefficients(modelo_exp)[-1]/modelo_exp$scale) -->
<!-- rCox <- lambda*larynx$time*exp(t(betas)%*%t(modelo_exp$x[,-1])) -->
<!-- larynx$rCox <- t(rCox) -->
<!-- modelo_exp_CoxSnell <- coxph(Surv(rCox,delta)~1,data = larynx,ties = 'breslow') -->
<!-- H0_modelo_exp_CS <- basehaz(modelo_exp_CoxSnell,centered = FALSE) -->
<!-- plot(H0_modelo_exp_CS$time,H0_modelo_exp_CS$hazard) -->
<!-- abline(a = 0,b=1) -->
<!-- ``` -->

<!-- en donde podemos ver que el ajuste es bastante aceptable. También -->
<!-- analizamos un gráfico de los residuos de devianza vs el tiempo de -->
<!-- ocurrencia del evento: -->
<!-- ```{r} -->
<!-- rDev <- residuals(modelo_exp,type = 'deviance') -->
<!-- plot(larynx$time,rDev) -->
<!-- abline(h=c(-2,2),col=2) -->
<!-- ``` -->
<!-- Note que hay unos cuantas observaciones que tienen residuos absolutos -->
<!-- ligeramente mayores a dos, estas observaciones son: -->
<!-- ```{r} -->
<!-- mayores_dev <- larynx %>% mutate(rDev=rDev)%>% arrange(rDev) -->
<!-- mayores_dev[1:3,] -->
<!-- ``` -->
<!-- En estos casos pareciera que los pacientes fallecieron de forma muy -->
<!-- temprana a distintas edades y en distintos estadíos de la enfermedad, -->
<!-- por lo que se pueden considerar puntos extremos en la muestra. -->
<!-- ### Modelos de fragilidad -->
<!-- El siguiente ejemplo consiste en un experimento realizado sobre 50 -->
<!-- camadas de ratas (Litter) en donde una rata se tomó al azar y se le -->
<!-- aplicó una droga y a otras dos se les dió un un placebo con el fin de -->
<!-- analizar el tiempo hasta la aparición de un tumor. Carga de datos: -->
<!-- ```{r} -->
<!-- ratas <- read_csv('./data/rats.csv') -->
<!-- head(ratas) -->
<!-- ``` -->
<!-- Primero vamos a medir la posible asociación entre la camada *Litter* y -->
<!-- el tiempo hasta la aparición del tumor (puede deberse a similitudes -->
<!-- genéticas). Además ajustamos un modelo con una fragilidad en la variable -->
<!-- *Litter* para verificar si hay una asociación en el comportamiento de la -->
<!-- sobrevivencia en una camada a través de la significancia del componente -->
<!-- aleatorio: -->
<!-- ```{r} -->
<!-- library(frailtyEM) -->
<!-- modelo_fragil_EM <- emfrail(Surv(time,Delta)~Group+cluster(Litter),data = ratas) -->
<!-- summary(modelo_fragil_EM) -->
<!-- ``` -->
<!-- Note que no hay evidencia de que haya una asociación entre la camada y -->
<!-- el tiempo al desarrollo de un tumor según la prueba de -->
<!-- Commenges-Andersen. Según el LRT el modelo es significativo con niveles -->
<!-- de confianza inferiores al 89% aproximadamente, lo cual puede ser que no -->
<!-- sea aplicable en este caso ya que el tamaño de muestra es de 150 -->
<!-- individuos. El término de fragilidad tiene una varianza estimada de -->
<!-- 0.472 pero este no es significativo al 95% ya que el intervalo de -->
<!-- confianza de Var(Z) incluye al 0. El intervalo de confianza del tau de -->
<!-- Kendall también incluye al 0 lo cual confirma el resultado obtenido en -->
<!-- la prueba de asociación. -->
<!-- Ahora ajustamos un modelo de sobrevivencia marginal en donde se use -->
<!-- "working independence" para ajustar la varianza de los estimadores. Para -->
<!-- eso usamos *coxph* y *cluster*: -->
<!-- ```{r} -->
<!-- modelo_marginal <- coxph(Surv(time,Delta)~Group,data = ratas,cluster = Litter) -->
<!-- summary(modelo_marginal) -->
<!-- ``` -->
<!-- Note que el error estándar ajustado del único coeficiente es 0.3024. El -->
<!-- resultado anterior lo comparamos con un modelo de Cox sin agrupar: -->
<!-- ```{r} -->
<!-- modelo_nagrupado <- coxph(Surv(time,Delta)~Group,data = ratas) -->
<!-- summary(modelo_nagrupado) -->
<!-- ``` -->
<!-- en donde podemos también comparar los intervalos de confianza del riesgo -->
<!-- relativo del grupo tratamiento sobre el placebo. En el caso del modelo -->
<!-- Cox estándar, este intervalo es (1.326, 4.604) y en el caso del modelo -->
<!-- marginal la variabilidad es menor: (1.366, 4.47). -->


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./DRSP.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Análisis de Diagnósticos en el Modelo de Cox</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./references.html" class="pagination-link">
        <span class="nav-page-text">Referencias</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>