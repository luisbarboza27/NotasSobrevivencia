[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Análisis de Sobrevivencia",
    "section": "",
    "text": "Introducción\nEstas notas de clase corresponden al material teórico y práctico del curso Análisis de Sobrevivencia (Modelos de Vida) (CA0503) durante el I-2023."
  },
  {
    "objectID": "Preliminares.html#características-de-x",
    "href": "Preliminares.html#características-de-x",
    "title": "1  Preliminares",
    "section": "1.1 Características de \\(X\\):",
    "text": "1.1 Características de \\(X\\):\nA continuación explicamos cada característica:\n\n1.1.1 Función de Sobrevivencia\n\nDefinition 1.1 (Función de sobrevivencia) \\[S(x)=P(X>x)\\]\n\nEn un contexto de tiempo de vida de aparatos o máquinas, a la función \\(S(x)\\) también se le llama función de utilidad o fiabilidad.\nNote que si \\(X\\) es una variable aleatoria continua entonces \\(S(x)\\) es una función monótona decreciente. Además, si \\(f\\) es la función de densidad de \\(X\\):\n\\[S(x)=1-F(x)=\\int_x^{\\infty} f(t)dt\\] y por lo tanto: \\[f(x)=-\\frac{dS(x)}{dx}\\]\n\n\n\n\n\n\nEjemplo: Distribución Weibull\n\n\n\nEn este caso \\(S(x)=\\exp(-\\lambda x^{\\alpha})\\), para \\(\\lambda>0\\) y \\(\\alpha>0\\).\nNote que si \\(\\alpha=1\\) entonces \\(X\\sim \\text{Exponencial}(\\lambda)\\).\n\n\nA continuación se ilustra \\(S(x)\\) cuando \\(\\lambda=\\alpha=2\\):\n\nSWeibull <- function(x,lambda,alpha){\n  exp(-lambda*x^(alpha))\n}\n\nggplot()+\n  xlim(0,3)+\n  geom_function(fun = SWeibull,args= list(lambda = 2, alpha = 2))+\n  ylab('S')+\n  theme_bw()\n\n\n\n\nEn términos generales \\(S(0)=1\\) y \\(S(\\infty)=0\\), para cualquier función de sobrevivencia \\(S\\). Además, es importante recalcar que una tabla de vida o una tabla de decrementos en general es un estimador de \\(S\\) bajo un cierto conjunto de datos observados.\nNote que en el caso discreto: \\[S(x)=\\sum_{x_j>x}p(x_j)\\]\ndonde \\(p(x_j)\\) es la función de masa evaluada en \\(x_j\\).\n\n\n1.1.2 Función o Tasa de Riesgo\nEsta función se conoce en otros contextos con otros nombres:\n\nTasa de fallo condicional (aparatos electrónicos, ingeniería)\nFuerza de mortalidad (demografía)\nTasa de fallo específica por edad (epidemiología)\nHazard (en inglés)\n\n\nDefinition 1.2 (Función de riesgo) \\[h(x)=\\lim_{\\Delta x\\rightarrow 0}\\frac{P[x\\leq X < x+\\Delta x|X\\geq x]}{\\Delta x}\\]\n\nEn el caso en que \\(X\\) es una variable aleatoria continua: \\[\\begin{align*}\nh(x)&=\\lim_{\\Delta x\\rightarrow 0}\\frac{F(x+\\Delta x)-F(x)}{\\Delta x}\\cdot \\frac{1}{S(x)}\\\\\n&=\\frac{f(x)}{S(x)}=-\\frac{d}{dx}\\log (S(x))\n\\end{align*}\\]\nSi la función de riesgo se acumula en el intervalo \\([0,x]\\), se obtiene la función de riesgo acumulativo:\n\\[\\begin{align*}\nH(x)=\\int_0^xh(u)du&=-\\int_0^x \\frac{d}{du}\\log(S(u))du\\\\\n&=-\\log(S(x)).\n\\end{align*}\\]\nEntonces: \\[\nS(x)=\\exp[-H(x)]=\\exp\\left[-\\int_0^th(u)du\\right]\n\\tag{1.1}\\]\nen donde a la expresión \\(h(u)du\\) dentro de la integral se le llama probabilidad instantánea del riesgo.\nLa función de riesgo \\(h(x)\\) necesita ser solamente positiva para asegurar de que la función de sobrevivencia esté bien definida. Por lo tanto no hay muchas restricciones en la forma que tiene la función de riesgo en \\((0,\\infty)\\). Por ejemplo la función de riesgo es monótona creciente en la mayoría de situaciones en donde hay desgaste en las condiciones de existencia en seres o aparatos. También puede ser monótona decreciente en situaciones en donde el riesgo del evento disminuye conforme pasa el tiempo, por ejemplo en el caso de la mortalidad infantil. También se puede tener funciones de riesgo combinadas al tener episodios de riesgo creciente y después de un evento el riesgo disminuye hasta un cierto valor, por ejemplo cuando un paciente es intervenido en un momento de riesgo máximo y después se recupera disminuyendo su riesgo hasta un valor esperable.\n\n\n\n\n\n\nEjemplo: Distribución Weibull\n\n\n\nEn este caso la función de densidad es: \\[f(x)=-\\frac{dS(x)}{dx}=\\lambda \\alpha x^{\\alpha-1}\\exp(-\\lambda x^{\\alpha})\\] entonces: \\[h(x)= \\lambda \\alpha x^{\\alpha-1}\\] Note que si \\(\\alpha=1\\) entonces \\(h(x)=h\\alpha\\), si \\(\\alpha>1\\) la función de riesgo es creciente y si \\(\\alpha<1\\) es decreciente.\n\n\nEn el caso en que \\(\\alpha=\\lambda=2\\)\n\nhWeibull <- function(x,lambda,alpha){\n  lambda*alpha*x^(alpha-1)\n}\n\nggplot()+\n  xlim(0,3)+\n  geom_function(fun = hWeibull,args= list(lambda = 2, alpha = 2))+\n  ylab('h')+\n  theme_bw()\n\n\n\n\nPara otro caso, ver ejemplo 2.2 del (Klein and Moeschberger 2003).\nEn el caso en que \\(X\\) es una variable aleatoria discreta: \\[h(x_j)=P[X=x_j|X\\geq x_j]=\\frac{p(x_j)}{S(x_{j-1})}\\] para \\(j=1,2,\\ldots\\) y donde \\(S(x_0)=1\\). Como \\(p(x_j)=S(x_{j-1})-S(x_j)\\) entonces: \\[h(x_j)=1-\\frac{S(x_j)}{S(x_{j-1})}\\]\nAdemás:\n\\[\\begin{align*}\nS(x)&=\\prod_{x_j\\leq x}\\frac{S(x_j)}{S(x_{j-1})}\\\\\n&=\\prod_{x_j\\leq x}[1-h(x_j)]\n\\end{align*}\\]\n\n\n\n\n\n\nEjemplo: Distribución Discreta\n\n\n\nSi \\(p(x_j)=\\frac 1 3\\) para \\(j=1,2,3\\) entonces: \\[S(x)=P(X>x)=\n  \\begin{cases}\n  1 & 0\\leq x <1\\\\\n  2/3 & 1\\leq x <2 \\\\\n  1/3 & 2\\leq x <3 \\\\\n  0 & x\\geq 3\n  \\end{cases}\n\\]\ny \\[h(x)=\n    \\begin{cases}\n  1/3 & j=1 \\\\\n  1/2 & j=2 \\\\\n  1 & j=3\n    \\end{cases}\n  \\]\n\n\nEn términos generales la función de riesgo es más informativa que la función de sobrevivencia.\nSiguiendo con el caso discreto: \\[H(x)=\\sum_{x_j\\leq x}h(x_j)\\] y la relación Equation 1.1 no aplica. Otros autores prefieren definir la función de riesgo acumulada: \\[H(x)=-\\sum_{x_j\\leq x}\\log(1-h(x_j))\\] y en este caso la relación exponencial entre \\(S(x)\\) y \\(H(x)\\) sí se preserva. Note que si \\(h(x_j)\\approx 0\\) entonces la definición anterior de \\(H(x)\\) es una aproximación de Taylor de la definición original.\n\n\n1.1.3 Vida Residual Media\nEn muchas aplicaciones se requiere una estimación del tiempo esperado en que el evento va a ocurrir, dadas las condiciones actuales:\n\nDefinition 1.3 (Vida Residual Media)  \n\\[\\begin{align*}\n    mrl(x)&=E[X-x|X>x]=\\frac{\\int_x^{\\infty}(t-x)f(t)dt}{S(x)}\\\\\n    &=\\frac{\\int_x^{\\infty}S(t)dt}{S(x)}\n\\end{align*}\\]\n\nCuando \\(x=0\\), entonces \\(mrl(0)=\\int_0^{\\infty}S(t)dt=EX\\). Por otro lado se puede comprobar (Ejercicio):\n\\[\\begin{align*}\n    \\text{Var}(X)=2\\int_0^{\\infty}tS(t)dt-\\left[\\int_0^{\\infty}S(t)dt\\right]^2\n\\end{align*}\\]\nAdemás a partir de la función de sobrevivencia, también se puede calcular el cuantil correspondiente:\n\nDefinition 1.4 (Cuantil-p) Mínimo \\(x_p\\) tal que \\(S(x_p)\\leq 1-p\\): \\[\\inf\\{t:S(t)\\leq 1-p\\}\\] En el caso continuo: \\(S(x_p)=1-p\\).\n\n\n\n\n\n\n\nEjemplo: Ejemplos de vida media\n\n\n\nExponencial: Vida media \\(\\mu=EX=\\frac 1 \\lambda\\). Vida mediana \\(S(x_{0.5})=0.5\\), entonces:\n\\[S(x_{0.5})=e^{-\\lambda x_{0.5}}=\\frac 1 2 \\Rightarrow x_{0.5}=\\frac{\\log 2}{\\lambda}\\]\nVida media residual (usando la propiedad de pérdida de memoria): \\[mrl(x)=E[X-x|X>x]=E[X]=\\frac 1 \\lambda\\]\nWeibull:: \\[1-p=\\exp(-\\lambda x^{\\alpha}_p)\\Rightarrow x_p=\\left[-\\frac{\\log(1-p)}{\\lambda}\\right]^{1/\\alpha}\\]\n\n\nEn el ejemplo desarrollado anteriormente, en donde \\(\\alpha=\\lambda=2\\):\n\nalpha <- lambda <- 2\nx_05 <- (-log(1-0.5)/lambda)^(1/alpha)\nshow(x_05)\n\n[1] 0.588705\n\n\nes la vida mediana bajo el supuesto Weibull.\nEn el caso discreto: \\[mrl(x)=\\frac{(x_{i+1}-x)S(x_i)+\\sum_{j\\geq i+1}(x_{j+1}-x_j)S(x_j)}{S(x)}\\qquad \\text{para }x_i\\leq x<x_{i+1}\\]"
  },
  {
    "objectID": "Preliminares.html#modelos-paraméricos-usuales",
    "href": "Preliminares.html#modelos-paraméricos-usuales",
    "title": "1  Preliminares",
    "section": "1.2 Modelos Paraméricos Usuales",
    "text": "1.2 Modelos Paraméricos Usuales\nAdemás del caso Weibull, existen otras escogencias para modelar la función de sobrevivencia. Las más usuales son:\n\n1.2.1 Exponencial\n\\[\\begin{align*}\n    S(x)&=e^{-\\lambda x}, \\qquad x>0, \\lambda>0\\\\\n    f(x)&=\\lambda e^{-\\lambda x}\\\\\n    h(x)&=\\lambda\n\\end{align*}\\]\nRecuerden además que en el caso exponencial se cumple la propiedad de pérdida de memoria: \\(P(X\\geq x+z|X\\geq x)=P(X\\geq z)\\).\n\n\n1.2.2 Weibull\n\\[\\begin{align*}\n    S(x)&=e^{-\\lambda x^\\alpha}, \\qquad x>0, \\lambda>0, \\alpha>0\\\\\n    h(x)&=\\lambda\\alpha x^{\\alpha-1}\n\\end{align*}\\]\na los parámetros \\(\\lambda\\) y \\(\\alpha\\) se les llama de escala y forma respectivamente.\nBajo la transformación \\(Y=\\log X\\) si \\(X\\sim Weibull\\) se puede escribir \\(Y=\\mu+\\sigma E\\) donde \\(\\mu=\\frac{-\\log \\lambda}{\\alpha}\\) y \\(\\sigma=\\frac 1 \\alpha\\) y \\(E\\sim\\) Valor Extremo Estándar, es decir: \\[f_e(w)=e^{w-e^w}, \\quad w\\in  \\mathbb R\\] y \\[S_E(w)=e^{-e^w}\\]\n\n\n1.2.3 Log-normal\n\\(X\\) es una LogNormal\\((\\mu,\\sigma^2)\\) si \\(Y=\\log X\\sim N(\\mu,\\sigma^2)\\). En este caso:\n\\[\\begin{align*}\n    S(x)&=1-\\Phi\\left(\\frac{\\log x-\\mu}{\\sigma}\\right)\\\\\n    h(x)&=\\frac{\\phi(x)}{S(x)}\n\\end{align*}\\]\nEn general la tasa de riesgo \\(h(x)\\) no es monótona, por ejemplo tomando \\(\\mu=0\\) y \\(\\sigma=1\\):\n\nhLNormal <- function(x,mu,sigma){\n  dnorm(x)/plnorm(x,meanlog = mu,sdlog = sigma,lower.tail = F)\n}\n\nggplot()+\n  xlim(0,3)+\n  geom_function(fun = hLNormal,args= list(mu = 0, sigma = 1))+\n  ylab('h')+\n  theme_bw()\n\n\n\n\nlo cual no necesariamente tiene sentido en muchas aplicaciones.\n\n\n1.2.4 Log-logístico\n\\(X\\) es una variable aleatoria log-logística si \\(Y=\\log X\\sim\\) logístico: \\[f_Y(y)=\\frac{e^{\\frac{y-\\mu}{\\sigma}}}{\\sigma\\left[1+e^{\\frac{y-\\mu}{\\sigma}}\\right]^2},\\qquad y \\in \\mathbb R\\]\ncon función de tasa y función de sobrevivencia:\n\\[\\begin{align*}\n    h(x)&=\\frac{\\alpha \\lambda x^{\\alpha-1}}{1+\\lambda x^\\alpha}\\qquad \\text{más flexible que Weibull}\\\\\n    S(x)&=\\frac{1}{1+\\lambda x^\\alpha}\n\\end{align*}\\]\ncon \\(\\alpha=\\frac 1 \\sigma>0\\), \\(\\lambda=e^{-\\mu/\\sigma}\\)\n\n\n1.2.5 Gamma\n\\[f(x)=\\frac{\\lambda^\\beta x^{\\beta-1}e^{-\\lambda x}}{\\Gamma(\\beta)},\\qquad \\lambda,\\beta,x>0\\] Si \\(\\beta=1\\): exponencial, \\(\\beta\\longrightarrow \\infty\\): Normal. Además \\(h(x)\\) tiene una forma complicada (ver Klein) pero no es muy flexible (solamente crece o decrece).\n\n\n1.2.6 Gompertz\n\\[\\begin{align*}\n    f(x)&=\\theta \\exp(\\alpha x)\\exp \\left(\\frac \\theta \\alpha (1-e^{\\alpha x})\\right)\\\\\n    h(x)&=\\theta \\exp(\\alpha x)\n\\end{align*}\\]\nen este caso si \\(\\alpha>1\\) y \\(\\theta>0\\) entonces \\(h\\) es monótona creciente. Además podemos generalizar levemente la ley anterior por medio del modelo de Makeham: \\[h(x)=\\theta \\exp(\\alpha x)+\\lambda\\]\nla cual permite que \\(h\\) sea más flexible.\n\nhGompertz <- function(x,alpha,theta,lambda){\n  theta*exp(alpha*x)+lambda\n}\n\nggplot()+\n  xlim(0,3)+\n  geom_function(fun = hGompertz,args= list(alpha = 0.5, theta = 0.5,lambda = 0.2))+\n  ylab('h')+\n  theme_bw()"
  },
  {
    "objectID": "Preliminares.html#modelos-de-regresión-para-datos-de-sobrevivencia",
    "href": "Preliminares.html#modelos-de-regresión-para-datos-de-sobrevivencia",
    "title": "1  Preliminares",
    "section": "1.3 Modelos de regresión para datos de sobrevivencia",
    "text": "1.3 Modelos de regresión para datos de sobrevivencia\nSea \\(X\\) la variable aleatoria de tiempo de fallo u ocurrencia de riesgo. Usualmente la distribución de la variable \\(X\\) se asocia con variables explicativas o covariables:\n\\[Z^T=(Z_1,\\ldots,Z_p)\\]\ndonde estas covariables pueden ser cuantitativas o categóricas, y no se descarta la posibilidad de que estas dependan del tiempo \\(x\\):\n\\[Z^T(x)=(Z_1(x),\\ldots,Z_p(x))\\]\nUsualmente los modelos de regresión en este contexto se definen de dos formas:\nEnfoque 1\nUsar la variable dependiente \\(X\\) como variable transformada según \\(Y=\\log(X)\\) y hacer la regresión lineal múltiple:\n\\[Y=\\mu+\\gamma^TZ+\\sigma \\epsilon\\]\ndonde \\(\\gamma^T=(\\gamma_1,\\ldots,\\gamma_p)\\) es un vector de coeficientes y \\(\\epsilon\\) es un error independiente que se puede distribuir según:\n\nUna normal estándar (Regresión log-normal).\nUna distribución de valor extremo estándar (Regresión Weibull)\nUna distribución logística (Regresión log-logística).\n\nMétodo de estimación: Máxima Verosimilitud.\nSea \\(S_0(x)\\) la función de sobrevivencia de \\(X=e^Y\\) cuando \\(Z=0\\), es decir es la función de sobrevivencia de \\(\\exp(\\mu+\\sigma \\epsilon)\\). Entonces:\n\\[\\begin{align*}\n    P[X>x|Z]&=P[Y>\\log x|Z]=P[\\mu+\\gamma^TZ+\\sigma \\epsilon>\\log x|Z]\\\\\n    &=P[\\exp(\\mu+\\sigma \\epsilon)>x\\exp(-\\gamma^T Z)|Z]=S_0(x\\exp(-\\gamma^T Z)).\n\\end{align*}\\]\nConclusión: el efecto de las covariables \\(Z\\) en la función de sobrevivencia de \\(X\\) es el escalamiento del tiempo \\(x\\) a través del factor \\(\\exp(-\\gamma^T Z)\\). Por este motivo a este modelo se le llama modelo de tiempo de fallo acelerado. Su función de riesgo es (ejercicio): \\[h(x|Z)=h_0\\left[x\\exp(-\\gamma^T Z)\\right]\\exp(-\\gamma^T Z)\\]\n\n\n\n\n\n\nEjemplo: Regresión Weibull\n\n\n\nSea \\(X\\sim Weibull(\\lambda, \\alpha)\\). Si \\(Y=\\log X\\) entonces \\(Y=\\mu+\\sigma W\\) donde \\(\\mu=-\\frac{\\log \\lambda}{\\alpha}\\), \\(\\sigma=\\frac 1 \\alpha\\) y \\(W\\sim \\text{VE-Standard}\\), es decir: \\[f_W(w)=\\exp\\left(w-e^w\\right)\\qquad w\\in \\mathbb R\\]\nSi \\(Z_1=1\\) en el vector de covariables \\(Z\\), entonces bajo el modelo de regresión Weibull, se puede calcular:\n\\[\\begin{align*}\n    S_Y(y|Z)&=P[Y>y|Z]=P\\left[W>\\frac{y-\\gamma^T Z}{\\sigma}|Z\\right]\\\\\n    &=\\exp\\left[-\\exp\\left[\\frac{y-\\gamma^T Z}{\\sigma}\\right]\\right]\n\\end{align*}\\]\ny cambiando a la variable original \\(X\\):\n\\[\\begin{align*}\nS_X(x|Z)&=\\exp\\left[-\\exp\\left[\\frac{\\log x-\\gamma^T Z}{\\sigma}\\right]\\right]=\\exp\\left[-x^{1/\\sigma}\\exp\\left[-\\frac{\\gamma^T Z}{\\sigma}\\right]\\right]\\\\\n&=\\exp\\left[-\\left[x\\exp(-\\gamma^T Z)\\right]^\\alpha\\right]=S_0(x\\exp(-\\gamma^T Z))\n\\end{align*}\\] donde \\(S_0\\) es la función de sobrevivencia Weibull.\n\n\nEnfoque 2\nModelación de la tasa de riesgo condicional\nEn este enfoque se trabaja con dos tipos de modelos:\n\nModelos con tasa de riesgo multiplicativa:\n\n\\[\nh(x|Z)=h_0(x)c(\\beta^T Z)\n\\tag{1.2}\\]\ndonde \\(h_0\\) puede ser una función paramétrica o arbitraria y \\(c\\) es una función arbitraria no-negativa. Cuando\n\\[c(\\beta^T Z)=\\exp(\\beta^T Z)\\]\nal modelo en Equation 1.2 se le llama Modelo de Cox. Para este último modelo, si existe dos individuos con distinto conjunto de covariables \\(Z_1\\) y \\(Z_2\\). Entonces:\n\\[\\frac{h(x|Z_1)}{h(x|Z_2)}=\\frac{c(\\beta^TZ_1)}{c(\\beta^TZ_2)}\\]\nlo cual es independiente de \\(x\\) (propiedad de riesgos proporcionales). Además, note que\n\\[\\begin{align*}\n    S(x|Z)&=\\exp\\left[-\\int_0^xh(u|Z)du\\right]=\\exp\\left[-c(\\beta^T Z)\\int_0^xh_0(u)du\\right]\\\\\n    &=S_0(x)^{c(\\beta^T Z)}.\n\\end{align*}\\]\n\n\n\n\n\n\nEjemplo: Regresión Weibull\n\n\n\nEn el caso Weibull: \\(h_0(x)=\\alpha \\lambda x^{\\alpha-1}\\) y la función de riesgo condicional en el caso de un modelo de Cox es: \\[h(x|Z)=\\alpha \\lambda x^{\\alpha-1}\\exp(\\beta^T Z)\\]\nNote que en este caso: \\[\\begin{align*}\n    S(x|Z)&=S_0(x)^{c(\\beta^T Z)}\\\\\n    &=\\exp[-\\lambda (x\\exp(\\beta^T Z/\\alpha))^\\alpha]=S_0(x\\exp(\\beta^T Z/\\alpha))\n\\end{align*}\\]\npor lo cual el modelo de regresión Weibull se puede expresar como modelo de tiempo de fallo acelerado o bien como modelo de riesgos proporcionales. (único caso)\n\n\n\nModelos con tasa de riesgo aditiva: \\[h(x|Z)=h_0(x)+\\sum_{j=1}^pZ_j(x)\\beta_j(x)\\]\n\nEste tipo de modelo tiene dificultades extra, por ejemplo los parámetros \\(\\beta_j(x)\\) deben ser seleccionados de manera que la tasa de riesgo \\(h(x|Z)\\) sea positiva. Por otro lado también \\(\\beta_j(x)\\) puede depender del tiempo \\(x\\)."
  },
  {
    "objectID": "Preliminares.html#modelos-de-riesgos-en-competencia",
    "href": "Preliminares.html#modelos-de-riesgos-en-competencia",
    "title": "1  Preliminares",
    "section": "1.4 Modelos de riesgos en competencia",
    "text": "1.4 Modelos de riesgos en competencia\nSi \\(T\\) denota el tiempo de fallo o bien el tiempo hasta que ocurre un evento. En este contexto, puede ser que existan \\(K\\) distintas causas del fallo. Por ejemplo, ante el evento de muerte a los 65 años, esta se puede deber a muchas causas.\nSea \\(X_i\\) el tiempo hasta que ocurra el \\(i\\)-ésimo riesgo en competencia. Sea \\(T=\\min(X_1,\\ldots,X_K)\\) y considere la variable \\(\\delta\\) que asume el valor \\(i\\) si \\(T=X_i\\). Definimos la tasa del riesgo \\(i\\)-ésimo como:\n\\[\\begin{align*}\n   h_i(t)&=\\lim_{\\Delta t\\rightarrow 0}\\frac{P[t\\leq T < t+\\Delta t, \\delta=i|T\\geq t]}{\\Delta t}\\\\\n   &=\\lim_{\\Delta t\\rightarrow 0}\\frac{P[t\\leq X_i < t+\\Delta t|X_j\\geq t, \\quad j=1,\\ldots,K]}{\\Delta t}\n\\end{align*}\\]\nEntonces, si \\(S(t_1,\\ldots,t_K)=P[X_1>t_1,\\ldots,X_K>t_K]\\)\n\\[\\begin{align*}\n   h_T(t)=\\sum_{i=1}^Kh_i(t) \\quad \\text{y} \\quad h_i(t)=\\frac{-\\frac{\\delta}{\\delta t_i}S(t_1,\\ldots,t_k)|_{t_1=\\cdots=t_K=t}}{S(t,\\ldots,t)}\n\\end{align*}\\]\nCaso especial: si los \\(K\\) riesgos en competencia son independientes:\n\\[h_i(t)=\\frac{-\\frac{\\delta}{\\delta t_i}\\prod_{j=1}^KS_j(t_j)|_{t_1=\\cdots=t_K=t}}{\\prod_{j=1}^KS_j(t)}=\\frac{-\\frac{\\delta}{\\delta t_i}S_i(t_i)|_{t_i=t}}{S_i(t)}\\]\nEn el caso no independiente (ver Ejemplo 2.7 del Klein).\nNota: es fundamental hacer algún supuesto sobre la estructura de dependencia en los tiempos de fallo, ya que al acontecer el riesgo en una causa especifica no se observó el tiempo de fallo en los riesgos restantes.\nEn el contexto de riesgos en competencia, no siempre se utiliza la tasas de riesgo para sintetizar la información, sino que también se utiliza probabilidades con distinta interpretación:\n\nProbabilidades crudas: probabilidad de muerte de un individuo bajo una causa en particular, cuando el resto de las causas también influyen en el comportamiento de sobrevivencia del individuo.\n\nSe calculan a través de la función de incidencia acumulativa:\n\\[\\begin{align*}\n   F_i(t)&=P[T\\leq t, \\delta = i]\\\\\n   &=\\int_0^th_i(u)\\exp[-H_T(u)]du\n\\end{align*}\\]\ndonde el último término exponencial es la tasa acumulativa de todos los riesgos en competencia. Note que \\(F_i\\) no es una distribución ya que:\n\\[F_i(\\infty)=P[\\delta = i]\\neq 1\\]\nAl aplicar la función \\(F_i\\) se puede calcular las probabilidades crudas directamente.\n\nProbabilidades netas: Probabilidad de muerte de un individuo donde la causa de muerte o riesgo de interés es el único. Usando la notación:\n\n\\[S_i(t)=S(0,\\ldots,0,\\stackrel{\\text{posicion }i}{t},0,\\ldots,0)\\]\nEn el caso independiente:\n\\[\\begin{align*}\n   S_i(t)&=\\exp(0)\\cdots \\exp\\left(-\\int_0^th_i(u)du\\right)\\cdots \\exp(0)\\\\\n   &=\\exp\\left[-\\int_0^t\\frac{dF_i(u)}{S_T(u)}du\\right]\n\\end{align*}\\]\n\nProbabilidades parciales crudas: Probabilidades de muerte en un contexto en donde algunos riesgos han sido eliminados. Sean \\(J\\): conjunto de causas o riesgos de interés. Defina:\n\n\\[T^J=\\min(X_i,i\\in J)\\quad \\text{y} \\quad F_i^J(t)=P[T^J\\leq t,\\delta=i]\\]\npara \\(i \\in J\\). Definimos la tasa de riesgo cruda parcial:\n\\[\\lambda_i^J=\\frac{-\\frac{\\delta S(t_1,\\ldots,t_K)}{\\delta t_i}\\Big \\vert_{t_j=t, j\\in J; t_j=0, j\\in J^C}}{S(t_1,\\ldots,t_K)\\Big \\vert_{t_j=t, j\\in J; t_j=0, j\\in J^C}}\\]\nEntonces:\n\\[F_i^J(t)=P[T^J\\leq t, \\delta=i]=\\int_0^t\\lambda^J_i(x)\\exp\\left[-\\sum_{j\\in J}\\int_0^t\\lambda_j^J(u)du\\right]dx\\]\nNote que en el caso independiente, la tasa de riesgo cruda parcial es:\n\\[\\lambda_i^J(t)=\\frac{dF_i(t)/dt}{S_T(t)}\\]"
  },
  {
    "objectID": "Preliminares.html#censura-y-truncamiento",
    "href": "Preliminares.html#censura-y-truncamiento",
    "title": "1  Preliminares",
    "section": "1.5 Censura y Truncamiento",
    "text": "1.5 Censura y Truncamiento\nConceptos de censura y truncamiento:\n\nDefinition 1.5 (Censura) Información de sobrevivencia de un individuo, que solamente se conoce con respecto a un intervalo y no a un punto fijo de occurrencia del evento de riesgo.\n\n\nDefinition 1.6 (Truncamiento) Restricción de entrada o salida a un estudio de sobrevivencia.\n\n\n1.5.1 Censura por la derecha\nTambién conocida como Censura Tipo I:\n\nDefinition 1.7 (Censura Tipo I) Evento de interés es observado solamente si ocurre antes de un tiempo específico.\n\nRecordando la notación que hemos usando hasta el momento, si \\(X\\) es el tiempo aleatorio en que ocurre el riesgo, \\(X\\sim f(x)\\) con función de sobrevivencia \\(S(x)\\) y además \\(C_r\\) denota el tiempo de censura fijo, entonces \\(X\\) es observado solamente si \\(X\\leq C_r\\) y si \\(X>C_r\\) decimos que el evento es “censurado”.\nEn este caso los datos pueden ser representados en pares:\n\\[(T,\\delta)\\]\ndonde \\(\\delta=1\\) indica que el evento se observa y \\(\\delta=0\\) indica que el evento es censurado. Además \\(T=\\min(X,C_r)\\).\n\n\n\n\n\n\nEjemplo: Ejemplo de Censura\n\n\n\nEn un estudio clínico, hay una serie de ratones alimentados con un agente cancerígeno. Se rastrea el tiempo de vida en cada ratón, hasta la muerte o bien hasta una censura pre-establecida (sacrificio):\n\n\n\n\n\nCensura Tipo I\n\n\n\n\nTambién se puede dar el caso de que el tiempo de censura entre observaciones no sea único (censura progresiva):\n\n\n\n\n\nCensura Tipo I-progresiva\n\n\n\n\nTambién se puede dar el caso de que no todos los sujetos de prueba (ratones) estuvieron al inicio del estudio (Censura Tipo I-generalizada):\n\n\n\n\n\nCensura Tipo I-generalizada\n\n\n\n\n\n\nOtra forma de representar los tiempos de sobrevivencia y censura en una muestra es a través de un Diagrama de Lexis, en donde se representa en el eje x el tiempo transcurrido (calendario) del estudio y en el eje y el tiempo transcurrido de cualquier individuo en el estudio:\n\n\n\n\n\nDiagrama de Lexis\n\n\n\n\nOtro tipo de esquema de censura por la derecha es la Censura Tipo II: en donde un estudio termina cuando fallan los primeros \\(r\\) individuos en un grupo de \\(n\\) individuos. Este tipo de esquema se suele aplicar en lotes de equipo electrónico por ejemplo o sistemas que están conectados en red. En este caso \\(r\\): número de fallos, \\(n-r\\): número de censuras y \\(T_{(r)}\\): tiempo de censura del estudio.\nTambién se puede utilizar un esquema progresivo para la censura tipo II. Suponga que hay \\(r_1\\) fallos de un total de \\(n\\) individuos. Además asuma que se censuran \\(n_1-r_1\\) individuos (\\(n_1<n\\)) con un primer tiempo de censura \\(T_{(r_1)}\\). El proceso puede continuar con los \\(n-n_1\\) individuos restantes, ocurre \\(r_2\\) fallos (\\(r_2<n-n_1\\)), \\(n_2-r_2\\) censuras (\\(n_1+n_2<n\\)) y \\(T_{(n_1+r_2)}\\) es el segundo tiempo de censura y así sucesivamente.\n\n\n1.5.2 Censura por la izquierda o de intervalo\nSuponga que para un tiempo de vida \\(X\\) existe un tiempo \\(C_\\ell\\) en donde el evento de riesgo ocurrió antes de que el sujeto fuera observado. En este caso el tiempo \\(X\\) es observado si \\(X>C_\\ell\\). Al igual que en el caso de censura por la derecha, podemos usar la notación:\n\\[(T,\\epsilon)\\]\ndonde \\(T=X\\) si \\(\\epsilon=1\\) (observado) y \\(T=C_\\ell\\) si \\(\\epsilon=0\\) (censurado), es decir \\(T=\\max(X,C_\\ell)\\). Por ejemplo, si un estudio busca cuantificar el riesgo de fumar marihuana por primera vez (Klein and Moeschberger 2003), un individuo tendría una censura por la izquierda si no recuerda la primera vez que fumó, pero afirma que sí la ha consumido antes del inicio del estudio.\nSi por otro lado se combina la censura por la derecha y por la izquierda, se denomina censura doble, y en este caso los datos son:\n\\[(T,\\delta)\\quad \\text{donde} \\quad T=\\max\\left(\\min(X,C_r),C_\\ell\\right)\\]\ny\n\\[\\begin{align*}\n\\delta=\\begin{cases}\n1 & \\text{si $T$ ocurre entre $C_\\ell$ y $C_r$}\\\\\n0 & \\text{censura por la derecha}\\\\\n-1 & \\text{censura por la izquierda}\n\\end{cases}\n\\end{align*}\\]\nFinalmente, la censura por intervalo se utiliza en estudios en donde un paciente o individuo en general es visitado periódicamente y lo único que se sabe es que el evento de interés ocurrió en un intervalo \\((L_i,R_i]\\) cuyos extremos corresponde a los momentos de visitas consecutivas.\n\n\n1.5.3 Truncamiento\nEl truncamiento ocurre cuando en un estudio solamente se incluyen y observan individuos cuyos eventos ocurren en \\((Y_L,Y_R)\\). Si el evento ocurriera fuera de ese intervalo entonces no se incluye en el estudio.\nSi \\(Y_R=\\infty\\) entonces X es observado \\(\\Leftrightarrow Y_L<X\\) (truncamiento por la izquierda). Por ejemplo: (1) si se estudia la aparición de una enfermedad desde una fecha fija o (2) si se estudia el evento de muerte desde el inicio de un estudio clínico.\nNota: Muchas veces el truncamiento por la izquierda es acompañado con censura por la derecha.\nPara el caso de truncamiento por la derecha: si \\(Y_L=0\\): \\(X\\) es observado \\(\\Leftrightarrow X\\leq Y_R\\) (ver Ejemplo 3.8 del (Klein and Moeschberger 2003))."
  },
  {
    "objectID": "Preliminares.html#verosimilitud-bajo-censura-y-truncamiento",
    "href": "Preliminares.html#verosimilitud-bajo-censura-y-truncamiento",
    "title": "1  Preliminares",
    "section": "1.6 Verosimilitud bajo censura y truncamiento",
    "text": "1.6 Verosimilitud bajo censura y truncamiento\nSupuesto: tiempos de ocurrencia de evento y tiempos de censura son independientes. Cada tipo de censura/truncamiento aporta distintos factores a la verosimilitud completa de los datos:\n\nTiempo exacto del evento en estudio: \\(f(x)\\)\nCensura por la derecha: \\(P(X>C_r)=S(C_r)\\)\nCensura por la izquierda: \\(P(X<C_\\ell)=1-S(C_\\ell)\\)\nCensura en intervalo: \\(P(L<X<R)=S(L)-S(R)\\)\nTruncamiento por la izquierda: \\(f(x|X>Y_L)=\\frac{f(x)}{S(Y_L)}\\)\nTruncamiento por la derecha: \\(f(x|X<Y_R)=\\frac{f(x)}{1-S(Y_R)}\\)\n\nPor lo tanto la verosimilitud con datos censurados se puede escribir como:\n\\[L\\propto \\prod_{i \\in D}f(x_i)\\prod_{i \\in R}S(C_r)\\prod_{i \\in L}\\left(1-S(C_\\ell)\\right) \\prod_{i \\in I}[S(L_i)-S(R_i)]\\]\ndonde\n\n\\(D\\): conjunto de eventos observables.\n\\(R\\): conjunto de observaciones con censura por la derecha.\n\\(L\\): conjunto de observaciones con censura por la izquierda.\n\\(I\\): conjunto de observaciones con censura por intervalo.\n\nPara datos truncados por la izquierda y censurados por la derecha con intervalo de truncamiento \\((Y_{L_i},Y_{R_i})\\) independientes del \\(i\\)-ésimo momento de muerte, se reemplaza \\(f(x_i)\\) y \\(S(C_i)\\) (\\(C_i\\): tiempo de censura \\(i\\)-ésima) por:\n\\[\\frac{f(x_i)}{S(Y_{L_i})-S(Y_{R_i})} \\quad \\text{y} \\quad \\frac{S(C_i)}{S(Y_{L_i})-S(Y_{R_i})}\\]\nEn el caso en donde cada individuo tiene una distribución de riesgo distinta (Ejemplo: regresión):\n\\[L\\propto \\prod_{i \\in D}f_i(x_i)\\prod_{i \\in R}S_i(C_r)\\prod_{i \\in L}\\left(1-S_i(C_\\ell)\\right) \\prod_{i \\in I}[S_i(L_i)-S_i(R_i)]\\]\nCaso particular: censura tipo I (por la derecha)\nSi \\(\\delta=0\\) (censura):\n\\[\\begin{align*}\n   P[T,\\delta=0]&=P[T=C_r|\\delta=0]P[\\delta=0]=P[\\delta=0]\\\\\n   &=P[X>C_r]=S(C_r).\n\\end{align*}\\]\nSi \\(\\delta = 1\\):\n\\[\\begin{align*}\n   P[T,\\delta=1]&=P[T=X|\\delta=1]P[\\delta=1]\\\\\n   &=P[T=X|X\\leq C_r]P[X\\leq C_r]\\\\\n   &=\\frac{f(t)}{1-S(C_r)}[1-S(C_r)]=f(t).\n\\end{align*}\\]\nEntonces el aporte de \\(T=t\\) a la verosimilitud es:\n\\[[f(t)]^\\delta[S(t)]^{1-\\delta}\\]\nSi se tiene una muestra aleatoria de pares \\((T_i,\\delta_i)\\), para \\(i=1,\\ldots,n\\):\n\\[L=\\prod_{i=1}^nf(t_i)^{\\delta_i}[S(t_i)]^{1-\\delta_i}\\]\nComo \\(f(t_i)=h(t_i)S(t_i)\\) entonces:\n\\[L=\\prod_{i=1}^nh(t_i)^{\\delta_i}S(t_i)^{\\delta_i}[S(t_i)]^{1-\\delta_i}=\\prod_{i=1}^nh(t_i)^{\\delta_i}\\exp(-H(t_i))\\]\n\n\n\n\n\n\nEjemplo: Caso Exponencial\n\n\n\nAsuma que \\(X\\sim \\text{Exponencial}(\\lambda)\\) con \\(f(x)=\\lambda \\exp(-\\lambda x)\\), entonces:\n\\[\\begin{align*}\n   L&=\\prod_{i=1}^n [\\lambda \\exp(-\\lambda t_i)]^{\\delta_i}[\\exp(-\\lambda t_i)]^{(1-\\delta_i)}\\\\\n   &=\\lambda^r\\exp(-\\lambda S_T)\n\\end{align*}\\]\ndonde \\(r=\\sum \\delta_i\\) (total de eventos observados) y \\(S_T=\\sum_{i=1}^n t_i\\) (total de tiempo en el estudio)."
  },
  {
    "objectID": "Preliminares.html#laboratorio",
    "href": "Preliminares.html#laboratorio",
    "title": "1  Preliminares",
    "section": "1.7 Laboratorio",
    "text": "1.7 Laboratorio\n\n1.7.1 Ejemplos de datos de análisis de sobrevivencia\n\nlibrary(tidyverse)\nlibrary(KMsurv)\n\n\n1.7.1.1 Ejemplo 1\nEnsayo clínico de un fármaco, 6-mercaptopurina (6-MP), frente a un placebo en 42 niños con leucemia aguda. El ensayo se llevó a cabo en 11 hospitales estadounidenses. Se seleccionaron pacientes que habían experimentado una remisión completa o parcial de su leucemia inducida por el tratamiento con el fármaco prednisona. (Una remisión completa o parcial significa que la mayoría o todos los signos de la enfermedad habían desaparecido de la médula ósea). El ensayo se realizó emparejando pares de pacientes en un hospital determinado por estado de remisión (completa o parcial) y aleatorizando dentro del par para recibir terapia de mantenimiento con 6-MP o placebo. Los pacientes fueron seguidos hasta que su leucemia regresó (relapse) o hasta el final del estudio (en meses).\n\ndata(\"drug6mp\")\n#help(\"drug6mp\")\n\nglimpse(drug6mp)\n\nRows: 21\nColumns: 5\n$ pair    <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,…\n$ remstat <int> 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2\n$ t1      <int> 1, 22, 3, 12, 8, 17, 2, 11, 8, 12, 2, 5, 4, 15, 8, 23, 5, 11, …\n$ t2      <int> 10, 7, 32, 23, 22, 6, 16, 34, 32, 25, 11, 20, 19, 6, 17, 35, 6…\n$ relapse <int> 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0\n\n\n\nggplot()+geom_histogram(data = drug6mp,mapping = aes(t2),bins = 6,fill='white',col = 'black')+\n  theme_bw()\n\n\n\n\n\ntable(drug6mp$relapse)\n\n\n 0  1 \n12  9 \n\n\n\n\n1.7.1.2 Ejemplo 2\nEvaluación del tiempo hasta la primera infección del sitio de salida (en meses) en pacientes con insuficiencia renal, 43 pacientes utilizaron un catéter colocado quirúrgicamente (Grupo 1), y 76 pacientes utilizaron una colocación percutánea de su catéter (Grupo 2).\n\ndata(kidney)\n#help(kidney)\n\nglimpse(kidney)\n\nRows: 119\nColumns: 3\n$ time  <dbl> 1.5, 3.5, 4.5, 4.5, 5.5, 8.5, 8.5, 9.5, 10.5, 11.5, 15.5, 16.5, …\n$ delta <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ type  <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n\n\n\nggplot()+geom_histogram(data = kidney,mapping = aes(time),bins = 6,fill='white',col = 'black')+\n  theme_bw()\n\n\n\n\n\ntable(kidney$delta)\n\n\n 0  1 \n93 26 \n\n\n\n\n1.7.1.3 Ejemplo 3\nEstudio diseñado para determinar si las pacientes con cáncer de mama, clasificadas originalmente como negativas en los ganglios linfáticos por microscopía de luz estándar (SLM), podrían ser clasificadas de manera más precisa mediante examen inmunohistoquímico (IH) de sus ganglios linfáticos con un cóctel de anticuerpos monoclonales anticitokeratina. Se seleccionaron 45 pacientes con cáncer de mama femenino y ganglios linfáticos axilares negativos y un seguimiento mínimo de 10 años del Registro de Cáncer de los Hospitales de la Universidad Estatal de Ohio. De las 45 pacientes, 9 fueron positivas para inmunoperoxidasa, y las 36 restantes permanecieron negativas.\n\ndata(btrial)\n#help(btrial)\n\nglimpse(btrial)\n\nRows: 45\nColumns: 3\n$ time  <int> 19, 25, 30, 34, 37, 46, 47, 51, 56, 57, 61, 66, 67, 74, 78, 86, …\n$ death <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0…\n$ im    <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n\n\n\ntabla_1 <- btrial %>% group_by(death,im) %>% summarise(total = n()) %>%\n  ungroup() %>% mutate(total = round(total / sum(total)*100,2))\n\n`summarise()` has grouped output by 'death'. You can override using the\n`.groups` argument.\n\nshow(tabla_1)\n\n# A tibble: 4 × 3\n  death    im total\n  <int> <int> <dbl>\n1     0     1 44.4 \n2     0     2  2.22\n3     1     1 35.6 \n4     1     2 17.8 \n\n\n\ntabla_2 <- btrial %>% group_by(death,im) %>% summarise(total = round(mean(time),2)) \n\n`summarise()` has grouped output by 'death'. You can override using the\n`.groups` argument.\n\nshow(tabla_2)\n\n# A tibble: 4 × 3\n# Groups:   death [2]\n  death    im total\n  <int> <int> <dbl>\n1     0     1 148. \n2     0     2 144  \n3     1     1  52.1\n4     1     2  59.9\n\n\n\n\n1.7.1.4 Ejemplo 4\nMuestra de 101 pacientes con leucemia mieloide aguda avanzada reportados en el Registro Internacional de Trasplante de Médula Ósea. 51 de estos pacientes recibieron un trasplante autólogo de médula ósea en el que, después de altas dosis de quimioterapia, su propia médula fue reinfundida para reemplazar su sistema inmunológico destruido. 50 pacientes recibieron un trasplante alogénico de médula ósea en el que se utilizó médula de un hermano compatible en cuanto a antígenos leucocitarios humanos (HLA) para reponer sus sistemas inmunológicos. Una pregunta importante en el trasplante de médula ósea es la comparación de la efectividad de estos dos métodos de trasplante medida por la duración de la supervivencia libre de leucemia de los pacientes, el tiempo que viven y cuánto tiempo permanecen libres de enfermedad después de sus trasplantes.\n\ndata(\"alloauto\")\n#help(\"alloauto\")\n\nglimpse(alloauto)\n\nRows: 101\nColumns: 3\n$ time  <dbl> 0.030, 0.493, 0.855, 1.184, 1.283, 1.480, 1.776, 2.138, 2.500, 2…\n$ type  <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ delta <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1…\n\n\n\nalloauto <- alloauto %>% mutate(type = factor(type))\n\nggplot()+geom_histogram(data = alloauto,aes(x = time),bins = 7,fill='white',col = 'black')+\n  facet_wrap(facets = vars(type),nrow = 2)+\n  theme_bw()\n\n\n\n\n\nlibrary(asaur)\nhead(gastricXelox)\n\n  timeWeeks delta\n1         4     1\n2         8     1\n3         8     1\n4         8     1\n5         9     1\n6        11     1\n\ndim(gastricXelox)\n\n[1] 48  2\n\n\n\n\n1.7.1.5 Ejemplo 5\nEste es un ensayo clínico de Fase II (muestra única) de quimioterapia Xeloda y oxaliplatino (XELOX) administrado antes de la cirugía a 48 pacientes con cáncer gástrico avanzado con metástasis en los ganglios linfáticos paraaórticos (Wang et al.).\n\ntimeWeeks: tiempo de sobrevivencia en semanas.\ndelta: variable de censura: (1) muerte, (2) censura.\n\n\nhead(prostateSurvival)\n\n  grade stage ageGroup survTime status\n1  mode   T1c      80+       18      0\n2  mode  T1ab    75-79       23      0\n3  poor   T1c    75-79       37      0\n4  mode    T2    70-74       27      0\n5  mode   T1c    70-74       42      0\n6  poor    T2    75-79       38      2\n\ndim(prostateSurvival)\n\n[1] 14294     5\n\n\n\n\n1.7.1.6 Ejemplo 6\nDatos simulados de 14,294 pacientes con cáncer de próstata basados en análisis detallados de riesgos competitivos publicados por Lu-Yao et al. Para cada paciente, tenemos la clasificación histológica (poco o moderadamente diferenciado), la edad del diagnóstico (66-70, 71-75, 76-80 y 80+), el estadio del cáncer (T1c si se diagnosticó mediante una prueba de detección de antígeno específico de próstata, T1ab si se diagnosticó clínicamente sin cribado, o T2 si fue palpable en el momento del diagnóstico), el tiempo de supervivencia (días desde el diagnóstico hasta la muerte o la última fecha de seguimiento) y un indicador (“estado”) que indica si el paciente murió de cáncer de próstata (estado = 1), murió de otra causa (estado = 2) o seguía vivo en la última fecha de seguimiento (estado = 0).\n\nageGroup: edad de diagnóstico.\nstage: etapa del cáncer.\nsurvTime: tiempo de sobrevivencia.\nstatus: Muerte por cáncer de próstata (1), muerte por otra causa (2), sobrevivencia al final del estudio (0).\n\n\nhead(pharmacoSmoking)\n\n   id ttr relapse         grp age gender     race employment yearsSmoking\n1  21 182       0   patchOnly  36   Male    white         ft           26\n2 113  14       1   patchOnly  41   Male    white      other           27\n3  39   5       1 combination  25 Female    white      other           12\n4  80  16       1 combination  54   Male    white         ft           39\n5  87   0       1 combination  45   Male    white      other           30\n6  29 182       0 combination  43   Male hispanic         ft           30\n  levelSmoking ageGroup2 ageGroup4 priorAttempts longestNoSmoke\n1        heavy     21-49     35-49             0              0\n2        heavy     21-49     35-49             3             90\n3        heavy     21-49     21-34             3             21\n4        heavy       50+     50-64             0              0\n5        heavy     21-49     35-49             0              0\n6        heavy     21-49     35-49             2           1825\n\ndim(pharmacoSmoking)\n\n[1] 125  14\n\n\n\n\n1.7.1.7 Ejemplo 7\nEl propósito de este estudio (Steinberg et al. [63]) fue evaluar la duración prolongada de una combinación de tres medicamentos versus la terapia con parche de nicotina sola en fumadores con enfermedades médicas. Los pacientes con antecedentes de tabaquismo fueron asignados al azar a la combinación de tres medicamentos o a la terapia con parche, y se siguieron durante un máximo de seis meses. La variable de resultado primaria fue el tiempo desde la asignación aleatoria hasta la recaída (vuelta al tabaquismo); las personas que permanecieron sin fumar durante seis meses fueron censuradas.\n\nttr: tiempo en dias hasta una recaída (volver a fumar).\nrelapse: (1): volvió a fumar vs (0): censura.\nemployment: jornada laboral.\n\n\n\n1.7.1.8 Ejemplo 8\nTasas de riesgo (Tablas de vida en USA) expresadas por día calendario:\n\nlibrary(survival)\n\n\nAttaching package: 'survival'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    kidney\n\ndim(survexp.us)\n\n[1] 110   2  75\n\nhazMale <- survexp.us[,\"male\",\"2010\"]\nhazFemale <- survexp.us[,\"female\",\"2010\"]\ntm <- 1:110\ntm.diff <- c(1,diff(tm))\nsurvMale <- exp(-cumsum(hazMale*tm.diff)*365.24)\nsurvFemale <- exp(-cumsum(hazFemale *tm.diff)*365.24)\ndata.tot <- data.frame(tm,hMale = as.numeric(hazMale),\n                       hFemale = as.numeric(hazFemale),\n                       sMale = survMale, sFemale = survFemale)\ndata.tot.long <- pivot_longer(data.tot,cols = hMale:sFemale)\n\nGrafico de tasas de riesgo:\n\ndata.tot.long.h <- data.tot.long %>% filter(name == 'hMale' | name == 'hFemale')\nggplot(data = data.tot.long.h)+geom_line(mapping = aes(x = tm,y = value,col = name)) + theme_bw() + xlab('Age')+ylab('Hazard')\n\n\n\n\nGrafico de probabilidades de sobrevivencia:\n\ndata.tot.long.s <- data.tot.long %>% filter(name == 'sMale' | name == 'sFemale')\nggplot(data = data.tot.long.s)+geom_line(mapping = aes(x = tm,y = value,col = name)) + theme_bw() + xlab('Age')+ylab('Hazard')\n\n\n\n\n\n\n\n\nKlein, John P., and Melvin L. Moeschberger. 2003. Survival analysis : techniques for censored and truncated data. Springer."
  },
  {
    "objectID": "estNP.html#intervalos-de-confianza-puntuales-de-st",
    "href": "estNP.html#intervalos-de-confianza-puntuales-de-st",
    "title": "2  Estimación No-Paramétrica",
    "section": "2.1 Intervalos de confianza puntuales de \\(S(t)\\)",
    "text": "2.1 Intervalos de confianza puntuales de \\(S(t)\\)\nSea \\(\\sigma_S(t)^2=\\frac{\\hat V[\\hat S(t)]}{\\hat S(t)^2}\\). Si \\(t_0\\) es un punto fijo de tiempo, definimos el intervalo de confianza lineal al \\(100\\cdot (1-\\alpha)\\)% para \\(S(t_0)\\) como:\n\\[\\hat S(t_0)\\pm z_{1-\\alpha/2}\\sigma_S(t_0)\\hat S(t_0)\\]\nCon el fin de mejorar el intervalo de confianza anterior, se puede considerar un intervalo de confianza sobre el logaritmo de \\(H(t)\\):\n\\[\\log \\hat H(t_0)\\pm z_{1-\\alpha/2}\\cdot \\sigma^*(t_0)\\]\ndonde \\(\\sigma^*(t_0)\\) lo tenemos que calcular o bien aproximar. Como \\(\\text{Var}(\\hat S(t))\\approx \\hat S(t)^2\\sigma_S(t)^2\\) entonces por el método delta (Ejercicio):\n\\[\\begin{align*}\n   \\text{Var}[\\log H(t_0)]&=\\text{Var}[\\log(-\\log S(t_0))]\\\\\n   &\\approx \\frac{1}{[\\log \\hat S(t_0)]^2}\\underbrace{\\sum_{t_i\\leq t}\\frac{d_i}{Y_i(Y_i-d_i)}}_{\\sigma_S(t_0)^2}\n\\end{align*}\\]\nentonces podemos aproximar el término \\(\\sigma^*(t_0)\\) y obtener:\n\\[\\log \\hat H(t_0)\\pm z_{1-\\alpha/2}\\cdot \\frac{1}{\\log S(t_0)}\\sigma_S(t_0)\\]\nes un intervalo de confianza al \\(100(1-\\alpha)\\)’% para \\(\\log[-\\log S(t_0)]\\). Entonces:\n\\[\\hat H(t_0)\\exp\\left[\\pm\\frac{z_{1-\\alpha/2}\\sigma_S(t_0)}{\\log S(t_0)}\\right]\\]\nes un IC para \\(H(t_0)\\) y \\([\\hat S(t_0)^{1/\\theta},\\hat S(t_0)^\\theta]\\) donde \\(\\theta=\\exp\\left[\\frac{z_{1-\\alpha/2}\\sigma_S(t_0)}{\\log \\hat S(t_0)}\\right]\\) es el IC al \\(100(1-\\alpha)\\)% para \\(S(t_0)\\).\nOtra posibilidad es utilizar la transformación \\(\\text{arcsen}[\\hat S(t_0)^{1/2}]\\)\nVentaja: ambas posibilidades permiten que el IC de \\(S(t_0)\\) no salga del intervalo \\([0,1]\\).\nPor otro lado, para muestras pequeñas, el IC con la transformación arcsen es más conservador, seguido del IC con transformación log-log y de último el lineal (sin transformación).\nNota: los intervalos log-log y arcsen no son simétricos."
  },
  {
    "objectID": "estNP.html#bandas-de-confianza-para-st",
    "href": "estNP.html#bandas-de-confianza-para-st",
    "title": "2  Estimación No-Paramétrica",
    "section": "2.2 Bandas de confianza para \\(S(t)\\)",
    "text": "2.2 Bandas de confianza para \\(S(t)\\)\nQueremos encontrar dos funciones aleatorias \\(L(t)\\) y \\(U(t)\\) tal que:\n\\[P[L(t)\\leq S(t)\\leq U(t)\\quad \\forall t: t_L\\leq t\\leq t_U]=1-\\alpha\\]\nA \\([L(t),U(t)]\\) le llamamos banda de confianza al \\(100(1-\\alpha)\\)% para \\(S(t)\\).\nNair(1984) define el concepto de Bandas EP, las cuales son proporcionales a los intervalos puntuales. Sean \\(t_L<t_U\\) tal que \\(t_L\\geq \\text{tiempo más pequeño del evento observado}\\) y \\(t_U\\leq \\text{tiempo más grande del evento observado}\\). Si \\(n\\) es el tamaño de muestra, defina:\n\\[a_L=\\frac{n\\sigma_S(t_L)^2}{1+n\\sigma_S(t_L)^2},\\qquad a_U=\\frac{n\\sigma_S(t_U)^2}{1+n\\sigma_S(t_U)^2}\\]\ny tomando \\(c_\\alpha(a_L,a_U)\\) de la tabla C.3 del Klein (también se puede obtener de R) entonces los tres tipos de Banda de confianza al \\(100(1-\\alpha)\\)% son:\n\nLineal: \\(\\hat S(t)\\pm c_\\alpha(a_L,a_U)\\sigma_S(t)\\hat S(t)\\)\nLog-log; \\((\\hat S(t)^{1/\\theta},\\hat S(t)^\\theta)\\), donde \\(\\theta=\\exp\\left[\\frac{c_\\alpha(a_L,a_U)\\sigma_S(t)}{\\log[\\hat S(t)]}\\right]\\).\nArcsen-raíz cuadrada: ver fórmula 4.4.4 del Klein.\n\nOtro método para construir las bandas es el de Hall y Wellner (1980) (ver Klein).\nNotas:\n\nSe pueden construir bandas de confianza para la tasa de riesgo acumulativo.\nIgual que en el caso de los intervalos puntuales, los intervalos log-log y arcsen se comportan mejor bajo muestras pequeñas."
  },
  {
    "objectID": "estNP.html#estimación-del-tiempo-medio-y-mediano-de-sobrevivencia",
    "href": "estNP.html#estimación-del-tiempo-medio-y-mediano-de-sobrevivencia",
    "title": "2  Estimación No-Paramétrica",
    "section": "2.3 Estimación del tiempo medio y mediano de sobrevivencia",
    "text": "2.3 Estimación del tiempo medio y mediano de sobrevivencia\nRecuerden que el tiempo medio de sobrevivencia es:\n\\[\\mu=\\int_0^\\infty S(t)dt\\]\nUn estimador plug-in para este caso es:\n\\[\\hat \\mu=\\int_0^\\infty\\hat S(t)dt\\]\ncon el principal inconveniente de que el estimador de Kaplan-Meier está definido hasta un valor de \\(t\\) máximo, llámese \\(\\tau\\) (tiempo de sobrevivencia máximo condicionado con respecto a censuras):\n\\[\\hat \\mu_\\tau=\\int_0^\\tau \\hat S(t)dt\\]\nNormalmente \\(\\tau\\) es el tiempo de muerte máximo o bien el tiempo máximo de censura asumiendo muerte del individuo (corrección de Efron). Para el estimador \\(\\mu_\\tau\\), su varianza es:\n\\[\\hat V[\\hat \\mu_\\tau]=\\sum_{i=1}^D\\left[\\int_{t_i}^\\tau \\hat S(t)dt\\right]^2\\frac{d_i}{Y_i(Y_i-d_i)}\\]\ny un intervalo de confianza para \\(\\mu\\) al \\(100(1-\\alpha)\\)% es:\n\\[\\hat \\mu_\\tau\\pm z_{1-\\alpha/2}\\sqrt{\\hat V[\\hat \\mu_\\tau]}\\]\nPor otro lado, también es posible estimar cuantiles de la distribución de \\(T\\):\n\\[\\text{cuantil-}p = x_p = \\inf\\{t:S(t)\\leq 1-p\\}\\]\nel cual puede ser estimado con un estimador plug-in:\n\\[\\hat x_p = \\inf\\{t:\\hat S(t)\\leq 1-p\\}\\]\nLa varianza del estimador anterior se pueden estimar como:\n\\[\\hat V(\\hat x_p)=\\frac{\\hat V[\\hat S(\\hat x_p)]}{\\hat f(\\hat x_p)^2}\\]\ndonde \\(\\hat f(\\hat x_p)\\) es un estimador no-paramétrico de \\(f(\\hat x_p)\\) (densidad). Por ejemplo, cualquier estimador por kernel de \\(f\\) es una opción válida.\nAproximación de Brookmeyer y Crowley\n\\[-z_{1-\\alpha/2}\\leq \\frac{\\hat S(t)-(1-p)}{\\hat V^{1/2}[\\hat S(t)]}\\leq z_{1-\\alpha/2}\\]\nes un intervalo de confianza al \\(100(1-\\alpha)\\)% para \\(x_p\\). Un IC para \\(x_p\\) basado en la transformación log-log es:\n\\[-z_{1-\\alpha/2}\\leq \\frac{\\log(-\\log \\hat S(t))-\\log(-\\log(1-p))}{\\frac{\\hat V^{1/2}(\\hat S(t))}{\\hat S(t)\\log \\hat S(t)}}\\leq z_{1-\\alpha/2}\\]\nNota: caso más usual es \\(p=1/2\\)."
  },
  {
    "objectID": "estNP.html#estimadores-para-datos-censurados-por-la-derecha-y-truncados-por-la-izquierda",
    "href": "estNP.html#estimadores-para-datos-censurados-por-la-derecha-y-truncados-por-la-izquierda",
    "title": "2  Estimación No-Paramétrica",
    "section": "2.4 Estimadores para datos censurados por la derecha y truncados por la izquierda",
    "text": "2.4 Estimadores para datos censurados por la derecha y truncados por la izquierda\nConsidere para cada individuo:\n\n\\(L_j\\): edad aleatoria de ingreso del individuo \\(j\\)-ésimo.\n\\(T_j\\): tiempo de ocurrencia del evento o censura para el individuo \\(j\\)-ésimo.\n\nSea \\(t_1<t_2<\\cdots <t_D\\) los tiempos distintos de ocurrencia de los eventos. Además, siguiendo la notación de las secciones anteriores:\n\n\\(d_i\\): número de individuos que experimentan el evento o riesgo de interés en tiempo \\(t_i\\) (\\(i=1,\\ldots,D\\))\n\\(Y_i\\): individuos en riesgo al tiempo \\(t_i\\).\n\nCon el fin de considerar esquemas de censura/truncamiento más amplios, se tienen las siguientes dos definiciones para la población en riesgo:\n\n\\(Y_i\\): número de individuos en el estudio en tiempo \\(0\\) y que están en riesgo al momento \\(t_i\\) (esquema sin truncamiento )\n\\(Y_i\\): número de individuos en riesgo al momento \\(t_i\\) tales que (Truncamiento por la izquierda) (Tsai, Jewell, and Wang 1987):\n\n\\[L_j\\leq t_i \\leq T_j\\]\nTodos los estimadores de \\(S(t)\\) vistos hasta ahora aplican, pero la interpretación debe hacerse con cuidado. Por ejemplo, el estimador de KM se debe interpretar como el estimador de la función de sobrevivencia en tiempo \\(t\\), pero condicional en \\(L=\\min_j\\{L_j\\}\\):\n\\[P[X>t|X\\geq L]=\\frac{S(t)}{S(L)}\\]\nPor lo tanto el estimador de KM sería:\n\\[\\hat S_L(t)=\\prod_{L\\leq t_i \\leq t}\\left[1-\\frac{d_i}{Y_i}\\right]\\qquad t\\geq L\\]\nes decir se estaía incluyendo solamente eventos o censuras que estén después de \\(a\\), donde \\(a=L\\).\nNota: las fórmulas de Nelson-Aalen y Greenwood también se pueden calcular en este contexto."
  },
  {
    "objectID": "estNP.html#estimadores-para-riesgos-en-competencia",
    "href": "estNP.html#estimadores-para-riesgos-en-competencia",
    "title": "2  Estimación No-Paramétrica",
    "section": "2.5 Estimadores para riesgos en competencia",
    "text": "2.5 Estimadores para riesgos en competencia\nPara modelos de riesgos de competencia, el supuesto de independencia entre tiempos de eventos y censuras no necesariamente se puede aplicar. En este caso, definimos tres formas distintas de resumir información:\nEstimador de Kaplan-Meier complementario\nSi existieran dos riesgos en competencia (A y B) se define el estimador:\n\\[\\hat S_A(t)=KM(\\text{ocurrencias de A como eventos, ocurrencias de B como censuras})\\]\nLa idea se generaliza muy fácilmente para el caso de más de dos riesgos. Inconveniente: estimador muy crudo para generar interpretaciones apropiadas.\nFunción acumulada de incidencia\nSea \\(t_1,\\ldots,t_k\\) los tiempos distintos en los cuales uno de los riesgos en competencia ocurre. En tiempo \\(t_i\\) definimos lo siguiente:\n\n\\(Y_i\\): número de sujetos en riesgo al momento \\(t_i\\).\n\\(r_i\\): número de sujetos que les ocurrió el evento de interés.\n\\(d_i\\): número de sujetos que les ocurrió otro evento que no sea el de interés (sin incluir censuras).\n\nLa función acumulada de incidencia se define:\n\\[\\begin{align*}\n   CI(t)=\\begin{cases}\n     0 & t\\leq t_1\\\\\n     \\sum_{t_i\\leq t}\\underbrace{\\left[\\prod_{j=1}^{i-1}\\frac{1-(d_j+r_j)}{Y_j}\\right]}_{\\hat S(t_{i-})}\\frac{r_i}{Y_i} & t_1\\leq t\n  \\end{cases}\n\\end{align*}\\]\ndonde \\(\\hat S(t_{i-})\\) es el estimador KM evaluado justo antes de \\(t_i\\).\nInterpretación de \\(CI(t)\\): probabilidad de que el evento de interés ocurra antes de tiempo \\(t\\) y antes de cualquier otro evento en competencia. La varianza de \\(CI(t)\\) es: (fórmula 4.7.2-Klein)\n\\[V[CI(t)]=\\sum_{t_i\\leq t}\\hat S(t_i)^2\\left[(CI(t)-CI(t_i))^2\\cdot \\frac{r_i+d_i}{Y_i^2}+[1-2(CI(t)-CI(t_i))]\\cdot \\frac{r_i}{Y_i^2}\\right]\\]\nde lo anterior es posible construir un intervalo de confianza al \\(100(1-\\alpha)\\)% para la incidencia acumulada:\n\\[CI(t)\\pm z_{1-\\alpha/2}V[CI(t)]^{1/2}\\]\nProbabilidad condicional para un riesgo en competencia\nSi \\(CI_k(t)\\) es la función acumulada de incidencia para el riesgo \\(k\\)-ésimo y \\(CI_{k^c}(t)\\) es la función acumulada de incidencia para todos los riesgos excepto el \\(k\\)-ésimo. Entonces definimos la probabilidad condicional para el riesgo \\(k\\)-ésimo como:\n\\[CP_k(t)=\\frac{CI_k(t)}{1-CI_{k^c}(t)}\\]\ncon varianza:\n\\[V[CP_k(t)]=\\frac{\\hat S(t_{-})^2}{[1-CI_{k^c}(t)]^4}\\sum_{t_i\\leq t}\\frac{[1-CI_{k^c}(t_i)]^2r_i+CI_k(t_i)^2d_i}{Y_i^2}\\]\nInterpretación de \\(CP_k(t)\\): estima la probabilidad condicional de que el evento \\(k\\) ocurre en tiempo \\(t\\) si ninguna de las otras causas de riesgo han ocurrido antes de \\(t\\)."
  },
  {
    "objectID": "estNP.html#estimación-de-st-para-otros-esquemas-de-censura",
    "href": "estNP.html#estimación-de-st-para-otros-esquemas-de-censura",
    "title": "2  Estimación No-Paramétrica",
    "section": "2.6 Estimación de \\(S(t)\\) para otros esquemas de censura",
    "text": "2.6 Estimación de \\(S(t)\\) para otros esquemas de censura\n\n2.6.1 Censura por la izquierda\nEn este caso los individuos experimentan el evento antes del periodo de observación, o bien lo experimentan dentro del periodo de observacion.\nSolución: redefinir el tiempo al fijar para \\(\\tau>0\\) (grande):\n\\[\\tilde t=\\tau-t\\]\ny transformar entonces la censura por la izquierda por censura por la derecha. Como estimadores se pueden utilizar KM o Nelson-Aalen con la particularidad de que:\n\\[P[\\tau-X>t]=P[X<t-\\tau]\\]\n\n\n2.6.2 Censura doble\nPara estimar \\(S(t)\\) bajo este esquema, usaremos el Proceso o algoritmo de Turnbull:\nSuponga una grilla de puntos en el tiempo:\n\\[0=t_0<t_1<t_2<\\cdots<t_m\\]\ny defina:\n\n\\(d_i\\): número de eventos en tiempo \\(t_i\\) (\\(d_i\\) puede ser 0).\n\\(r_i\\): número de individuos con censura por la derecha en tiempo \\(t_i\\).\n\\(c_i\\): número de individuos con censura por la izquierda en tiempo \\(t_i\\).\n\nAlgoritmo\n\nPaso 0: Produzca un estimador inicial de \\(S(t)\\) en cada \\(t_j\\) llamado \\(S_0(t_j)\\). Turnbull (1974): tome \\(S_0(t)=KM(t)\\) ignorando la censura por la izquierda.\nPaso \\(k+1\\):\n\nCon \\(S_k(\\cdot)\\) calcule, para \\(j\\leq i\\):\n\n\n\\[p_{ij}=P[t_{j-1}<X\\leq t_j|X\\leq t_i]= \\frac{S_k(t_{j-1})-S_k(t_j)}{1-S_k(t_i)}\\]\n\nEstime el número de eventos en tiempo \\(t_i\\) como:\n\n\\[\\hat d_i=d_i+\\sum_{i=j}^m c_ip_{ij}\\]\n\nCalcule el estimador KM con datos censurados por la derecha usando \\(\\hat d_i\\) como eventos y \\(r_i\\) como censuras.\nSi \\(S_{k+1}(t)\\) es cercano a \\(S_k(t)\\) para todo \\(t_i\\) entonces el proceso termina.\n\n\n\n2.6.3 Censura por intervalo\nPara este esquema cada individuo tiene un intervalo \\((L_i,R_i]\\) en donde el evento ocurre, pero el tiempo exacto es desconocido (\\(i=1,\\ldots,n\\))\nPara estimar la función de sobrevivencia, se utiliza una modificación del algoritmo de Turnbull. Considere una grilla de tiempos \\(0=\\tau_0<\\tau_1<\\cdots<\\tau_m\\) que incluyen a \\(L_i,R_i\\) para todo \\(i=1,\\ldots,n\\).\nPara la observación \\(i\\)-ésima, defina:\n\\[\\begin{align*}\n\\alpha_{ij}=\n   \\begin{cases}\n       1 & \\text{si } (\\tau_{j-1},\\tau_j]\\subseteq (L_i,R_i] \\\\\n       0 & \\text{otro caso}\n   \\end{cases}\n\\end{align*}\\]\ny dado un estimador inicial de \\(S(\\tau_j)\\):\n\nPaso 1: Calcule la probabilidad de que el evento ocurre en tiempo \\(\\tau_j\\):\n\n\\[p_j=S(\\tau_{j-1})-S(\\tau_j) \\qquad j=1,\\ldots,m\\]\n\nPaso 2: Estime el número de eventos al tiempo \\(\\tau_i\\):\n\n\\[d_i=\\sum_{i=1}^n \\frac{\\alpha_{ij}p_j}{\\sum_k \\alpha_{ik}p_k}\\]\n\nPaso 3: Calcule una estimación de los sujetos en riesgo al tiempo \\(\\tau_i\\):\n\n\\[Y_i=\\sum_{k=i}^m d_k\\]\n\nPaso 4: Calcule el estimador KM con los datos en los pasos 3 y 4 hasta que haya convergencia de \\(S\\) uniformemente en \\(\\tau_i\\)."
  },
  {
    "objectID": "estNP.html#laboratorio",
    "href": "estNP.html#laboratorio",
    "title": "2  Estimación No-Paramétrica",
    "section": "2.7 Laboratorio",
    "text": "2.7 Laboratorio\n\n2.7.1 Ajustes básicos\nPaquete base de análisis de sobrevivencia: survival. Junto con el paquete KMsurv que contiene los datos del libro de Klein y M.\n\nlibrary(survival)\nlibrary(KMsurv)\nlibrary(survMisc)\n\n\nAttaching package: 'survMisc'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    autoplot\n\nlibrary(tidyverse)\n\nPara ilustrar el cálculo de los estimadores no paramétricos de sobrevivencia con el paquete survival, trabajamos con la base de la sección 1.2 del Klein: Estudio clínico de la droga 6-MP vs un placebo en 42 niños con leucemia aguda. Todos los pacientes presentaban una remisión en el cańcer a nivel de la médula ósea, gracias a un tratamiento con prednisona. A los pacientes se agruparon en pares y se les administró 6-MP o el placebo y se monitoreó hasta que la leucemia regresaba o hasta el fin del estudio (meses). A continuación un vistazo de los datos:\n\ndata(\"drug6mp\")\nhead(drug6mp)\n\n  pair remstat t1 t2 relapse\n1    1       1  1 10       1\n2    2       2 22  7       1\n3    3       2  3 32       0\n4    4       2 12 23       1\n5    5       2  8 22       1\n6    6       1 17  6       1\n\n\nPara una explicación de las variables ver la ayuda de drug6mp o bien la tabla 1.1 en el Klein. Noten que la última columna corresponde al indicador del evento (recaída de los pacientes) para el grupo que se le administró el tratamiento (6-MP).\nComo un primer ejercicio, se calcula el estimador de Kaplan-Meier para el grupo tratamiento (6_MP). Para eso primero calculamos el objeto Surv que contiene los tiempos de ocurrencia junto con las censuras:\n\nsurv_6MP <- Surv(time = drug6mp$t2,event = drug6mp$relapse)\n\nsurv_6MP\n\n [1] 10   7  32+ 23  22   6  16  34+ 32+ 25+ 11+ 20+ 19+  6  17+ 35+  6  13   9+\n[20]  6+ 10+\n\n\ny después calculamos el estimador de Kaplan-Meier:\n\nKM_6MP <- survfit(surv_6MP~1)\n\nsummary(KM_6MP)\n\nCall: survfit(formula = surv_6MP ~ 1)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    6     21       3    0.857  0.0764        0.720        1.000\n    7     17       1    0.807  0.0869        0.653        0.996\n   10     15       1    0.753  0.0963        0.586        0.968\n   13     12       1    0.690  0.1068        0.510        0.935\n   16     11       1    0.627  0.1141        0.439        0.896\n   22      7       1    0.538  0.1282        0.337        0.858\n   23      6       1    0.448  0.1346        0.249        0.807\n\n\nComparen esta tabla con Tabla 4.1A del Klein. La quinta columna con el error estándar corresponde a \\(\\sigma_S(t)\\). Un gráfico de \\(\\hat S(t)\\) es:\n\nplot(KM_6MP)\n\n\n\n\nPor default, los intervalos de confianza se calculan sobre el logaritmo de \\(S(t)\\). Para calcular los intervalos con la transformación log-log al 95% de confianza:\n\nKM_6MP_loglog <- survfit(surv_6MP~1,conf.type='log-log',)\n\nsummary(KM_6MP_loglog)\n\nCall: survfit(formula = surv_6MP ~ 1, conf.type = \"log-log\")\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    6     21       3    0.857  0.0764        0.620        0.952\n    7     17       1    0.807  0.0869        0.563        0.923\n   10     15       1    0.753  0.0963        0.503        0.889\n   13     12       1    0.690  0.1068        0.432        0.849\n   16     11       1    0.627  0.1141        0.368        0.805\n   22      7       1    0.538  0.1282        0.268        0.747\n   23      6       1    0.448  0.1346        0.188        0.680\n\n\nAsimismo se puede calcular bandas de confianza a través del paquete km.ci:\n\nlibrary(km.ci)\n\nbandasEP_KM_6MP <- km.ci(KM_6MP,conf.level = 0.95,tl = NA,tu = NA,\n                         method = 'epband')\nbandasHall_KM_6MP <- km.ci(KM_6MP,conf.level = 0.95,tl = NA,tu = NA,\n                         method = 'hall-wellner')\nplot(bandasEP_KM_6MP,lty = 2,lwd=2)\nlines(bandasHall_KM_6MP,lty = 3,lwd=2)\nlines(KM_6MP_loglog,lty=1,lwd=2)\nlines(KM_6MP_loglog,lty=4,lwd=2,conf.int = T)\nlinetype<-c(1, 2, 3, 4)\nlegend(0, .4, c(\"Kaplan-Meier\", \"EP\",\"Hall-Wellner\", \"Pointwise\"),\n       lty=(linetype))\n\n\n\n\ny también pueden utilizar la función ci del paquete survMisc.\nTambién se puede estimar \\(S(t)\\) a través del estimador de Nelson-Aalen:\n\nNA_6MP <- survfit(coxph(surv_6MP~1), type=\"aalen\")\n\nsummary(NA_6MP)\n\nCall: survfit(formula = coxph(surv_6MP ~ 1), type = \"aalen\")\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    6     21       3    0.867  0.0715        0.737        1.000\n    7     17       1    0.817  0.0828        0.670        0.997\n   10     15       1    0.765  0.0927        0.603        0.970\n   13     12       1    0.704  0.1035        0.527        0.939\n   16     11       1    0.642  0.1111        0.458        0.902\n   22      7       1    0.557  0.1249        0.359        0.864\n   23      6       1    0.471  0.1317        0.273        0.815\n\n\no bien se puede calcular el riesgo acumulado \\(H\\) y su varianza a través de la función sf de survMisc:\n\nt_6MP <- ten(surv_6MP)\nH_6MP <- sf(x = t_6MP$e,n = t_6MP$n,what = 'H')\nHv_6MP <- sf(x = t_6MP$e,n = t_6MP$n,what = 'Hv')\nTabla4_2 <- data.frame(tiempo=t_6MP$t,d=t_6MP$e,H_6MP,Hv_6MP)\nTabla4_2 <- Tabla4_2 %>% filter(d>0) %>% mutate(ErrorS=sqrt(Hv_6MP))\nround(Tabla4_2,4)\n\n  tiempo d  H_6MP Hv_6MP ErrorS\n1      6 3 0.1429 0.0068 0.0825\n2      7 1 0.2017 0.0103 0.1013\n3     10 1 0.2683 0.0147 0.1213\n4     13 1 0.3517 0.0217 0.1471\n5     16 1 0.4426 0.0299 0.1730\n6     22 1 0.5854 0.0503 0.2243\n7     23 1 0.7521 0.0781 0.2795\n\n\nComparen este resultado con la Tabla 4.2 del Klein.\nOtro aspecto a calcular es el tiempo medio de sobrevivencia de este grupo de pacientes. Para ello usamos la función print del paquete survival:\n\nprint(KM_6MP,print.rmean = T)\n\nCall: survfit(formula = surv_6MP ~ 1)\n\n      n events rmean* se(rmean) median 0.95LCL 0.95UCL\n[1,] 21      9   23.3      2.83     23      16      NA\n    * restricted mean with upper limit =  35 \n\n\ny al igual que en el Klein obtenemos un valor estimado de 23.29 días usando corrección de Efron, y un error estándar de 2.83 días. La mediana del tiempo de sobrevivencia usando la transformación log-log se puede obtener también con:\n\nquantile(KM_6MP_loglog,probs = c(0.5,0.15))\n\n$quantile\n50 15 \n23  7 \n\n$lower\n50 15 \n13  6 \n\n$upper\n50 15 \nNA 13 \n\n\nen donde también calculamos el cuantil 0.15 de la misma distribución junto con sus intervalos de confianza usando la definición de Klein. Note que para el caso de la mediana, la intersección con el límite superior del intervalo de confianza es nula, por eso nos da un NA.\nPara ilustrar el esquema de truncamiento por la izquierda y censura por la derecha, usaremos los datos de la sección 1.16 del Klein, en donde se tiene la edad de muerte (en meses) o su salida de 462 ancianos en un centro de retiro en California y además la edad cuando entraron al mismo centro. Los datos deben ser truncados para medir la mortalidad dentro del centro de retiro, y no debido a otras causas. Un vistazo de los datos es el siguiente:\n\ndata(\"channing\")\n\nhead(channing)\n\n  obs death ageentry  age time gender\n1   1     1     1042 1172  130      2\n2   2     1      921 1040  119      2\n3   3     1      885 1003  118      2\n4   4     1      901 1018  117      2\n5   5     1      808  932  124      2\n6   6     1      915 1004   89      2\n\n\nNote que la variable ageentry es la edad de entrada en meses a la casa de retiro y age es la edad de muerte o censura por la derecha. De nuevo el truncamiento por la izquierda es la mejor opción cuando se tiene un subconjunto de edades más limitado como el que se tiene en esta muestra. Los estimadores de Kaplan-Meier condicionados en 68 y 80 años para hombres y mujeres se ilustra a continuación (transformando los datos a datos anuales):\n\nchanning_Years <- channing %>% mutate(ageentry=ageentry/12,age=age/12)\nattach(channing_Years)\nKM_Chan_68 <- survfit(Surv(time = ageentry,time2 = age,event = death,\n                           type = 'counting')~gender,start.time=68,\n                      data=channing_Years)\n\nWarning in Surv(time = ageentry, time2 = age, event = death, type =\n\"counting\"): Stop time must be > start time, NA created\n\nplot(KM_Chan_68,conf.int = F,col = c(1,2))\nKM_Chan_80 <- survfit(Surv(time = ageentry,time2 = age,event = death,\n                           type = 'counting')~gender,start.time=80,\n                      data=channing_Years)\n\nWarning in Surv(time = ageentry, time2 = age, event = death, type =\n\"counting\"): Stop time must be > start time, NA created\n\nlines(KM_Chan_80,conf.int = F,col = c(3,4))\nlegend(90, 1, c(\"Male-68\", \"Female-68\",\"Male-80\", \"Female-80\"), \n       col=1:4,lty=1)\n\n\n\n\n\n\n2.7.2 Riesgos en competencia\n1384 Pacientes con gammapatía monoclonal de significado incierto (MGUS) a los cuales se les hace un seguimiento hasta la aparición de neoplasia de células plasmáticas (PCM) o la muerte (en meses). Por ejemplo, el estimador KM de la sobrevivencia (riesgo de muerte) de los pacientes clasificado por sexo es:\n\nmfit1 <- survfit(Surv(futime, death) ~ sex, data=mgus2)\nplot(mfit1, col=c(1,2), xscale=12, mark.time=FALSE, lwd=2,\n     xlab=\"Years post diagnosis\", ylab=\"Survival\")\nlegend(\"topright\", c(\"female\", \"male\"), col=1:2, lwd=2, bty='n')\n\n\n\n\nConsidere dos riesgos en competencia: PCM y muerte no relacionada a PCM.\n\nmgus3 <- mgus2 %>% mutate(etime=ifelse(pstat==0, futime,ptime),\n                          event = ifelse(pstat==0, 2*death, 1))\nmgus3$event <- factor(mgus3$event, 0:2, \n                      labels=c(\"censor\", \"pcm\", \"death\"))\ntable(mgus3$event)\n\n\ncensor    pcm  death \n   409    115    860 \n\n\ncon el cálculo correspondiente de la incidencia cumulada:\n\nmfit2 <- survfit(Surv(etime, event) ~ sex, data=mgus3)\nprint(mfit2, rmean=240, scale=12)\n\nCall: survfit(formula = Surv(etime, event) ~ sex, data = mgus3)\n\n               n nevent    rmean*\nsex=F, (s0)  631      0  9.853608\nsex=M, (s0)  753      0  8.675012\nsex=F, pcm   631     59  1.323284\nsex=M, pcm   753     56  1.064693\nsex=F, death 631    370  8.823108\nsex=M, death 753    490 10.260294\n   *restricted mean time in state (max time = 20 )\n\n\n\nplot(mfit2, col=c(1,2,1,2), lty=c(2,2,1,1),\n     mark.time=FALSE, lwd=2, xscale=12,\nxlab=\"Years post diagnosis\", ylab=\"Probability in State\")\nlegend(240, .6, c(\"death:female\", \"death:male\", \"pcm:female\", \"pcm:male\"),\ncol=c(1,2,1,2), lty=c(1,1,2,2), lwd=2, bty='n')\n\n\n\n\n\n\n2.7.3 Otros esquemas de muestreo\nEn esta segunda clase, se calculará empíricamente la función de sobrevivencia bajo tres distintos esquemas de muestreo.\n\n2.7.3.1 Censura doble (Censura por derecha y por izquierda)\nVamos a replicar aproximadamente el ejemplo 5.1 del Klein. A continuación la carga de datos:\n\nedades <- 10:18\neventos <- c(4,12,19,24,20,13,3,1,4)\ncensuras_izq <- c(0,0,0,1,2,3,2,3,1)\ncensuras_der <- c(0,0,2,15,24,18,14,6,0)\ntabla_5_1 <- data.frame(edades,censuras_izq,eventos,censuras_der)\ntabla_5_1\n\n  edades censuras_izq eventos censuras_der\n1     10            0       4            0\n2     11            0      12            0\n3     12            0      19            2\n4     13            1      24           15\n5     14            2      20           24\n6     15            3      13           18\n7     16            2       3           14\n8     17            3       1            6\n9     18            1       4            0\n\n\ncomparen esta tabla con la Tabla 5.1 del Klein. El ajuste de este tipo de datos se hace con el paquete survival con el algoritmo de Turnbull ajustado a través de EM (Método de Esperanza-Maximización). Antes, hay que convertir los datos a intervalos individualizados según el tipo de censura:\n\ncensuras_izq_v <- NULL\nfor(i in 1:dim(tabla_5_1)[1]){\n  if(tabla_5_1[i,2]>0){\n    censuras_izq_v <- rbind(censuras_izq_v,\n                            matrix(rep(c(-Inf,tabla_5_1[i,1]),\n                                       each=tabla_5_1[i,2]),\n                                   nrow=tabla_5_1[i,2]))\n    }\n}\neventos_v <- NULL\n\nfor(i in 1:dim(tabla_5_1)[1]){\n  if(tabla_5_1[i,3]>0){\n    eventos_v <- rbind(eventos_v,\n                       matrix(rep(c(tabla_5_1[i,1],\n                                    tabla_5_1[i,1]),\n                                  each=tabla_5_1[i,3]),\n                              nrow = tabla_5_1[i,3]))\n  }\n}\n\ncensuras_der_v <- NULL\n\nfor(i in 1:dim(tabla_5_1)[1]){\n  if(tabla_5_1[i,4]>0){\n    censuras_der_v <- rbind(censuras_der_v,\n                            matrix(rep(c(tabla_5_1[i,1],Inf),\n                          each=tabla_5_1[i,4]),nrow = tabla_5_1[i,4]))\n    }\n}\n\ndatos_5_1 <- rbind(censuras_der_v,censuras_izq_v,eventos_v)\nhead(datos_5_1)\n\n     [,1] [,2]\n[1,]   12  Inf\n[2,]   12  Inf\n[3,]   13  Inf\n[4,]   13  Inf\n[5,]   13  Inf\n[6,]   13  Inf\n\ntail(datos_5_1)\n\n       [,1] [,2]\n[186,]   16   16\n[187,]   17   17\n[188,]   18   18\n[189,]   18   18\n[190,]   18   18\n[191,]   18   18\n\n\ny ya con los datos convertidos se puede estimar la función de sobrevivencia:\n\nsurv_obj_5_1 <- Surv(time = datos_5_1[,1],time2 = datos_5_1[,2],\n                     type = 'interval2')\nS_5_1 <- survfit(surv_obj_5_1~1)\nsummary(S_5_1)\n\nCall: survfit(formula = surv_obj_5_1 ~ 1)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n   10 191.00    4.48    0.977  0.0104        0.956        0.998\n   11 186.52   13.43    0.906  0.0194        0.865        0.949\n   12 173.09   21.27    0.795  0.0241        0.738        0.857\n   13 149.82   26.91    0.652  0.0236        0.585        0.727\n   14 107.91   22.37    0.517  0.0200        0.446        0.599\n   15  61.54   14.65    0.394  0.0161        0.321        0.483\n   16  28.89    3.39    0.348  0.0149        0.273        0.443\n   17  11.50    1.19    0.312  0.0152        0.229        0.423\n   18   4.31    4.31    0.000  0.0000           NA           NA\n\nplot(S_5_1)\n\n\n\n\n\n\n2.7.3.2 Censura por intervalo\nEn el caso de censura por intervalo, se ilustrará el algoritmo de Turnbull-EM con los datos del ejemplo 5.2. Estos datos consisten en la comparación de dos tratamientos de cáncer de mama a nivel de 95 mujeres (Variable treat: 1-Radioterapia, 2-Radioterapia+quimioterapia). Durante visitas periodicas, los médicos midieron el deterioro cosmético en el seno de cada mujer bajo los dos tratamientos. Lo único que se guarda en cada caso en el periodo de tiempo en donde el deterioro fue severo o moderado entre dos visitas sucesivas. El tiempo se mide en meses.\n\ndata(\"bcdeter\")\nhead(bcdeter)\n\n  lower upper treat\n1     0     5     1\n2     0     7     1\n3     0     8     1\n4     4    11     1\n5     5    11     1\n6     5    12     1\n\n\nLa estimación de la función de sobrevivencia para el riesgo de deterioro se estima por tipo de tratamiento:\n\nsurv_obj_5_2 <- Surv(time = bcdeter$lower,time2 = bcdeter$upper,\n                     type = 'interval2')\nS_5_2 <- survfit(surv_obj_5_2~treat,data = bcdeter)\nsummary(S_5_2)\n\nCall: survfit(formula = surv_obj_5_2 ~ treat, data = bcdeter)\n\n                treat=1 \n time n.risk  n.event survival std.err lower 95% CI upper 95% CI\n  4.5 46.000 2.13e+00    0.954  0.0431        0.869        1.000\n  6.5 43.868 1.54e+00    0.920  0.0505        0.819        1.000\n  7.5 42.332 4.08e+00    0.832  0.0769        0.669        1.000\n 11.5 38.255 3.25e+00    0.761  0.0791        0.582        0.994\n 15.5 34.000 2.27e-15    0.761  0.0791        0.582        0.994\n 17.5 33.000 9.07e-04    0.761  0.0791        0.582        0.994\n 24.5 28.999 3.53e+00    0.668  0.0783        0.474        0.942\n 25.5 25.469 3.11e-08    0.668  0.0783        0.474        0.942\n 33.5 23.469 2.87e+00    0.586  0.0705        0.392        0.876\n 34.5 19.596 1.85e-10    0.586  0.0705        0.392        0.876\n 36.5 17.596 1.43e-04    0.586  0.0705        0.392        0.876\n 39.0 13.596 2.79e+00    0.466  0.0594        0.272        0.797\n 42.0  9.801 6.71e-03    0.466  0.0594        0.272        0.796\n 47.0  0.794 7.94e-01    0.000  0.0000           NA           NA\n\n                treat=2 \n time n.risk  n.event survival std.err lower 95% CI upper 95% CI\n  4.5  49.00 2.08e+00    0.958 0.04029       0.8786        1.000\n  6.5  46.92 2.08e+00    0.915 0.05401       0.8065        1.000\n  8.5  44.84 2.55e-05    0.915 0.05401       0.8065        1.000\n 11.5  42.84 3.15e+00    0.848 0.07262       0.6955        1.000\n 12.5  39.69 2.40e-06    0.848 0.07262       0.6955        1.000\n 16.5  36.69 6.28e+00    0.703 0.09750       0.4773        1.000\n 18.5  30.41 4.99e+00    0.588 0.08670       0.3591        0.961\n 19.5  25.43 5.52e+00    0.460 0.06488       0.2522        0.839\n 21.5  18.91 4.19e-05    0.460 0.06488       0.2522        0.839\n 22.5  18.91 6.10e-06    0.460 0.06488       0.2522        0.839\n 23.5  17.91 1.50e-07    0.460 0.06488       0.2522        0.839\n 24.5  17.91 5.05e+00    0.330 0.03922       0.1632        0.668\n 30.5  12.85 3.33e-02    0.329 0.03907       0.1626        0.667\n 31.5  11.82 1.07e-07    0.329 0.03907       0.1626        0.667\n 34.0  10.82 3.29e+00    0.229 0.02279       0.0979        0.536\n 34.5   5.53 1.93e-11    0.229 0.02279       0.0979        0.536\n 35.5   4.53 2.40e+00    0.108 0.00806       0.0275        0.421\n 48.0   2.13 2.13e+00    0.000 0.00000           NA           NA\n\n\ny gráficamente:\n\nplot(S_5_2,col = c(1,2))\nlegend(0,0.4,legend = c('T-1','T-2'),col=c(1,2),lty=1)\n\n\n\n\n\n\n2.7.3.3 Estimación de \\(S(x)\\) con una tabla de vida de un cohorte .\nA manera de resumen (les recomiendo que estudien esta sección por su propia cuenta, ya que no presenta diferencias sustanciales con respecto al resto del curso), estos son los principales indicadores que se calculan en una tabla de vida de forma no-paramétrica:\n\nCohorte: grupo de individuos con un origen en común en cuanto al tiempo en el cual un evento es calculado (por ejemplo, la misma edad al momento de inicial el estudio)\nSe considera intervalos disjuntos \\(I_j=(a_{j-1},a_j]\\), \\(j=1,\\ldots,k+1\\) con \\(a_0=0\\) y \\(a_{k+1}=\\infty\\), en donde cada individuo del cohorte tendrá el evento de interés.\nSea \\(Y_j'\\): número de individuos que no han experimentado el evento en el \\(j\\)-ésimo intervalo.\n\\(W_j\\): número de individuos del cohorte que no presentan el evento en el intervalo \\(j\\)-ésimo (censuras).\n\\(d_j\\): número de individuos del cohorte que presentan el evento en el intervalo \\(j\\)-ésimo (eventos).\nLa población en riesgo del intervalo \\(j\\)-ésimo se estima asumiendo una distribución uniforme de las censuras:\n\n\\[\\begin{align*}\nY_j=Y_j'-W_j/2\n\\end{align*}\\]\n\nLa función de sobrevivencia estimada es análoga al estimador de Kaplan-Meier:\n\n\\[\\begin{align*}\n\\hat S(a_j)=\\prod_{i=1}^j\\left(1-d_i/Y_i\\right)\n\\end{align*}\\]\n\nLa densidad estimada en el punto medio del intervalo \\(j\\)-ésimo (\\(a_{mj}=(a_j+a_{j-1})/2\\)) es:\n\n\\[\\begin{align*}\n\\hat f(a_{mj})=\\frac{\\hat S(a_{j-1})-\\hat S(a_j)}{a_{j-1}-a_j}\n\\end{align*}\\]\n\nLa tasa de riesgo estimada en el punto medio del intervalo \\(j\\)-ésimo:\n\n\\[\\begin{align*}\n\\hat h(a_{mj})&=\\frac{\\hat f(a_{mj})}{\\hat S(a_{mj})}\\\\\n&=\\frac{2\\hat f(a_{mj})}{\\hat S(a_{j})+\\hat S(a_{j-1})}\n\\end{align*}\\]\nusando interpolación lineal para calcular \\(\\hat S(a_{mj})\\).\n\nLas probabilidad condicionales de sobrevivencia en el \\(j\\)-ésimo intervalo es:\n\n\\[\\begin{align*}\n\\hat p_j=1-\\hat q_j=1-d_j/Y_j\n\\end{align*}\\]\ndonde \\(\\hat q_j\\) es la probabilidad condicional de ocurrencia del evento en el mismo intervalo.\nVamos a replicar el ejemplo 5.4 en donde se tiene datos de 927 recién nacidos cuyas madres los alimentaron con lactancia materna. La duración de lactancia materna se midió en semanas, y el evento de interés es la interrupción de la lactancia materna. En cada intervalo también hubo salidas del estudio.\nExtraemos los datos y hacemos el cálculo de la tabla de sobreviencia del cohorte:\n\ndata(\"bfeed\")\nlibrary(tidyverse)\nhead(bfeed)\n\n  duration delta race poverty smoke alcohol agemth ybirth yschool pc3mth\n1       16     1    1       0     0       1     24     82      14      0\n2        1     1    1       0     1       0     26     85      12      0\n3        4     0    1       0     0       0     25     85      12      0\n4        3     1    1       0     1       1     21     85       9      0\n5       36     1    1       0     1       0     22     82      12      0\n6       36     1    1       0     0       0     18     82      11      0\n\nninit <- dim(bfeed)[1]\ntis <- c(0,2,3,5,7,11,17,25,37,53,NA)\ntis_2 <- c(0,2,3,5,7,11,17,25,37,53,Inf)\npretablas <- bfeed %>% dplyr::select(duration,delta) %>%\n  mutate(intervalo=cut(duration,breaks = tis_2))%>%\n  group_by(delta,intervalo)%>%\n  summarise(conteo=n())\n\n`summarise()` has grouped output by 'delta'. You can override using the\n`.groups` argument.\n\ntabla_resumen <- data.frame(intervalos=unique(pretablas$intervalo),\n                            eventos=pretablas$conteo[pretablas$delta==1],\n                            censuras=c(pretablas$conteo[pretablas$delta==0],\n                                       rep(0,3)))\n\ntabla_resumen$Yprima <- 0\ntabla_resumen$Yprima[1] <-ninit\n\nfor(i in 2:dim(tabla_resumen)[1]){\n  tabla_resumen$Yprima[i]<-tabla_resumen$Yprima[i-1]-\n    tabla_resumen$eventos[i]-\n    tabla_resumen$censuras[i]\n}\n\nLa tabla resultante y el cálculo de la función de sobrevivencia:\n\nshow(tabla_resumen)\n\n   intervalos eventos censuras Yprima\n1       (0,2]     148        5    927\n2       (2,3]      49        3    875\n3       (3,5]      89        6    780\n4       (5,7]      71        9    700\n5      (7,11]      96        4    600\n6     (11,17]     147        5    448\n7     (17,25]     107        3    338\n8     (25,37]      73        0    265\n9     (37,53]      85        0    180\n10   (53,Inf]      27        0    153\n\ntabla_vida <- lifetab(tis,ninit,\n                      nlost = tabla_resumen$censuras,\n                      nevent = tabla_resumen$eventos)\nshow(tabla_vida)\n\n      nsubs nlost nrisk nevent       surv         pdf     hazard     se.surv\n0-2     927     5 924.5    148 1.00000000 0.080043267 0.08700764 0.000000000\n2-3     774     3 772.5     49 0.83991347 0.053276065 0.06550802 0.012059831\n3-5     722     6 719.0     89 0.78663740 0.048686181 0.06597480 0.013484256\n5-7     627     9 622.5     71 0.68926504 0.039307484 0.06047700 0.015262465\n7-11    547     4 545.0     96 0.61065007 0.026891012 0.04828974 0.016123102\n11-17   447     5 444.5    147 0.50308602 0.027729151 0.06603774 0.016605169\n17-25   295     3 293.5    107 0.33671112 0.015344161 0.05572917 0.015796965\n25-37   185     0 185.0     73 0.21395783 0.007035550 0.04096521 0.013792960\n37-53   112     0 112.0     85 0.12953123 0.006144059 0.07643885 0.011350812\n53-NA    27     0  27.0     27 0.03122628          NA         NA 0.005907255\n            se.pdf   se.hazard\n0-2   0.0060299154 0.007124861\n2-3   0.0074051486 0.009353268\n3-5   0.0049023311 0.006978078\n5-7   0.0044762921 0.007164162\n7-11  0.0025903363 0.004905511\n11-17 0.0020829076 0.005338742\n17-25 0.0013843547 0.005251978\n25-37 0.0007849941 0.004647529\n37-53 0.0006300324 0.006560105\n53-NA           NA          NA\n\n\nLas columnas de desviaciones estándar de las función de sobrevivencia, tasa de riesgo y función de densidad se calculan según las fórmulas 5.4.5, 5.4.6 y 5.4.7 del Klein.\n\n\n\n\nTsai, Wei-Yann, Nicholas P Jewell, and Mei-Cheng Wang. 1987. “A Note on the Product-Limit Estimator Under Right Censoring and Left Truncation.” Biometrika 74 (4): 883–86."
  },
  {
    "objectID": "PH.html#pruebas-de-hipótesis-de-una-muestra",
    "href": "PH.html#pruebas-de-hipótesis-de-una-muestra",
    "title": "3  Pruebas de Hipótesis",
    "section": "3.1 Pruebas de Hipótesis de una muestra",
    "text": "3.1 Pruebas de Hipótesis de una muestra\nSupongamos una muestra con censura de tamaño \\(n\\). Se quiere probar las siguientes hipótesis:\n\n\\(H_0:\\) La tasa de riesgo de la población es \\(h_0(t)\\) para todo \\(t \\leq \\tau\\).\n\\(H_1:\\) La tasa de riesgo de la población es distinta a \\(h_0(t)\\) para algún \\(t \\leq \\tau\\).\n\nDonde \\(h_0(t)\\) es una tasa de riesgo conocida en \\([0,\\tau]\\) y \\(\\tau\\): máximo de los tiempo de estudio observados.\nConsidere el estimador de Nelson-Aalen de \\(H(t)\\):\n\\[\\hat H(t)=\\sum_{t_i\\leq t}\\frac{d_i}{Y(t_i)}\\] donde \\(d_i:\\) número de eventos en los tiempos observados \\(t_1<t_2<\\cdots < t_D\\) y \\(Y(t_i)\\): número de individuos en riesgo al tiempo \\(t_i\\). Un estimador (muy crudo) de \\(h(t_i)\\) es\n\\[\\frac{d_i}{Y(t_i)}\\]\ny este estadístico nos permite definir un estadístico de prueba que busca comparar las tasas de riesgo observadas y esperadas usado diferencias ponderadas. Sea \\(W(t)\\): función de pesos tal que \\(W(t)=0\\) si \\(Y(t)=0\\). Defina el siguiente estadístico de prueba:\n\\[Z(\\tau)=O(\\tau)-E(\\tau)=\\sum_{i=1}^DW(t_i)\\frac{d_i}{Y(t_i)}-\\int_0^\\tau W(s)h_0(s)ds\\] Bajo \\(H_0\\), la varianza de \\(Z(\\tau)\\) es:\n\\[V[Z(\\tau)]=\\int_0^\\tau W^2(s)\\frac{h_0(s)}{Y(s)}ds\\] Si \\(n\\) es grande:\n\\[\\frac{Z(\\tau)^2}{V[Z(\\tau)]}\\underset{H_0}{\\sim}\\chi_1^2\\] Por lo tanto se rechaza \\(H_0\\) si \\(\\frac{Z(\\tau)^2}{V[Z(\\tau)]}>\\chi_{1,1-\\alpha}^2\\) bajo un nivel de significancia de \\(\\alpha\\).\nSi se quiere probar \\(H_0: h(t)>h_0(t)\\) entonces se rechaza \\(H_0\\) si:\n\\[\\frac{Z(\\tau)}{\\sqrt{V[Z(\\tau)]}}>z_{1-\\alpha}\\] con nivel \\(\\alpha\\). La función de pesos se puede seleccionar de muchas formas, por ejemplo la forma más usual es (Gehan):\n\\[W(t)=Y(t)\\] con lo cual se genera una prueba de rango (Prueba de bondad de ajuste no-paramétrica). Otros casos: (Harrington-Fleming):\n\\[W(t)=Y(t)S_0(t)^p[1-S_0(t)]^q, \\qquad p,q\\geq 0\\] y \\(S_0(t)=\\exp[-H_0(t)]\\).\nEn el caso de truncamiento por la izquierda, sea:\n\n\\(T_j\\): tiempo de ocurrencia del evento en el \\(j\\)-ésimo paciente.\n\\(L_j\\): tiempo de truncamiento por la izquierda en el \\(j\\)-ésimo paciente. Este tiempo se puede interpretar como el momento de entrada en el estudio.\n\nSi se usa la opción \\(W(t)=Y(t)\\), entonces:\n\\[O(\\tau)=\\sum_{i=1}^D d_i\\]\ny\n\\[E(\\tau)=\\int_0^\\tau Y(s)h_0(s)ds = V[Z(\\tau)]=\\sum_{j=1}^n H_0(T_j)-H_0(L_j)\\]"
  },
  {
    "objectID": "PH.html#pruebas-de-hipótesis-para-más-de-una-muestra",
    "href": "PH.html#pruebas-de-hipótesis-para-más-de-una-muestra",
    "title": "3  Pruebas de Hipótesis",
    "section": "3.2 Pruebas de Hipótesis para más de una muestra",
    "text": "3.2 Pruebas de Hipótesis para más de una muestra\nQueremos probar las siguientes alternativas:\n\n\\(H_0: h_1(t)=h_2(t)=\\cdots=h_k(t)\\) para todo \\(t\\leq \\tau\\)\n\\(H_1\\): al menos uno de los \\(h_j(t)\\) es diferente para algún \\(t\\leq \\tau\\).\n\nSea \\(\\tau\\): tiempo máximo en donde todos los grupos tienen al menos un individuo en riesgo. Normalmente \\(\\tau=\\min_k \\{\\max \\{ \\text{tiempos de estudio}\\}\\}\\).\nLos datos en este caso constituyen muestras independientes de datos censurados, truncados por la izquierda para cada una de las \\(k\\) poblaciones. Sea \\(t_1<t_2<\\cdots <t_D\\) los distintos tiempos de ocurrencia del evento de interés en la muestra combinada.\nEn tiempo \\(t_i\\) se observa \\(d_{ij}\\) eventos en la \\(j\\)-ésima muestra con \\(Y_{ij}\\): individuos en riesgo de la población \\(j\\)-ésima (\\(j=1,\\ldots,k\\), \\(i=1,\\ldots,D\\)).\nAdemás:\n\\[d_i=\\sum_{j=1}^k d_{ij}\\qquad \\text{y} \\qquad Y_i=\\sum_{j=1}^k Y_{ij}\\] Si \\(H_0\\) es cierto, un estimador de la tasa de riesgo para la población \\(j\\)-ésima es el estimador combinado:\n\\[\\frac{d_i}{Y_i}\\]\nSi \\(W_j(t_i)\\) denota una función de pesos tal que es cero si \\(Y_{ij}=0\\), entonces defina el estadístico:\n\\[Z_j(\\tau)=\\sum_{j=1}^D W_j(t_i)\\left[\\frac{d_{ij}}{Y_{ij}}-\\frac{d_i}{Y_i}\\right]\\] Interpretación del estadístico \\(Z_j(\\tau)\\): valores altos dan evidencia de que \\(H_0\\) no es cierto.\nEn general, se simplifica la ponderación de \\(Z_j\\) al escoger:\n\\[W_j(t_i)=Y_{ij}W(t_i)\\] en donde \\(W(t_i)\\) es un peso en común para toda la muestra combinada. En este caso la diferencia ponderada quedaría:\n\\[Z_j(\\tau)=\\sum_{i=1}^D W(t_i)\\left[d_{ij}-\\underbrace{Y_{ij}\\left(\\frac{d_i}{Y_i}\\right)}_{**}\\right]\\] donde \\(**\\) es el número de eventos esperados bajo \\(H_0\\). La varianza de \\(Z_j(\\tau)\\) es:\n\\[\\hat \\sigma_{jj}=\\sum_{i=1}^D W(t_i)^2\\frac{Y_{ij}}{Y_i}\\left(1-\\frac{Y_{ij}}{Y_i}\\right)\\left(\\frac{Y_i-d_i}{Y_i-1}\\right)d_i\\] para \\(j=1,\\ldots,k\\). La covarianza entre \\(Z_j(\\tau)\\) y \\(Z_g(\\tau)\\) es:\n\\[\\hat \\sigma_{jg}=-\\sum_{i=1}^D W(t_i)^2\\frac{Y_{ij}}{Y_i}\\frac{Y_{ig}}{Y_i}\\left(\\frac{Y_i-d_i}{Y_i-1}\\right)d_i\\] El término \\(\\frac{Y_i-d_i}{Y_i-1}\\) es igual a 1 si no hay individuos que tengan un tiempo en común de ocurrencia del evento, por lo tanto se puede considerar este término como un factor de correción a la estructura de varianza ante la presencia de múltiples ocurrencias en un mismo tiempo (ties).\nNote que \\((Z_1(\\tau),\\ldots,Z_k(\\tau))\\) cumple que:\n\\[\\sum_{j=1}^k Z_j(\\tau)=0\\]\nSeleccionamos entonces \\(k-1\\) de las poblaciones y sea \\(\\Sigma\\) la matriz de varianza-covarianza con elementos \\(\\hat \\sigma_{jg}\\). Se define el estadístico:\n\\[\\chi^2=(Z_1(\\tau),\\ldots,Z_{k-1}(\\tau))\\Sigma^{-1}(Z_1(\\tau),\\ldots,Z_{k-1}(\\tau))^T\\]\nBajo \\(H_0\\) se tiene que \\(\\chi^2\\sim \\chi_{k-1}^2\\). En el caso en que \\(k=2\\):\n\\[\\begin{align*}\n    Z&=\\frac{\\sum_{i=1}^D W(t_i)\\left[d_{i1}-Y_{i1}\\left(\\frac{d_i}{Y_i}\\right)\\right]}{\\sqrt{\\sum_{i=1}^D W(t_i)^2\\frac{Y_{i1}}{Y_i}\\left(1-\\frac{Y_{i1}}{Y_i}\\right)\\left(\\frac{Y_i-d_i}{Y_i-1}\\right)}}\\\\\n    &\\underset{H_0}{\\sim} N(0,1)\n\\end{align*}\\]\nPor lo tanto se rechaza \\(H_0: h_1(t)=h_2(t)\\) si \\(|Z|>z_{1-\\alpha/2}\\) o se rechaza \\(H_0: h_1(t)>h_2(t)\\) si \\(Z>z_{1-\\alpha}\\).\nEscogencias de \\(W(t)\\):\n1- \\(W(t)=1\\): Prueba de log-rango.\n2- \\(W(t_i)=Y_i\\): similar a la prueba de Wilcoxon-Mann-Whitney.\n3- \\(W(t_i)=Y_i^{1/2}\\) (otorga más peso donde hay más datos).\n4- Considere\n\\[\\tilde S(t)=\\prod_{t_i\\leq t}\\left(1-\\frac{d_i}{Y_i+1}\\right)\\] tome \\(W(t_i)=\\tilde S(t_i)\\) (Peto-Peto, (1972)).\n5- Modificación de Andersen (1982) (Peto-Peto Modificada)\n\\[W(t_i)=\\frac{\\tilde S(t_i)Y_i}{Y_i+1}\\] 6- Fleming and Harrington\nSea \\(\\hat S(t)\\) el estimador de Kaplan-Meier usando la muestra combinada. Defina:\n\\[W_{p,q}(t_i)=\\hat S(t_{i-1})^p[1-\\hat S(t_{i-1})]^q, \\qquad p\\geq 0, q\\geq 0\\]\n2 casos: \\(p=q=0\\) (log-rango) y \\(p=1, q=0\\) (Mann-Whitney-Wilcoxon)"
  },
  {
    "objectID": "PH.html#pruebas-de-tendencia",
    "href": "PH.html#pruebas-de-tendencia",
    "title": "3  Pruebas de Hipótesis",
    "section": "3.3 Pruebas de tendencia",
    "text": "3.3 Pruebas de tendencia\nPrincipal objetivo: detectar alternativas ordenadas a la hipótesis nula:\n\n\\(H_0:h_1(t)=h_2(t)=\\cdots=h_k(t)\\) para todo \\(t\\leq \\tau\\)\n\\(H_1: h_1(t)\\leq h_2(t)\\leq \\cdots\\leq h_k(t)\\) para \\(t\\leq \\tau\\) con al menos una desigualdad estricta.\n\nNote que\n\\[h_1(t)\\leq \\cdots \\leq h_k(t) \\Leftrightarrow S_1(t)\\geq \\cdots \\geq S_k(t)\\] Usando la notación anterior, sea \\(a_1<a_2<\\cdots <a_k\\) una secuencia de scores (usualmente \\(a_j=j\\) o algún estadístico representativo para la población \\(j\\)-ésima):\n\\[Z=\\frac{\\sum_{j=1}^k a_jZ_j(\\tau)}{\\sqrt{\\sum_{j=1}^k \\sum_{g=1}^k a_ja_g\\hat \\sigma_{jg}}}\\underset{H_0}{\\sim} N(0,1)\\]"
  },
  {
    "objectID": "PH.html#pruebas-estratificadas",
    "href": "PH.html#pruebas-estratificadas",
    "title": "3  Pruebas de Hipótesis",
    "section": "3.4 Pruebas estratificadas",
    "text": "3.4 Pruebas estratificadas\nSuponga que se tiene un conjunto de covariables que definen \\(M\\) estados o configuraciones sobre el conjunto de \\(k\\) poblaciones. Se quiere probar:\n\\[H_0: h_{1s}(t)=h_{2s}(t)=\\cdots=h_{ks}(t), \\qquad s=1,\\ldots,M\\qquad t<\\tau\\] Para un estrato \\(s\\) fijo, sea \\(Z_{js}(\\tau)\\):\n\\[Z_{js}(\\tau)=\\sum_{i=1}^DW(t_i)\\left[\\underbrace{d_{ij}-Y_{ij}\\left(\\frac{d_i}{Y_i}\\right)}_{\\text{solamente estrato s}}\\right]\\]\ny \\(\\hat \\Sigma_s\\) es la matriz de varianza-covarianza de \\(Z_{js}\\). La prueba estratificada se construye definiendo:\n\\[Z_{j.}(\\tau)=\\sum_{s=1}^MZ_{js}(\\tau)  \\qquad \\text{y} \\qquad \\hat \\sigma_{jg.}=\\sum_{s=1}^M \\hat \\sigma_{jgs}\\]\ny \\(\\hat \\sigma_{jgs}\\) es la entrada \\(jg\\) del \\(\\hat \\Sigma_s\\). El estadístico de prueba estaría dado por:\n\\[X_.=(Z_{1.}(\\tau),\\ldots,Z_{k-1,.}(\\tau))\\Sigma_.^{-1}(Z_{1.}(\\tau),\\ldots,Z_{k-1,.}(\\tau))^T\\]\ndonde \\(\\Sigma_.\\) es la matriz con entradas \\(\\hat \\sigma_{jg.}\\). Bajo \\(H_0\\):\n\\[X_.\\sim \\chi_{k-1}^2\\]\nEn el caso de dos muestras el estadístico se puede escribir:\n\\[\\frac{\\sum_{s=1}^M Z_{1s}(\\tau)}{\\sqrt{\\sum_{s=1}^M \\hat \\sigma_{11s}}}\\underset{H_0}{\\sim}N(0,1)\\] y este estadístico también permite probar hipótesis de una cola en el caso de dos muestras.\nOtro tipo de prueba basada en pruebas estratificadas es una prueba pareada. Si \\((T_{1i},T_{2i})\\) son pares de eventos de interés con indicadores de eventos \\((\\delta_{1i},\\delta_{2i})\\) para \\(i=1,\\ldots,M\\). Queremos probar las hipótesis:\n\\[H_0: h_{1i}(t)=h_{2i}(t), \\qquad i=1,\\ldots,M\\] (misma interpretación en términos de estratos). En este caso el estadístico \\(Z_{js}\\) es: (\\(j=1,2\\))\n\\[\\begin{align*}\nZ_{1i}(\\tau)=\n    \\begin{cases}\n        W(T_{1i})\\left(1-\\frac 1 2\\right)=\\frac{W(T_{1i})}{2} & \\text{bajo Escenario A}\\\\\n        W(T_{2i})\\left(0-\\frac 1 2\\right)=-\\frac{W(T_{2i})}{2} & \\text{bajo Escenario B}\\\\\n        0 & \\text{otro caso}\n    \\end{cases}\n\\end{align*}\\]\n\nEscenario A: si \\(T_{1i}<T_{2i}\\), \\(\\delta_{1i}=1\\) o \\(T_{1i}=T_{2i}\\), \\(\\delta_{1i}=1\\), \\(\\delta_{2i}=0\\).\nEscenario B: \\(T_{2i}<T_{1i}\\), \\(\\delta_{2i}=1\\) o \\(T_{1i}=T_{2i}\\), \\(\\delta_{2i}=1\\), \\(\\delta_{1i}=0\\).\n\ny\n\\[\\begin{align*}\n\\hat \\sigma_{11i}=\n    \\begin{cases}\n        W(T_{1i})^2/4 & \\text{bajo Escenario A}\\\\\n        W(T_{2i})^2/4 & \\text{bajo Escenario B}\\\\\n        0 & \\text{otro caso}\n    \\end{cases}\n\\end{align*}\\]\nSumando sobre los estratos (\\(i=1,\\ldots,M\\)):\n\\[Z_{1.}(\\tau)=w \\cdot \\frac{D_1-D_2}{2}\\] y\n\\[\\hat \\sigma_{11.}=w^2\\cdot \\frac{D_1+D_2}{4}\\] donde:\n\n\\(D_1\\): número de parejas en donde el evento aparece en el sujeto de la primera muestra.\n\\(D_2\\): número de parejas en donde el evento aparece en el sujeto de la segunda muestra.\n\\(w\\): peso evaluado en el tiempo más pequeño de ocurrencia del evento.\n\nEntonces:\n\\[\\frac{Z_{1.}(\\tau)}{\\sqrt{\\hat \\sigma_{11.}}}=\\frac{D_1-D_2}{\\sqrt{D_1+D_2}}\\underset{H_0}{\\sim}N(0,1)\\]"
  },
  {
    "objectID": "PH.html#pruebas-de-renyi",
    "href": "PH.html#pruebas-de-renyi",
    "title": "3  Pruebas de Hipótesis",
    "section": "3.5 Pruebas de Renyi",
    "text": "3.5 Pruebas de Renyi\nInconveniente de las pruebas anteriores: algunas veces las diferencias en las tasas de riesgo son simétricas (un primer grupo sobrepasa al otro en riesgo un número similar de veces al que el primer grupo es sobrepasado por el otro grupo). Esto provoca problemas de potencia en la prueba. Solución: utilizar otras medidas de comparación.\nSuponga que se tiene dos muestras independientes de tamaño \\(n_1\\) y \\(n_2\\) respectivamente.\nSea \\(n=n_1+n_2\\) y \\(t_1<t_2<\\cdots<t_D\\) los distintos tiempo de ocurrencia en la muestra combinada y \\(Y_{ij}\\): número de individuos en riesgo en tiempo \\(t_i\\) (\\(j=1,2\\)). Al igual que antes \\(Y_i=Y_{i1}+Y_{i2}\\), \\(d_i=d_{i1}+d_{i2}\\) (eventos ocurridos). Sea \\(W(t)\\) la función de pesos (como las consideradas anteriormente). En este caso se calcula:\n\\[Z(t_i)=\\sum_{t_k\\leq t_i}W(t_k)\\left[d_{k1}-Y_{k1}\\left(\\frac{d_k}{Y_k}\\right)\\right]\\qquad i=1,\\ldots,D\\] y\n\\[\\sigma(\\tau)=\\sum_{t_k\\leq \\tau}W(t_k)^2\\left(\\frac{Y_{k1}}{Y_k}\\right)\\left(\\frac{Y_{k2}}{Y_k}\\right)\\left(\\frac{Y_{k}-d_k}{Y_k-1}\\right)d_k\\] donde \\(\\tau\\) es el \\(t_k\\) máximo tal que \\(Y_{k1}, Y_{k2}>0\\).\nBajo la hipótesis:\n\n\\(H_0: h_1(t)=h_2(t),\\qquad t<\\tau\\)\n\\(H_1: h_1(t)\\neq h_2(t)\\)\n\nel estadístico de prueba es:\n\\[Q=\\sup_{t\\leq \\tau}\\frac{|Z(t)|}{\\sigma(\\tau)}\\] cuya distribución bajo \\(H_0\\) se aproxima con la distribución de \\(\\sup_{0\\leq x\\leq 1}|B(x)|\\) donde \\(B\\) es un proceso Browniano estándar."
  },
  {
    "objectID": "PH.html#pruebas-en-un-punto-fijo-en-el-tiempo",
    "href": "PH.html#pruebas-en-un-punto-fijo-en-el-tiempo",
    "title": "3  Pruebas de Hipótesis",
    "section": "3.6 Pruebas en un punto fijo en el tiempo",
    "text": "3.6 Pruebas en un punto fijo en el tiempo\nObjetivo: hacer comparaciones de funciones de sobrevivencia o curvas de incidencia de \\(k\\) poblaciones en un punto fijo en el tiempo \\(t_0\\).\nSea \\(\\Theta^T=(\\theta_1,\\ldots,\\theta_p)\\) un vector de parámetros de dimensión \\(p\\). Definimos un contraste como un conjunto de coeficientes \\(c=(c_1,\\ldots,c_p)\\) que definen una combinación lineal de parámetros \\(\\theta^c=c\\Theta=c_1\\theta_1+\\cdots+c_p\\theta_p\\).\nEjemplo: si \\(p=3\\) y \\(c=(1,-1,0)\\), entonces \\(\\theta^c=\\theta_1-\\theta_2\\). Decir que \\(H_0: \\theta^c=0\\) es equivalente a decir que \\(H_0:\\theta_1=\\theta_2\\).\nSuponga que se tiene \\(q\\) contrastes \\(c_k=(c_{k1},\\ldots,c_{kp})\\) para \\(k=1,\\ldots,q\\) y se tiene que probar las hipótesis:\n\\[H_0: c_k\\Theta=0\\qquad \\forall k\\] Defina la matriz de contrastes:\n\\[\\begin{align*}\nC=\n    \\begin{pmatrix}\n    c_1\\\\\n    \\vdots \\\\\n    c_q\n    \\end{pmatrix}\n\\end{align*}\\]\nSi \\(\\hat \\theta_j\\) es el estimador de \\(\\theta_j\\) con matriz de varianza \\(V\\) (con entradas \\(\\hat V(\\hat \\theta_j,\\hat \\theta_k)\\)) (\\(V\\): varianza). Entonces si se quiere probar:\n\\[H_0: C\\Theta^T=0\\]\nEl estadístico de prueba es:\n\\[X^2=[C\\Theta]^T[CVC^T]^{-1}[C\\Theta]\\underset{H_0}{\\sim}\\chi_q^2\\] Caso particular:\n\n\\(H_0: S_1(t_0)=S_2(t_0)=\\cdots S_k(t_0)\\) vs \\(H_1\\): al menos uno de los \\(S_j(t_0)\\) es distinto.\n\\(H_0: CI_1(t_0)=CI_2(t_0)=\\cdots =CI_k(t_0)\\) vs \\(H_1\\): al menos uno de los \\(CI_j(t_0)\\) es distinto.\n\nSea \\(\\hat \\theta_j\\) el estimador de Kaplan-Meier de \\(S_j(t_0)\\) o la curva de incidencia estimada en \\(t_0\\). Sea\n\\[\\begin{align*}\nC=\n    \\begin{pmatrix}\n      1 & 0 & 0 & \\cdots & 0 & -1 \\\\\n      0 & 1 & 0 & \\cdots & 0 & -1 \\\\\n      \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n      0 & 0 & 0 & \\cdots & 1 & -1\n    \\end{pmatrix}\n\\end{align*}\\]\ny \\(V=\\text{diag}(\\hat V(\\hat \\theta_k(t_0)))\\). Entonces:\n\\[\\begin{align*}\nX^2&=\n    \\begin{pmatrix}\n        \\hat \\theta_1-\\hat \\theta_p\\\\\n        \\vdots\\\\\n        \\hat \\theta_{p-1}-\\hat \\theta_p\n    \\end{pmatrix}^T\n    \\begin{pmatrix}\n        V_1+V_p & V_p & \\cdots & V_p \\\\\n        V_p & V_2+V_p & \\cdots & V_p \\\\\n        \\vdots & \\vdots & \\vdots & \\vdots \\\\\n        V_p & V_p & \\cdots & V_{p-1}+V_p\n    \\end{pmatrix}^{-1}\n    \\begin{pmatrix}\n        \\hat \\theta_1-\\hat \\theta_p\\\\\n        \\vdots\\\\\n        \\hat \\theta_{p-1}-\\hat \\theta_p\n    \\end{pmatrix}\\\\\n    & \\underset{H_0}{\\sim} \\chi_{p-1}^2\n\\end{align*}\\]\nCaso particular (p=2):\nCon la hipótesis nula \\(H_0: S_1(t_0)=S_2(t_0)\\):\n\\[Z=\\frac{\\hat S_1(t_0)-\\hat S_2(t_0)}{\\sqrt{\\hat V(\\hat S_1(t_0))+\\hat V(\\hat S_2(t_0))}}\\underset{H_0}{\\sim}N(0,1)\\] Nota: Si se quiere hacer comparaciones simultáneas (\\(k\\) en total, 2 a 2) se puede usar un factor de corrección de Bonferroni (Ejercicio)."
  },
  {
    "objectID": "PH.html#laboratorio",
    "href": "PH.html#laboratorio",
    "title": "3  Pruebas de Hipótesis",
    "section": "3.7 Laboratorio",
    "text": "3.7 Laboratorio\n\n3.7.1 Prueba de una muestra\nCarga de paquetes básicos:\n\nlibrary(survival)\nlibrary(KMsurv)\nlibrary(survMisc)\nlibrary(tidyverse)\n\nEste cálculo busca replicar el ejemplo 7.1 en donde se compara la mortalidad en una muestra de 26 pacientes psiquiátricos en Iowa con respecto a la mortalidad general de la población del mismo estado en el año 1960. Primero cargamos los datos:\n\ndata(\"psych\")\nhead(psych)\n\n  sex age time death\n1   2  51    1     1\n2   2  58    1     1\n3   2  55    2     1\n4   2  28   22     1\n5   1  21   30     0\n6   1  19   28     1\n\n\ny cargamos la información de la mortalidad de todo Iowa (1:Hombres, 2:Mujeres):\n\nIowa_mort <- read_csv('Iowa_1960.csv')\n\nRows: 60 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): Age, Survival_males, Survival_females\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncolnames(Iowa_mort) <- c('age','1','2')\nhead(Iowa_mort)\n\n# A tibble: 6 × 3\n    age   `1`   `2`\n  <dbl> <dbl> <dbl>\n1    18 0.964 0.974\n2    19 0.962 0.973\n3    20 0.961 0.973\n4    21 0.959 0.972\n5    22 0.957 0.972\n6    23 0.956 0.971\n\n\nDespués de algunos cambios, unimos las dos fuentes de información:\n\nIowa_mort <- Iowa_mort %>%\n  pivot_longer(-age,names_to = 'sex',values_to = 'Survival') %>%\n  mutate(sex=as.numeric(sex))\n\npsych <- psych %>% left_join(Iowa_mort) %>% mutate(age2=age+time)\n\nJoining with `by = join_by(sex, age)`\n\nhead(psych)\n\n  sex age time death Survival age2\n1   2  51    1     1  0.92756   52\n2   2  58    1     1  0.89304   59\n3   2  55    2     1  0.90942   57\n4   2  28   22     1  0.96805   50\n5   1  21   30     0  0.95919   51\n6   1  19   28     1  0.96246   47\n\n\nSe maneja dos distintas situaciones bajo estos datos censurados por la derecha: (1) truncamiento por la izquierda o (2) ningún truncamiento:\n\nattach(psych)\nsurv_7_1 <- Surv(time = age,time2 = age2,event = death,type = 'counting')\nsurv_7_1_b <- Surv(time = age2,event = death)\n\nSi queremos comparar las dos distribuciones sin asumir truncamiento por la izquierda se puede ejecutar:\n\nS_7_1_b <- survdiff(surv_7_1_b~offset(Survival))\nS_7_1_b\n\nCall:\nsurvdiff(formula = surv_7_1_b ~ offset(Survival))\n\n Observed  Expected         Z         p \n 1.40e+01  1.40e+00 -1.06e+01  1.89e-26 \n\n\nEn donde concluimos que la mortalidad de los pacientes es distinta a la resto del estado bajo los niveles de significancia usuales. En el caso de truncamiento por la izquierda, hacemos el cálculo de manera directa:\n\npsych <- psych %>% mutate(H=-log(Survival))\n\nIowa_mort <- Iowa_mort %>% select(age2=age,sex,Survival2=Survival)\n\npsych <- psych %>% left_join(Iowa_mort) %>%\n  mutate(H2=-log(Survival2)) %>%\n  mutate(dif=H2-H)\n\nJoining with `by = join_by(sex, age2)`\n\nOtau <- sum(psych$death)\n\nEtau <- sum(psych$dif)\n\nX2 <- (Otau-Etau)^2/Etau\n\nvalor_p <- pchisq(q = X2,df = 1,lower.tail = F)\nshow(valor_p)\n\n[1] 1.014724e-05\n\ndetach(psych)\n\nPor lo que llegamos a la misma conclusión.\n\n\n3.7.2 Prueba de dos muestras\nEl primer conjunto de datos mide la efectividad de dos técnicas distintas de colocación de catéteres en procedimientos de diálisis en riñones.\n\ndata(\"kidney\")\nhead(kidney)\n\n  time delta type\n1  1.5     1    1\n2  3.5     1    1\n3  4.5     1    1\n4  4.5     1    1\n5  5.5     1    1\n6  8.5     1    1\n\n\nPrimero estimamos las funciones de sobrevivencia según Kaplan-Meier:\n\nattach(kidney)\nlibrary(survminer)\n\nLoading required package: ggpubr\n\n\n\nAttaching package: 'survminer'\n\n\nThe following object is masked from 'package:survival':\n\n    myeloma\n\nsurv_7_2 <- Surv(time,event = delta)\nS_7_2 <- survfit(surv_7_2~type,data = kidney)\nggsurvplot(S_7_2)\n\n\n\n\nY comparamos las tasas de riesgo bajo los dos procedimientos bajo distintas escogencias de funciones de pesos \\(W(t)\\) (log-rank, Peto-Peto y tres posibilidades de escogencia de Fleming-Harrington):\n\nX_7_2_logrank <- survdiff(surv_7_2~type,data = kidney,rho = 0)\nX_7_2_logrank\n\nCall:\nsurvdiff(formula = surv_7_2 ~ type, data = kidney, rho = 0)\n\n        N Observed Expected (O-E)^2/E (O-E)^2/V\ntype=1 43       15       11      1.42      2.53\ntype=2 76       11       15      1.05      2.53\n\n Chisq= 2.5  on 1 degrees of freedom, p= 0.1 \n\nX_7_2_PetoPeto <- survdiff(surv_7_2~type,data = kidney,rho = 1)\nX_7_2_PetoPeto\n\nCall:\nsurvdiff(formula = surv_7_2 ~ type, data = kidney, rho = 1)\n\n        N Observed Expected (O-E)^2/E (O-E)^2/V\ntype=1 43     12.0     9.48     0.686      1.39\ntype=2 76     10.4    12.98     0.501      1.39\n\n Chisq= 1.4  on 1 degrees of freedom, p= 0.2 \n\nlibrary(FHtest) # http://www.bioconductor.org/packages/release/bioc/html/Icens.html\n\nLoading required package: interval\n\n\nLoading required package: perm\n\n\nLoading required package: Icens\n\n\nLoading required package: MLEcens\n\n\nDepends on Icens package available on bioconductor. \nTo install use for example:\ninstall.packages('BiocManager')\nBiocManager::install('Icens')\n\nX_7_2_FH1 <- FHtestrcc(surv_7_2~type,data = kidney,rho = 0,lambda=1)\nX_7_2_FH1\n\n\n    Two-sample test for right-censored data\n\nParameters: rho=0, lambda=1\nDistribution: counting process approach\n\nData: surv_7_2 by type\n\n        N Observed Expected   O-E (O-E)^2/E (O-E)^2/V\ntype=1 43    2.973     1.56  1.41      1.28      9.67\ntype=2 76    0.565     1.98 -1.41      1.01      9.67\n\nStatistic Z= -3.1, p-value= 0.00188\nAlternative hypothesis: survival functions not equal\n\nX_7_2_FH2 <- FHtestrcc(surv_7_2~type,data = kidney,rho = 1,lambda=0)\nX_7_2_FH2\n\n\n    Two-sample test for right-censored data\n\nParameters: rho=1, lambda=0\nDistribution: counting process approach\n\nData: surv_7_2 by type\n\n        N Observed Expected   O-E (O-E)^2/E (O-E)^2/V\ntype=1 43     12.0     9.48  2.55     0.686      1.39\ntype=2 76     10.4    12.98 -2.55     0.501      1.39\n\nStatistic Z= -1.2, p-value= 0.239\nAlternative hypothesis: survival functions not equal\n\nX_7_2_FH3 <- FHtestrcc(surv_7_2~type,data = kidney,rho = 1,lambda=1)\nX_7_2_FH3\n\n\n    Two-sample test for right-censored data\n\nParameters: rho=1, lambda=1\nDistribution: counting process approach\n\nData: surv_7_2 by type\n\n        N Observed Expected   O-E (O-E)^2/E (O-E)^2/V\ntype=1 43     2.21     1.19  1.02     0.875      9.83\ntype=2 76     0.48     1.50 -1.02     0.694      9.83\n\nStatistic Z= -3.1, p-value= 0.00171\nAlternative hypothesis: survival functions not equal\n\ndetach(kidney)\n\nNoten que bajo algunas escogencias de pesos no hay evidencia suficiente para rechazar la igualdad entre tasas de riesgos.\nEl ejemplo 7.3 del Klein busca comparar dos tasas de riesgo bajo un esquema de truncamiento por la izquierda. En este caso se usa los datos de la casa de retiro Channing, que anteriormente habíamos usado para comparar entre hombres y mujeres la sobrevivencia de adultos mayores. Ahora se busca probar \\(H_0:h_F(t)=h_M(t)\\) contra la alternativa de una cola \\(H_A:h_F(t)\\leq h_M(t)\\).\n\ndata(\"channing\")\nhead(channing)\n\n  obs death ageentry  age time gender\n1   1     1     1042 1172  130      2\n2   2     1      921 1040  119      2\n3   3     1      885 1003  118      2\n4   4     1      901 1018  117      2\n5   5     1      808  932  124      2\n6   6     1      915 1004   89      2\n\nattach(channing)\nsurv_7_3 <- Surv(time = ageentry,time2 = age,event = death,type = 'counting')\n\nWarning in Surv(time = ageentry, time2 = age, event = death, type =\n\"counting\"): Stop time must be > start time, NA created\n\nS_7_3 <- coxph(surv_7_3~gender)\nsummary(S_7_3)\n\nCall:\ncoxph(formula = surv_7_3 ~ gender)\n\n  n= 458, number of events= 176 \n   (4 observations deleted due to missingness)\n\n          coef exp(coef) se(coef)      z Pr(>|z|)  \ngender -0.3163    0.7289   0.1731 -1.827   0.0677 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n       exp(coef) exp(-coef) lower .95 upper .95\ngender    0.7289      1.372    0.5191     1.023\n\nConcordance= 0.528  (se = 0.018 )\nLikelihood ratio test= 3.17  on 1 df,   p=0.07\nWald test            = 3.34  on 1 df,   p=0.07\nScore (logrank) test = 3.36  on 1 df,   p=0.07\n\n\nEn este caso el estadístico de prueba corresponde al de la prueba Score (3.36). Como la prueba es de una cola, el valor p se puede calcular directamente:\n\npnorm(sqrt(3.36),lower.tail = F)\n\n[1] 0.03339903\n\ndetach(channing)\n\nLo que da evidencia de que bajo un nivel de confianza en la muestra del 95%, podríamos rechazar la hipótesis de que las dos tasas de riesgo son idénticas a favor de que de las mujeres es mayor a la de los hombres.\nEl ejemplo 7.4 usa los datos de 137 pacientes que iban a someterse a un transplante de médula ósea bajo tres distintas condiciones de leucemia (ALL, AML-low, AML-high). Vamos a comparar la sobrevivencia de los pacientes bajo estos tres grupos de riesgo.\n\ndata(\"bmt\")\nhead(bmt)\n\n  group   t1   t2 d1 d2 d3   ta da  tc dc tp dp z1 z2 z3 z4 z5 z6   z7 z8 z9\n1     1 2081 2081  0  0  0   67  1 121  1 13  1 26 33  1  0  1  1   98  0  1\n2     1 1602 1602  0  0  0 1602  0 139  1 18  1 21 37  1  1  0  0 1720  0  1\n3     1 1496 1496  0  0  0 1496  0 307  1 12  1 26 35  1  1  1  0  127  0  1\n4     1 1462 1462  0  0  0   70  1  95  1 13  1 17 21  0  1  0  0  168  0  1\n5     1 1433 1433  0  0  0 1433  0 236  1 12  1 32 36  1  1  1  1   93  0  1\n6     1 1377 1377  0  0  0 1377  0 123  1 12  1 22 31  1  1  1  1 2187  0  1\n  z10\n1   0\n2   0\n3   0\n4   0\n5   0\n6   0\n\n\nLas funciones de sobrevivencia estimadas se grafican:\n\nS_7_4 <- survfit(Surv(time=t2, event=d3) ~ group, data=bmt)\nggsurvplot(S_7_4)\n\n\n\n\ny probamos la hipótesis de la igualdad de tasas de riesgo entre los tres grupos, usando tres posibilidades de escogencia de parámetros de Fleming-Harrington, y bajo las opciones de log-rank y Gehan:\n\nb1 <- ten(Surv(time=t2, event=d3) ~ group, data=bmt)\npruebas_7_4 <- comp(b1, p=c(1, 0, 1), q=c(0, 1, 1))\n\n             chiSq df pChisq\n1          13.8037  2      6\nn          16.2407  2      1\nsqrtN      15.6529  2      5\nS1         15.7260  2      3\nS2         15.7781  2      2\nFH_p=1_q=0 15.6725  2      4\nFH_p=0_q=1  6.1097  2      8\nFH_p=1_q=1  9.9331  2      7\n$tft\n                     Q         Var        Z pNorm\n1             -10.6695     42.7801 -1.63127     6\nn           -1294.0000 439987.8847 -1.95081     1\nsqrtN        -118.1769   4202.2583 -1.82302     5\nS1             -9.2667     23.2023 -1.92379     3\nS2             -9.1996     22.7588 -1.92839     2\nFH_p=1_q=0     -9.3529     23.6462 -1.92339     4\nFH_p=0_q=1     -1.3166      4.5757 -0.61551     8\nFH_p=1_q=1     -1.0948      1.4957 -0.89516     7\n\n$scores\n[1] 1 2 3\n\n\nNote que en esta versión del paquete survMisc los valores p no son calculados correctamente. Por ejemplo, para el caso de la prueba con pesos de Gehan este se podría calcular como:\n\npchisq(16.2407,df = 2,lower.tail = F)\n\n[1] 0.0002974245\n\n\nPor lo tanto bajo los niveles de confianza usuales se rechaza la hipótesis de que las tres tasas de riesgo son iguales para cualquier \\(t\\).\n\n\n3.7.3 Pruebas de tendencia\nComo ejemplo de la prueba de tendencia se utiliza una base de 40 pacientes con cáncer de laringe clasificados según la etapa de la enfermedad. Se probará la hipótesis de que no hay una diferencia entre las tasas de riesgo entre las 4 etapas vs la hipótesis de que entre más alta la etapa, más alta la tasa de riesgo. Graficamos las 4 funciones de sobrevivencia estimadas:\n\ndata(\"larynx\")\n\nS_7_6 <- survfit(Surv(time, delta) ~ stage,data=larynx)\n\nggsurvplot(S_7_6)\n\n\n\n\ny el estadístico de prueba lo calculamos con la función comp, usando como scores \\(a_j=j, \\; 1,\\ldots,4\\) y bajo distintas escogencias de funciones de pesos:\n\nl1 <- ten(Surv(time, delta) ~ stage, data=larynx)\n\ncomp(l1)\n\n            chiSq df pChisq\n1          22.763  3      6\nn          23.177  3      2\nsqrtN      23.141  3      5\nS1         23.171  3      3\nS2         23.170  3      4\nFH_p=1_q=1 16.661  3      1\n$tft\n                     Q         Var       Z pNorm\n1             -25.8061     48.1505 -3.7190     1\nn           -1939.0000 210644.6590 -4.2248     3\nsqrtN        -221.9185   2990.6169 -4.0580     6\nS1            -21.3895     26.8311 -4.1293     5\nS2            -21.0942     26.0075 -4.1363     4\nFH_p=1_q=1     -2.9412      1.5056 -2.3970     2\n\n$scores\n[1] 1 2 3 4\n\np <- attr(l1, \"tft\")\n\np$tft$pChisq\n\n[1] 2.000459e-04 2.391900e-05 4.949255e-05 3.638010e-05 3.529216e-05\n[6] 1.653027e-02\n\n\nPor ejemplo para el caso de la prueba con pesos de Tarone, el valor p es:\n\n2*pnorm(4.0580,lower.tail = F)\n\n[1] 4.949477e-05\n\n\npor lo que se rechaza la hipótesis nula inmediatamente, a favor de una en donde las tasas son crecientes.\n\n\n3.7.4 Pruebas estratificadas\nComo complemento al ejemplo de la sobrevivencia en pacientes con leucemia, se incluye la covariable de uso del químico MTX como profiláctico en el tratamiento, el cual puede ser una variable confusora en la prueba del ejemplo 7.4.\n\nS_7_4_est <- survfit(Surv(time=t2, event=d3) ~ group+strata(z10), data=bmt)\n\nggsurvplot(S_7_4_est)\n\n\n\n\ny hacemos una prueba de log-rango con el paquete survival:\n\nPrueba_7_4_est <- survdiff(Surv(time=t2, event=d3) ~ group+strata(z10), data=bmt)\n\nprint(Prueba_7_4_est)\n\nCall:\nsurvdiff(formula = Surv(time = t2, event = d3) ~ group + strata(z10), \n    data = bmt)\n\n         N Observed Expected (O-E)^2/E (O-E)^2/V\ngroup=1 38       24     23.2    0.0261     0.038\ngroup=2 54       25     38.7    4.8663     9.621\ngroup=3 45       34     21.0    7.9673    10.796\n\n Chisq= 13.2  on 2 degrees of freedom, p= 0.001 \n\n\npor lo tanto se rechaza la hipótesis nula de igualdad de tasas de riesgo, independientemente del efecto del uso del químico MTX en la población de estudio.\n\n\n3.7.5 Prueba de Renyi\nPara ilustrar el uso de la prueba de Renyi usamos los datos de sobrevivencia de 90 pacientes con cáncer gástrico a los cuales se les aplicó quimioterapia o la combinación de quimioterapia y radiación. Las funciones de sobrevivencia estimadas son:\n\ndata(\"gastric\")\n\nS_7_9_est <- survfit(Surv(time, event) ~ group, data=gastric)\n\nggsurvplot(S_7_9_est)\n\n\n\n\ndonde es muy evidente que las dos funciones de sobrevivencia se cruzan en una edad intermedia, por lo que es más recomendable usar la prueba de Renyi:\n\ng1 <- ten(Surv(time, event) ~ group, data=gastric)\n\npba <- comp(g1)\n\n                     Q         Var        Z pNorm\n1           2.1463e+00  1.9862e+01  0.48159     5\nn           4.9100e+02  6.0322e+04  1.99913     3\nsqrtN       4.3629e+01  9.8798e+02  1.38803     4\nS1          5.4126e+00  7.2723e+00  2.00710     2\nS2          5.3864e+00  7.0411e+00  2.02993     1\nFH_p=1_q=1 -8.9383e-02  7.1790e-01 -0.10549     6\n              maxAbsZ        Var      Q pSupBr\n1              9.8049    19.8617 2.2001      5\nn            725.0000 60322.4412 2.9519      3\nsqrtN         84.1532   987.9774 2.6773      4\nS1             7.9752     7.2723 2.9574      2\nS2             7.8688     7.0411 2.9654      1\nFH_p=1_q=1     1.3396     0.7179 1.5811      6\n\nattr(g1, \"sup\")\n\n              maxAbsZ        Var      Q pSupBr\n1              9.8049    19.8617 2.2001      5\nn            725.0000 60322.4412 2.9519      3\nsqrtN         84.1532   987.9774 2.6773      4\nS1             7.9752     7.2723 2.9574      2\nS2             7.8688     7.0411 2.9654      1\nFH_p=1_q=1     1.3396     0.7179 1.5811      6\n\np <- attr(g1, \"sup\")\n\ny los valores p correspondientes para cada una de las escogencias de pesos son:\n\np$pSupBr\n\n[1] 0.055604370 0.006316933 0.014843656 0.006205396 0.006045005 0.227716766\n\n\nPor lo que rechazaríamos la hipótesis de igualdad de tasas de riesgo para niveles de significacia superiores al 5% aproximadamente para todos los casos excepto la primera y la última ponderación."
  },
  {
    "objectID": "RSP.html#introducción",
    "href": "RSP.html#introducción",
    "title": "4  Regresión Semiparamétrica con Riesgos Proporcionales",
    "section": "4.1 Introducción",
    "text": "4.1 Introducción\nObjetivo: Modelar la probabilidad de sobrevivencia o tasa de riesgo bajo la presencia de información adicional en la forma de covariables.\nUtilizamos la misma notación de los capítulos anteriores en donde \\(X\\): tiempo aleatorio hasta la ocurrencia de un riesgo de interés. Los datos consisten en tripletas \\((T_j,\\delta_j,Z_j(t))\\) para \\(j=1,\\ldots,n\\) donde\n\n\\(T_j\\): tiempo de evento o censura para el paciente \\(j\\)-ésimo.\n\\(\\delta_j\\): indicador del evento.\n\\(Z_j(t)=(Z_{j1}(t),\\ldots,Z_{jp}(t))^T\\): vector de \\(p\\) covariables para el individuo \\(j\\)-ésimo en tiempo \\(t\\).\n\nNota: por ahora asumiremos que \\(Z_{jp}(t)\\) es constante con respecto al tiempo \\(t\\). (\\(j=1,\\dots,n\\) y \\(k=1,\\ldots,p\\)), es decir:\n\\[Z_j(t)=Z_j=(Z_{j1},\\ldots,Z_{jp})^T\\]\nSea \\(h(t|Z)\\) la tasa de riesgo en tiempo \\(t\\) para un individuo con covariables \\(Z\\). El modelo de Cox está dado por:\n\\[h(t|Z)=h_0(t)c(\\beta^TZ)\\]\ndonde \\(h_0(t)\\) es la tasa de riesgo base (arbitraria), \\(\\beta=(\\beta_1,\\ldots,\\beta_p)^T\\) y \\(c(\\cdot)\\) es una función conocida. Como \\(h(t|Z)\\) debe ser positiva, una posible forma (y la más usual) de escoger \\(c(\\cdot)\\) es:\n\\[c(\\beta^TZ)=\\exp[\\beta^TZ]=e^{\\sum_{k=1}^p\\beta_kZ_k}\\]\nlo que permite obtener el siguiente modelo lineal generalizado:\n\\[\\log\\left[\\frac{h(t|Z)}{h_0(t)}\\right]=\\sum_{k=1}^p \\beta_kZ_k\\] Nota: el tratamiento de las covariables tanto cuantitativas como categóricas es el mismo que el que se trabaja con modelos lineales.\nAl modelo de Cox se le llama usualmente el modelo de riesgos proporcionales dado que si dos individuos tienen covariables \\(Z\\) y \\(Z^*\\):\n\\[\\frac{h(t|Z)}{h(t|Z^*)}=\\frac{h_0(t)\\exp\\left[\\sum_{k=1}^p\\beta_kZ_k\\right]}{h_0(t)\\exp\\left[\\sum_{k=1}^p\\beta_kZ_k^*\\right]}=\\exp\\left[\\sum_{k=1}^p\\beta_k(Z_k-Z_k^*)\\right]\\] es decir: \\(h(t|Z)\\propto h(t|Z^*)\\). Al cociente \\(\\frac{h(t|Z)}{h(t|Z^*)}\\) se le llama riesgo relativo.\nPor ejemplo, si \\(Z_1\\): variable tratamiento, es decir:\n\\[Z_1=\\begin{cases}\n1 & \\text{tratamiento} (Z)\\\\\n0 & \\text{placebo} (Z^*)\n\\end{cases}\n\\] y se asume que el resto de las covariables son iguales entre los dos individuos, entonces el riesgo relativo es:\n\\[\\frac{h(t|Z)}{h(t|Z^*)}=\\exp[\\beta_1(1-0)+0]=e^{\\beta_1}\\] Nota: la codificación de la variable tratamiento cambia la interpretación de \\(\\beta_1\\) ya que si:\n\\[Z_1=\\begin{cases}\n1 & \\text{placebo} (Z)\\\\\n0 & \\text{tratamiento} (Z^*)\n\\end{cases}\n\\] entonces el riesgo relativo sería \\(e^{-\\beta_1}\\).\nA las variables categóricas se le llaman en este contexto de análisis de sobrevivencia: grupos de riesgo. Si el grupo de riesgo está compuesto de tres niveles se puede usar dos covariables como indicadoras, por ejemplo si el grupo de riesgo es etnia con niveles: afroamericano, caucásico e hispánico; se puede definir: \\(Z_1=1_{\\text{Afroamericano}}\\), \\(Z_2=1_{\\text{caucasico}}\\), entonces:\n\\[\\begin{align*}\n    h(t|\\text{Afroamericano})&=h(t|Z_1=1,Z_2=0)=h_0(t)\\exp[\\beta_1]\\\\\n    h(t|\\text{Caucasico})&=h(t|Z_1=0,Z_2=1)=h_0(t)\\exp[\\beta_2]\\\\\n    h(t|\\text{Hispanico})&=h(t|Z_1=0,Z_2=0)=h_0(t)\n\\end{align*}\\]\nSi las variables son cuantitativas entonces la interpretación de los riesgos relativos se realiza al comparar cambios producto de un aumento en una unidad en la variable de análisis:\n\\[\\frac{h(t|\\text{Edad}+1)}{h(t|\\text{Edad})}=e^{\\beta_{\\text{edad}}}\\] Otro aspecto importante es que la presencia de interacciones entre covariables afecta la interpretación, tal y como se observa en modelos más sencillos como regresión múltiple o logística. (ver final de la sección 8.2 del Klein.)"
  },
  {
    "objectID": "RSP.html#verosimilitud-parcial",
    "href": "RSP.html#verosimilitud-parcial",
    "title": "4  Regresión Semiparamétrica con Riesgos Proporcionales",
    "section": "4.2 Verosimilitud Parcial",
    "text": "4.2 Verosimilitud Parcial\nA nivel de datos, considere las tripletas de la sección anterior, no dependientes del tiempo: \\((T_j,\\delta_j,Z_j)\\), para \\(j=1,\\ldots,n\\).\nSupuestos:\n\nNo hay tiempos de ocurrencia del evento repetidos.\nDado \\(Z_j\\), los tiempos de ocurrencia y censura son independientes.\n\nSea \\(t_1<t_2<\\cdots <t_D\\) los tiempos de ocurrencia del evento y\n\n\\(Z_{(i)k}\\): \\(k\\)-ésima covariable del individuo cuyo tiempo de ocurrencia es \\(t_i\\).\n\\(R(t_i)\\): individuos en riesgo al tiempo \\(t_i\\).\n\nInconveniente: \\(h_0(t)\\) debe ser estimado junto con los \\(\\beta\\)’s.\nSolución: calculamos la probabilidad de que un individuo le ocurra el riesgo en tiempo \\(t_i\\) con covariables \\(Z_{(i)}\\) dado que uno de los individuos en \\(R(t_i)\\) le ocurrió el riesgo en tiempo \\(t_i\\):\n\\[\\begin{align*}\n    &P[\\text{individuo muere en $t_i$}|\\text{una muerte en $t_i$}]\\\\\n    &=\\frac{P[\\text{individuo muere en $t_i$}|\\text{sobrevive a $t_i$}]}{P[\\text{una muerte en $t_i$}|\\text{sobrevive a $t_i$}]}\\\\\n    &=\\frac{\\frac{f(t_i|Z_{(i)})}{S(t_i|Z_{(i)})}}{\\sum_{j\\in R(t_i)}\\frac{f(t_i|Z_j)}{S(t_i|Z_j)}}=\\frac{h(t_i|Z_{(i)})}{\\sum_{j \\in R(t_i)} h(t_i|Z_j)}=\\frac{h_0(t_i)\\exp(\\beta^TZ_{(i)})}{h_0(t_i)\\sum_{j \\in R(t_i)} \\exp(\\beta^TZ_j)}\\\\\n    &=\\frac{\\exp(\\beta^TZ_{(i)})}{\\sum_{j \\in R(t_i)} \\exp(\\beta^TZ_j)}\n\\end{align*}\\]\nLa verosimilitud parcial se obtiene al multiplicar todas las probabilidades condicionales anteriores sobre todos los tiempos en donde ocurre el evento en la muestra:\n\\[L(\\beta)=\\prod_{i=1}^D\\frac{\\exp(\\beta^TZ_{(i)})}{\\sum_{j \\in R(t_i)} \\exp(\\beta^TZ_j)}\\] El proceso de inferencia se realiza con \\(L(\\beta)\\) (no depende de \\(h_0(t)\\)) o bien sobre la log-verosimilitud parcial:\n\\[LL(\\beta)=\\log L(\\beta)=\\sum_{i=1}^D\\sum_{k=1}^p \\beta_kZ_{(i)k}-\\sum_{i=1}^D\\log\\left[\\sum_{j \\in R(t_i)}\\sum_{k=1}^p\\beta_kZ_{jk}\\right]\\]\ndefiniendo funciones score:\n\\[U_h(\\beta)=\\frac{\\partial }{\\partial \\beta_h}LL(\\beta)\\qquad h=1,\\ldots,p\\]\ny resolviendo el sistema de \\(p\\) ecuaciones no lineales:\n\\[U_h(\\beta)=0\\qquad h=1,\\ldots,p\\] la solución es el estimador de máxima verosimilitud parcial de \\(\\beta\\).\nComo justificación al uso de la verosimilitud parcial como herramienta inferencial, asuma las tripletas \\((T_j,\\delta_j,Z_j)\\) como datos y escribamos la verosimilitud total de los parámetros \\((\\beta,h_0(t))\\):\n\\[\\begin{align*}\n    L(\\beta,h_0(t))&=\\prod_{j=1}^n f(T_j|Z_j)^{\\delta_j}S(T_j|Z_j)^{1-\\delta_j}\\\\\n    &=\\prod_{j=1}^n h(T_j|Z_j)^{\\delta_j}S(T_j|Z_j)\\\\\n    &=\\prod_{j=1}^n h_0(T_j)^{\\delta_j}[\\exp(\\beta^TZ_j)]^{\\delta_j}\\exp[-H_0(T_j)\\exp(\\beta^TZ_j)]\\\\\n    &=\\left[\\prod_{i=1}^D h_0(t_i)\\exp(\\beta^TZ_{(i)})\\right]\\cdot \\exp\\left[-\\sum_{j=1}^n H_0(T_j)\\exp(\\beta^TZ_j)\\right]\n\\end{align*}\\]\nSea \\(h_{0i}=h_0(t_i)\\), \\(i=1,\\ldots,D\\) y \\(H_0(T_j)=\\sum_{t_i\\leq T_j}h_{0i}\\) entonces:\n\\[L(\\beta,h_0(t))=L_\\beta(h_{01},\\ldots,h_{0D})\\propto \\prod_{i=1}^Dh_{0i}\\exp\\left[-h_{0i}\\sum_{j\\in R(t_i)}\\exp(\\beta^TZ_j)\\right]\\]\ny manteniendo \\(\\beta\\) fijo y maximizando con respecto a \\(h_{0i}\\):\n\\[\\hat h_{0i}=\\frac{1}{\\sum_{j \\in R(t_i)}\\exp(\\beta^TZ_j)}\\] es el estimador por máxima verosimilitud (de perfil) de \\(h_{0i}\\). A partir de esto definimos el estimador de Breslow de \\(H_0(t)\\) como:\n\\[\\hat H_0(t)=\\sum_{t_i\\leq t}\\frac{1}{\\sum_{j\\in R(t_i)}\\exp(\\beta^TZ_j)}\\] y sustituyendo en la fórmula de verosimilitud completa:\n\\[L(\\beta,\\hat h_{0.})\\propto \\prod_{i=1}^D\\frac{\\exp[\\beta^TZ_{(i)}]}{\\sum_{j\\in R(t_i)}\\exp[\\beta^TZ_j]}\\]\n\n4.2.1 3 pruebas de hipótesis para \\(\\beta\\)\nSea \\(b=(b_1,\\ldots,b_p)^T\\) el estimador por máxima verosimilitud parcial de \\(\\beta\\) y sea \\(I(\\beta)\\) la matriz de información \\(p\\times p\\) con entradas:\n\\[I_{gh}(\\beta)=-\\frac{\\partial^2LL}{\\partial\\beta_g\\partial\\beta_h}(\\beta)\\]\n\nPrueba de Wald\n\nSe sabe que \\(b\\sim N_p(\\beta,I^{-1}(b))\\). Entonces el estadístico de prueba con hipótesis nula: \\(H_0: \\beta=\\beta_0\\) es:\n\\[X^2_w=(b-\\beta_0)^TI(b)(b-\\beta_0)\\underset{H_0}{\\sim}\\chi^2_p\\]\n\nPrueba de cociente de verosimilitud.\n\nBajo \\(H_0: \\beta=\\beta_0\\):\n\\[X^2_{LR}=2[LL(b)-LL(\\beta_0)]\\underset{H_0}{\\sim}\\chi^2_p\\]\n\nPrueba Score (o prueba de log-rank si no hay repeticiones)\n\nSea \\(U(\\beta)=(U_1(\\beta),\\ldots,U_p(\\beta))^T\\). Entonces:\n\\[U(\\beta)\\overset{H_0}{\\underset{\\text{n grande}}{\\sim}}N_p(0,I(\\beta))\\] Entonces un estadístico de prueba de \\(H_0: \\beta=\\beta_0\\) es:\n\\[X^2_{SC}=U(\\beta_0)^TI^{-1}(\\beta_0)U(\\beta_0)\\overset{H_0}{\\underset{\\text{n grande}}{\\sim}}\\chi_p^2\\]\n\n\n4.2.2 Verosimilitud parcial cuando hay repeticiones\nSea \\(t_1<t_2<\\cdots <t_D\\) sean \\(D\\) tiempos distintos de ocurrencia del evento, \\(d_i\\): número de eventos ocurridos en \\(t_i\\) y \\(\\mathbb D_i\\): conjunto de individuos que les ocurre el evento en \\(t_i\\). Sea\n\\[S_i=\\sum_{j\\in \\mathbb D_i}Z_j\\] Las siguientes son formas distintas de construir la verosimilitud parcial cuando hay repeticiones en los tiempos de ocurrencia del riesgo:\n\nVerosimilitud parcial de Breslow (1974)\n\n\\[L_1(\\beta)=\\prod_{i=1}^D\\frac{\\exp(\\beta^TS_i)}{\\left[\\sum_{j \\in R_i}\\exp(\\beta^TZ_j)\\right]^{d_i}}\\]\n\nVerosimilitud parcial de Efron (1977)\n\n\\[L_2(\\beta)=\\prod_{i=1}^D\\frac{\\exp(\\beta^TS_i)}{\\prod_{j=1}^{d_i}\\left[\\sum_{k\\in R_i}\\exp(\\beta^TZ_k)-\\frac{j-1}{d_i}\\sum_{k\\in \\mathbb D_i}\\exp(\\beta^TZ_k)\\right]}\\]\n\nVerosimilitud parcial de Cox (1972)\n\nSea \\(Q_i\\): conjunto de todos los subconjuntos de \\(d_i\\) individuos seleccionados de \\(R_i\\). Sea \\(q=(q_1,\\ldots,q_{d_i})\\) un elemento de \\(Q_i\\) y defina \\(s^*_q=\\sum_{j=1}^{d_i}Z_{q_j}\\), entonces:\n\\[L_3(\\beta)=\\prod_{i=1}^D\\frac{\\exp(\\beta^TS_i)}{\\sum_{q\\in Q_i}\\exp(\\beta^Ts^*_q)}\\]"
  },
  {
    "objectID": "RSP.html#pruebas-locales",
    "href": "RSP.html#pruebas-locales",
    "title": "4  Regresión Semiparamétrica con Riesgos Proporcionales",
    "section": "4.3 Pruebas Locales",
    "text": "4.3 Pruebas Locales\nEn este caso la hipótesis nula de interés es:\n\\[H_0: \\beta_1=\\beta_{10}\\qquad \\text{donde} \\; \\beta=(\\beta_1^T,\\beta_2^T)^T\\]\ny \\(\\beta_1\\) es un vector \\(q\\times 1\\) y \\(\\beta_2\\) es \\((p-q)\\times 1\\).\n\nPrueba de Wald\n\nSea \\(b=(b_1^T,b_2^T)^T\\) los estimadores de máxima verosimilitud parcial de \\(\\beta\\). Supongamos que particionamos la matriz de información \\(I\\) como:\n\\[\\begin{align*}\nI=\n   \\begin{pmatrix}\n     I_{11} & I_{12} \\\\\n     I_{21} & I_{22}\n   \\end{pmatrix}\n\\end{align*}\\]\ndonde \\(I_{11}:q\\times q\\) y \\(I_{22}: (p-q)\\times (p-q)\\) son los bloques correspondientes a \\(\\beta_1\\) y \\(\\beta_2\\) respectivamente. El estadístico de prueba en este caso es:\n\\[X^2_w=(b_1-\\beta_{10})^T[I''(b)]^{-1}(b_1-\\beta_{10})\\]\ndonde \\(I''(b)\\) es la submatriz \\(q\\times q\\) (superior) de \\(I^{-1}(b)\\) y:\n\\[X_w^2\\overset{H_0}{\\underset{\\text{n grande}}{\\sim}}\\chi_q^2\\]\nSea \\(b_2(\\beta_{10})\\) los estimadores de máxima verosimilitud parciales de \\(\\beta_2\\) basados en la log-verosimilitud parcial de \\(\\beta\\) fijando las primeras \\(q\\) entradas con el valor \\(\\beta_{10}\\).\n\nPrueba de cociente de verosimilitud\n\nEl estadístico correspondiente sería:\n\\[X^2_{LR}=2\\left(LL(b)-LL[\\beta_{10},b_2(\\beta_{10})]\\right)\\overset{H_0}{\\underset{\\text{n grande}}{\\sim}}\\chi_q^2\\]\n\nPrueba Score:\n\nSea \\(U_1[\\beta_{10},b_2(\\beta_{10})]\\) el score con tamaño \\(q\\times 1\\) para \\(\\beta_1\\) evaluado en \\((\\beta_{10}^T,b_2(\\beta_{10})^T)^T\\). Entonces:\n\\[X^2_{SC}=U_1[\\beta_{10},b_2(\\beta_{10})]^T[I''(\\beta_{10},b_2(\\beta_{10}))]U_1[\\beta_{10},b_2(\\beta_{10})]\\overset{H_0}{\\underset{\\text{n grande}}{\\sim}}\\chi_q^2\\]\nAlgunas veces se quiere probar una hipótesis sobre un contraste de los parámetros a través de una prueba de Wald. Sea:\n\\[\\begin{align*}\nC=\n   \\begin{pmatrix}\n   c_1^T\\\\\n   c_2^T\\\\\n   \\vdots \\\\\n   c_q^T\n   \\end{pmatrix}_{q\\times p}\n\\end{align*}\\]\ndonde \\(q\\leq p\\) y \\(C\\) es de rango completo. Además \\(c_k^T=(c_{k1},c_{k2},\\ldots,c_{kp})\\) y se quiere probar la hipótesis:\n\\[H_0: C\\beta=C\\beta_0\\]\na través del estadístico:\n\\[(Cb-C\\beta_0)^T[CI^{-1}(b)C^T]^{-1}(Cb-C\\beta_0)\\overset{H_0}{\\underset{\\text{n grande}}{\\sim}}\\chi_q^2\\]"
  },
  {
    "objectID": "RSP.html#discretización-de-una-variable-continua",
    "href": "RSP.html#discretización-de-una-variable-continua",
    "title": "4  Regresión Semiparamétrica con Riesgos Proporcionales",
    "section": "4.4 Discretización de una variable continua",
    "text": "4.4 Discretización de una variable continua\nCon el fin de facilitar la interpretación de un riesgo relativo de una covariable cuantitativa, se puede convertir en una variable dicotómica. El principal problema de esta conversión es la pérdida de información, pero esta pérdida se puede minimizar usando razonamiento biológico a priori o bien que la decisión en la conversión sea basada en datos.\nComo principal objetivo, si \\(X\\) es una variable aleatoria continua, queremos definir \\(Z=1_{X\\geq c}\\) que cause una diferencia máxima entre los resultados de un estadístico calculado cuando \\(Z=1\\) con respecto a \\(Z=0\\) (máximo grado de separación de información entre los dos grupos).\nContal y O’Quigley (1999)\nConsidere un conjunto de cortes \\(\\{c_k\\}\\) y para cada \\(k\\) se calcula el estadístico log-rank sobre el grupo en donde \\(X\\leq c_k\\) menos el mismo estadístico sobre el grupo donde \\(X\\geq c_k\\), es decir:\n\\[S_k=\\sum_{i=1}^D\\left[d_i^+-d_i\\frac{r_i^+}{r_i}\\right]\\]\ndonde\n\n\\(d_i, r_i\\): número total de eventos y grupo en riesgo.\n\\(d_i^+, r_i^+\\): número total de eventos y grupo en riesgo cuando \\(X\\geq c_k\\).\n\\(D\\): número de tiempos de ocurrencia de eventos (distintos).\n\nEl corte estimado \\(\\hat c=\\text{argmax}_{c_k}|S_k|\\). Bajo esta escogencia de \\(\\hat c\\), el modelo de Cox es:\n\\[h(t|X)=h_0(t)\\exp[bZ]\\]\ny se quiere probar \\(H_0:b=0\\). En este caso no se puede (ni se debe) usar las pruebas anteriores, sino a través del cálculo de:\n\\[s^2=\\frac{1}{D-1}\\sum_{i=1}^D\\left[1-\\sum_{j=1}^i\\frac{1}{D-j+1}\\right]\\]\ny el estadístico de prueba es:\n\\[Q=\\frac{\\max|S_k|}{s\\sqrt{D-1}}\\overset{H_0}{\\underset{\\text{n grande}}{\\sim}}|\\text{Puente Browniano}|\\]\nNote que si \\(Q>1\\), entonces el valor p de la prueba anterior es aproximadamente \\(2\\exp[-2Q^2]\\)."
  },
  {
    "objectID": "RSP.html#estimación-de-la-función-de-sobrevivencia",
    "href": "RSP.html#estimación-de-la-función-de-sobrevivencia",
    "title": "4  Regresión Semiparamétrica con Riesgos Proporcionales",
    "section": "4.5 Estimación de la función de sobrevivencia",
    "text": "4.5 Estimación de la función de sobrevivencia\nObjetivo: Estimar la probabilidad de sobrevivencia de un nuevo individuo con covariables \\(Z_0\\).\nDespués de haber ajustado el modelo de Cox, sea \\(b\\) el estimador de máxima verosimilitud parcial y \\(\\hat V(b)=I^{-1}(b)\\). Bajo la notación usual, defina:\n\\[W(t_i,b)=\\sum_{j \\in R(t_i)}\\exp\\left(\\sum_{h=1}^pb_hZ_{jh}\\right)\\]\ny usando el estimador de Breslow, estimamos la tasa de riesgo acumulada base como:\n\\[\\hat H_0(t)=\\sum_{t_i\\leq t}\\frac{d_i}{W(t_i,b)}\\]\nNota: \\(\\hat H_0(t)\\) es el estimador de Nelson-Aalen cuando no hay covariables.\nUsando el estimador anterior:\n\\[\\hat S_0(t)=\\exp[-\\hat H_0(t)]\\]\nPara estimar la sobrevivencia de un individuo con vector de covariables \\(Z=Z_0\\) usamos:\n\\[\\hat S(t|Z=Z_0)=\\hat S_0(t)^{\\exp[b^TZ_0]}\\]\nNote que bajo ciertas condiciones:\n\\[\\hat S(t|Z=Z_0)\\overset{\\text{t fijo}}{\\underset{\\text{n grande}}{\\sim}} N(S(t|Z=Z_0), \\hat V[\\hat S(t|Z=Z_0)])\\]\ndonde\n\\[\\hat V[\\hat S(t|Z=Z_0)]=[\\hat S(t|Z=Z_0)]^2[Q_1(t)+Q_2(t;Z_0)]\\]\ny\n\\[Q_1(t)=\\sum_{t_i\\leq t}\\frac{d_i}{W(t_i,b)^2}\\]\nel cual es el estimador de la varianza de \\(\\hat H_0(t)\\) si \\(\\beta=b\\), además:\n\\[Q_2(t)=Q_3(t,Z_0)^T\\hat V(b)Q_3(t,Z_0)\\]\ncon \\(Q_3\\) el vector de tamaño \\(p\\times 1\\) con \\(k\\)-ésima entrada: (\\(k=1,\\ldots,p\\))\n\\[Q_3(t,Z_0)_k=\\sum_{t_i\\leq t}\\left[\\frac{W^{(k)}(t_i,b)}{W(t_i,b)}-Z_{0k}\\right]\\left[\\frac{d_i}{W(t_i,b)}\\right]\\]\ndonde\n\\[W^{(k)}(t_i,b)=\\sum_{j \\in R(t_i)}Z_{jk}\\exp(b^TZ_j)\\]\nUsando \\(\\hat S(t|Z=Z_0)\\) y \\(\\hat V[\\hat S(t|Z=Z_0)]\\) se puede construir intervalos de confianza para \\(S(t|Z=Z_0)\\) usando las mismas técnicas que aprendimos en el caso no-paramétrico.\nNota: Una alternativa para el estimador de Breslow, es el de Kalbfleish y Prentice, que en el caso de no-repeticiones sería:\n\\[\\hat H_0(t)=\\sum_{t_i\\leq t}\\left[1-\\left(1-\\frac{\\delta_i\\exp(b^TZ_i)}{W(t_i,b)}\\right)^{\\exp(-b^TZ_i)}\\right]\\]"
  },
  {
    "objectID": "RSP.html#covariables-dependientes-del-tiempo",
    "href": "RSP.html#covariables-dependientes-del-tiempo",
    "title": "4  Regresión Semiparamétrica con Riesgos Proporcionales",
    "section": "4.6 Covariables dependientes del tiempo",
    "text": "4.6 Covariables dependientes del tiempo\nPara incluir covariables dependientes del tiempo consideramos la siguiente estructura de datos:\n\\[[T_j,\\delta_j,[Z_j(t), 0\\leq t\\leq T_j]]\\]\npara \\(j=1,\\ldots,n\\) donde:\n\n\\(T_j\\): tiempo de ocurrencia de evento/censura\n\\(\\delta_j\\): indicador de evento de riesgo y\n\\(Z_j(t)=[Z_{j1(t)},\\ldots,Z_{jp}(t)]\\): covariables del \\(j\\)-ésimo paciente en tiempo \\(t\\).\n\nAsumimos que \\(Z_j(t)\\) es observable en el periodo de estudio y además que no hay repeticiones para distintos individuos en los tiempos de ocurrencia:\n\\[t_1<t_2<\\cdots<t_D\\]\nSean \\(Z_{(i)}(t)\\) las covariables asociadas al individuo con tiempo de ocurrencia \\(t_i\\) y \\(R(t_i)\\): el grupo expuesto al riesgo al momento \\(t_i\\). En este caso la fórmula de verosimilitud parcial es:\n\\[L(\\beta)=\\prod_{i=1}^D\\frac{\\exp\\left[\\sum_{b=1}^p\\beta_pZ_{(i)p}(t_i)\\right]}{\\sum_{j \\in R(t_i)}\\exp\\left[\\sum_{b=1}^p\\beta_pZ_{jp}(t_i)\\right]}\\]\ny los procesos de estimación puntual y pruebas de hipótesis son análogos. Si hay repeticiones en \\(t_1<\\cdots<t_D\\) entonces se puede generalizar \\(L(\\beta)\\) como en el caso de covariables estáticas.\n\n4.6.1 Aplicación: Prueba de Riesgos Proporcionales\nSea \\(Z_1\\) una covariable fija. Si se quiere probar la hipótesis de riesgos proporcionales para \\(Z_1\\) entonces defina:\n\\[Z_2=Z_1\\cdot g(t)\\]\ndonde \\(g(t)\\) es una función conocida. (usualmente \\(g(t)=\\log t\\))\nConsidere un modelo de Cox con covariables \\(Z_1\\) y \\(Z_2\\):\n\\[h(t|Z_1)=h_0(t)\\exp[\\beta_1Z_1+\\beta_2(Z_1g(t))]\\]\nCompare dos individuos con covariables \\(Z_1\\) y \\(Z_1^*\\) a través de su riesgo relativo:\n\\[\\frac{h(t|Z_1)}{h(t|Z_1^*)}=\\exp[\\beta_1(Z_1-Z_1^*)+\\beta_2g(t)(Z_1-Z_1^*)]\\]\nNote que bajo la hipótesis \\(H_0:\\) riesgos proporcionales en \\(Z_1\\), la parte derecha de la ecuación anterior no depende de \\(t\\). Por lo tanto \\(H_0\\) es equivalente a la hipótesis \\(H_0: \\beta_2=0\\) la cual se puede verificar a través de la prueba de Wald, LRT o Score.\nSi el supuesto de riesgos proporcionales no es cierto para \\(Z_1\\) entonces se puede definir una covariable dependiente de tiempo:\n\\[\\begin{align*}\nZ_2(t)=\n   \\begin{cases}\n     Z_1\\cdot g(t) & \\text{si}\\quad Z_1=1\\\\\n     0 & \\text{si no}\n   \\end{cases}\n\\end{align*}\\]\nen el caso en que \\(Z_1\\) fuera dicotómica. El principal problema a este momento es la estimación de la función \\(g(t)\\). Una posible solución es asumir que \\(g(t)\\) es una variable indicadora. Definiríamos entonces:\n\\[\\begin{align*}\nZ_2(t)=\n   \\begin{cases}\n     Z_1 & t>\\tau \\\\\n     0 & t\\leq \\tau\n   \\end{cases}\n\\end{align*}\\]\nen este caso:\n\\[\\begin{align*}\nh(t|Z(t))=\n   \\begin{cases}\n     h_0(t)\\exp(\\beta_1Z_1) & t\\leq \\tau\\\\\n     h_0(t)\\exp((\\beta_1+\\beta_2)Z_1) & t>\\tau\n   \\end{cases}\n\\end{align*}\\]\ny por lo tanto:\n\\[\\begin{align*}\n&RR(Z_1=1\\text{ vs } Z_1=0; t\\leq \\tau) = \\exp(\\beta_1)\\\\\n&RR(Z_1=1\\text{ vs } Z_1=0; t> \\tau) = \\exp(\\beta_1+\\beta_2)\n\\end{align*}\\]\npor este motivo a \\(\\tau\\) se le llama punto de cambio en el riesgo relativo. Otra codificación que se puede utilizar es a través del uso de un modelo con dos covariables: \\(Z_2(t)\\) y\n\\[\\begin{align*}\nZ_3(t)=\n   \\begin{cases}\n       Z_1 & t\\leq \\tau\\\\\n       0 & t>\\tau\n   \\end{cases}\n\\end{align*}\\]\nEntonces:\n\\[\\begin{align*}\nh(t|Z(t))=\n   \\begin{cases}\n     h_0(t)\\exp(\\theta_3 Z_1) & t\\leq \\tau\\\\\n     h_0(t)\\exp(\\theta_2 Z_1) & t>\\tau\n   \\end{cases}\n\\end{align*}\\]\ny:\n\\[\\begin{align*}\n&RR(Z_1=1\\text{ vs } Z_1=0; t\\leq \\tau) = \\exp(\\theta_3)\\\\\n&RR(Z_1=1\\text{ vs } Z_1=0; t> \\tau) = \\exp(\\theta_2)\n\\end{align*}\\]\nEl siguiente paso es ajustar el modelo (bajo cualquiera de las dos codificaciones) para distintos valores de \\(\\tau\\) (tiempos de ocurrencia). El valor \\(\\tau\\) con máxima log-verosimilitud se toma como posible umbral.\nUna prueba de riesgos proporcionales se hace en \\(t\\leq \\tau\\) y \\(t>\\tau\\). Si en alguna de las dos regiones la prueba se rechaza, el proceso se repite."
  },
  {
    "objectID": "RSP.html#modelos-de-riesgos-proporcionales-estratificados",
    "href": "RSP.html#modelos-de-riesgos-proporcionales-estratificados",
    "title": "4  Regresión Semiparamétrica con Riesgos Proporcionales",
    "section": "4.7 Modelos de riesgos proporcionales estratificados",
    "text": "4.7 Modelos de riesgos proporcionales estratificados\nOtra solución en caso de que para una covariable el supuesto de riesgos proporcionales no sea cierto es a través del concepto de estratificación. Para el \\(j\\)-ésimo estrato:\n\\[h_j(t|Z(t))=h_{0j}(t)\\exp[\\beta^TZ(t)]\\qquad j=1,\\ldots,s\\]\nse asume que el supuesto de riesgos proporcionales es cierto dentro de cada estrato y además el efecto de las covariables es el mismo sobre todos los estratos.\nLa log-verosimilitud parcial se puede escribir:\n\\[LL(\\beta)=LL_1(\\beta)+\\cdots+LL_s(\\beta)\\]\ndonde \\(LL_j(\\beta)\\): log-verosimilitud parcial usando la muestra del \\(j\\)-ésimo estrato.\nPara probar la hipótesis de que las covariables tienen el mismo efecto para cualquier estrato, se:\n\nAjusta el modelo estratificado y se obtiene \\(LL(b)\\).\nPara \\(j=1,\\ldots,s\\), se ajusta el modelo con la muestra correspondiente al \\(j\\)-ésimo estrato y se obtiene \\(LL_j(b_j)\\)\n\nPara probar \\(H_0: \\beta=\\beta_j\\), con \\(j=1,\\ldots,s\\) se usa un LRT con estadístico:\n\\[-2[LL(b)-\\sum_{j=1}^sLL_j(b_j)]\\overset{H_0}{\\underset{\\text{n grande}}{\\sim}}\\chi_{(s-1)p}^2\\]\nNota: también se puede verificar \\(H_0\\) a través de la prueba de Wald. (ver libro de Klein).\nSi la muestra está compuesta por pares de observaciones (muestra pareada) entonces se puede probar la igualdad de los \\(\\beta\\)’s entre grupos usando dos estratos y el LRT anterior (o prueba de Wald)."
  },
  {
    "objectID": "RSP.html#truncamiento-por-la-izquierda",
    "href": "RSP.html#truncamiento-por-la-izquierda",
    "title": "4  Regresión Semiparamétrica con Riesgos Proporcionales",
    "section": "4.8 Truncamiento por la izquierda",
    "text": "4.8 Truncamiento por la izquierda\nEn el caso de datos truncados se denota \\(V_i\\): tiempo de entrada al estudio del individuo \\(i\\)-ésimo.\nPara facilitar el cálculo, se supone que para cada individuo, el tiempo de evento \\(X\\) y el tiempo de entrada \\(V\\) son condicionalmente independientes dada la covariable \\(Z\\). Es decir:\n\\[P(X=t|Z,X>V)=\\frac{P(X=t,V<t|Z)\\cdot P(Z)}{P(Z,V<X)}=\\frac{P(X=t|Z)P(V<t|Z)P(Z)}{P(Z,V<X)}\\]\nDe lo anterior se puede deducir:\n\\[h(t|Z,X>V)=h(t|Z)\\]\nusando el hecho de que:\n\\[h(t|Z,X>V)\\approx \\frac{P(X=t|Z,X>V)}{P(X\\geq t|Z,X>V)}\\]\nAjustando el conjunto de riesgo a:\n\\[R(t)=\\{j|V_j<t<T_j\\}\\]\ntodos los métodos de inferencia vistos hasta ahora funcionan para ajustar el modelo de Cox."
  },
  {
    "objectID": "RSP.html#laboratorio",
    "href": "RSP.html#laboratorio",
    "title": "4  Regresión Semiparamétrica con Riesgos Proporcionales",
    "section": "4.9 Laboratorio",
    "text": "4.9 Laboratorio\n\n4.9.1 Primer Ejemplo (Ejemplo 8.1)\nEn este ejemplo tenemos una muestra de 45 mujeres a las que se le aplicó un procedimiento llamado “examinación inmunohistoquímica” con el fin de detectar cáncer. Los datos de sobrevivencia de las pacientes son:\n\nlibrary(survival)\n\nlibrary(survMisc)\n\n\nAttaching package: 'survMisc'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    autoplot\n\nlibrary(KMsurv)\n\ndata(\"btrial\")\n\nhead(btrial)\n\n  time death im\n1   19     1  1\n2   25     1  1\n3   30     1  1\n4   34     1  1\n5   37     1  1\n6   46     1  1\n\nsummary(btrial)\n\n      time            death              im     \n Min.   : 19.00   Min.   :0.0000   Min.   :1.0  \n 1st Qu.: 51.00   1st Qu.:0.0000   1st Qu.:1.0  \n Median : 89.00   Median :1.0000   Median :1.0  \n Mean   : 98.33   Mean   :0.5333   Mean   :1.2  \n 3rd Qu.:144.00   3rd Qu.:1.0000   3rd Qu.:1.0  \n Max.   :189.00   Max.   :1.0000   Max.   :2.0  \n\n\nen donde podemos notar que la variable im debería ser una variable categórica (factor) indicando presencia/ausencia del procedimiento. Esto lo corregimos transformando la variable y tomando como categoría base la ausencia del procedimiento:\n\nlibrary(tidyverse)\n\nbtrial <- btrial %>% mutate(im=factor(im))\n\ncontrasts(btrial$im)\n\n  2\n1 0\n2 1\n\n\nLas funciones de sobrevivencia estimadas dependiendo del grupo “procedimiento” son:\n\nlibrary(survminer)\n\nLoading required package: ggpubr\n\n\n\nAttaching package: 'survminer'\n\n\nThe following object is masked from 'package:survival':\n\n    myeloma\n\nKM_8_1 <- survfit(Surv(time,death)~im,data = btrial)\n\nggsurvplot(KM_8_1)\n\n\n\n\nLa diferencia evidente entre ambas funciones, sugiere que uno puede correr una regresión tomando la variable im como covariable:\n\nmodelo_8_1 <- coxph(Surv(time,death)~im,data = btrial)\n\nsummary(modelo_8_1)\n\nCall:\ncoxph(formula = Surv(time, death) ~ im, data = btrial)\n\n  n= 45, number of events= 24 \n\n      coef exp(coef) se(coef)     z Pr(>|z|)  \nim2 0.9802    2.6650   0.4349 2.254   0.0242 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n    exp(coef) exp(-coef) lower .95 upper .95\nim2     2.665     0.3752     1.136      6.25\n\nConcordance= 0.583  (se = 0.042 )\nLikelihood ratio test= 4.45  on 1 df,   p=0.03\nWald test            = 5.08  on 1 df,   p=0.02\nScore (logrank) test = 5.49  on 1 df,   p=0.02\n\n\nNote que el riesgo relativo de una paciente con un resultado positivo del procedimiento con respecto a una con un negativo es 2.67, es decir una paciente positiva es 2.67 más probable que fallezca con respecto a una que tuvo un resultado negativo. Un intervalo al 95% para el riesgo relativo de la población es [1.136,6.25].\nTambién podemos probar la hipótesis de que el procedimiento no es significativo al 5%. Bajo cualquiera de las tres pruebas (LRT, Wald y Score) se rechaza esta hipótesis nula.\n\n\n4.9.2 Segundo ejemplo (Ejemplo 8.2)\nEl segundo ejemplo tiene como base los datos de 90 hombres diagnosticados con cáncer de laringe con su edad de diagnóstico (age), tiempo de muerte o censura en meses (time), indicador de censura (delta) y etapa de la enfermedad (stage).\n\ndata(\"larynx\")\n\nsummary(larynx)\n\n     stage            time             age            diagyr     \n Min.   :1.000   Min.   : 0.100   Min.   :41.00   Min.   :70.00  \n 1st Qu.:1.000   1st Qu.: 2.000   1st Qu.:57.00   1st Qu.:72.25  \n Median :2.000   Median : 4.000   Median :65.00   Median :74.00  \n Mean   :2.222   Mean   : 4.198   Mean   :64.61   Mean   :74.24  \n 3rd Qu.:3.000   3rd Qu.: 6.200   3rd Qu.:72.00   3rd Qu.:76.00  \n Max.   :4.000   Max.   :10.700   Max.   :86.00   Max.   :78.00  \n     delta       \n Min.   :0.0000  \n 1st Qu.:0.0000  \n Median :1.0000  \n Mean   :0.5556  \n 3rd Qu.:1.0000  \n Max.   :1.0000  \n\n\nTransformamos la variable stage para que sea factor, y mantenemos la variable discreta con el nombre stage_n:\n\nlarynx <- larynx %>% mutate(stage_n = stage) %>%\n\n  mutate(stage=factor(stage))\n\ncontrasts(larynx$stage)\n\n  2 3 4\n1 0 0 0\n2 1 0 0\n3 0 1 0\n4 0 0 1\n\n\nNoten que la base según esta codificación es la etapa 1 de la enfermedad. Corremos un modelo de Cox usando como covariable la etapa de la enfermedad, usando un estimador de Breslow en la tasa acumulada de riesgo base:\n\nmodelo_8_2 <- coxph(Surv(time,delta)~stage,data=larynx,ties = 'breslow')\n\nsummary(modelo_8_2)\n\nCall:\ncoxph(formula = Surv(time, delta) ~ stage, data = larynx, ties = \"breslow\")\n\n  n= 90, number of events= 50 \n\n          coef exp(coef) se(coef)     z Pr(>|z|)    \nstage2 0.06576   1.06797  0.45844 0.143   0.8859    \nstage3 0.61206   1.84423  0.35520 1.723   0.0849 .  \nstage4 1.72284   5.60040  0.41966 4.105 4.04e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n       exp(coef) exp(-coef) lower .95 upper .95\nstage2     1.068     0.9364    0.4348     2.623\nstage3     1.844     0.5422    0.9193     3.700\nstage4     5.600     0.1786    2.4604    12.748\n\nConcordance= 0.668  (se = 0.037 )\nLikelihood ratio test= 16.26  on 3 df,   p=0.001\nWald test            = 18.95  on 3 df,   p=3e-04\nScore (logrank) test = 22.46  on 3 df,   p=5e-05\n\n\nPor ejemplo el riesgo relativo de los pacientes con etapa 3 con respecto a etapa 1 es 1.844. El riesgo relativo de los pacientes etapa 3 con respecto a etapa 2 es:\n\n1.844/1.068\n\n[1] 1.726592\n\n\nAdemás, la hipótesis nula de que el riesgo relativo es igual para las etapas de la enfermedad se rechaza facílmente bajo cualquiera de las tres pruebas de hipótesis (Wald, Score y LRT).\nComo la prueba score en el modelo de Cox es la prueba logrank, al utilizar como covariable stage_n se estaría haciendo una prueba de tendencia:\n\nmodelo_8_2_trend <- coxph(Surv(time,delta)~stage_n,data=larynx,ties = 'breslow')\n\nsummary(modelo_8_2_trend)\n\nCall:\ncoxph(formula = Surv(time, delta) ~ stage_n, data = larynx, ties = \"breslow\")\n\n  n= 90, number of events= 50 \n\n          coef exp(coef) se(coef)     z Pr(>|z|)    \nstage_n 0.5054    1.6577   0.1411 3.582  0.00034 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n        exp(coef) exp(-coef) lower .95 upper .95\nstage_n     1.658     0.6032     1.257     2.186\n\nConcordance= 0.668  (se = 0.037 )\nLikelihood ratio test= 13.1  on 1 df,   p=3e-04\nWald test            = 12.83  on 1 df,   p=3e-04\nScore (logrank) test = 13.64  on 1 df,   p=2e-04\n\n\nEn este caso se rechaza la hipótesis de igualdad de funciones de sobrevivencia a favor de la hipótesis alternativa de decrecimiento en la sobrevivencia conforme se incrementa la etapa de la enfermedad.\nSi introducimos como covariable la edad de diagnóstico:\n\nmodelo_8_2_age <- update(modelo_8_2,formula. = .~.+age)\n\nsummary(modelo_8_2_age)\n\nCall:\ncoxph(formula = Surv(time, delta) ~ stage + age, data = larynx, \n    ties = \"breslow\")\n\n  n= 90, number of events= 50 \n\n          coef exp(coef) se(coef)     z Pr(>|z|)    \nstage2 0.13856   1.14862  0.46231 0.300    0.764    \nstage3 0.63835   1.89335  0.35608 1.793    0.073 .  \nstage4 1.69306   5.43607  0.42221 4.010 6.07e-05 ***\nage    0.01890   1.01908  0.01425 1.326    0.185    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n       exp(coef) exp(-coef) lower .95 upper .95\nstage2     1.149     0.8706    0.4642     2.842\nstage3     1.893     0.5282    0.9422     3.805\nstage4     5.436     0.1840    2.3763    12.436\nage        1.019     0.9813    0.9910     1.048\n\nConcordance= 0.682  (se = 0.039 )\nLikelihood ratio test= 18.07  on 4 df,   p=0.001\nWald test            = 20.82  on 4 df,   p=3e-04\nScore (logrank) test = 24.33  on 4 df,   p=7e-05\n\n\nPor lo tanto el riesgo relativo de un paciente con edad de diagnóstico igual a 50 años con respecto a uno con 40 años cuando la etapa de la enfermedad es la misma es:\n\nexp(10*modelo_8_2_age$coefficients[4])\n\n     age \n1.208063 \n\n\nEs decir hay un incremento de un 21% aproximadamente en el riesgo de fallecer entre una persona con 50 años con respecto a una de 40 años si ambos están en la misma etapa de la enfermedad.\nSi queremos probar la hipótesis nula de que \\(H_0:\\beta_1=\\beta_2=\\beta_3=0\\) en el modelo anterior podemos comparar a través de un LRT el modelo completo con todas las covariables y uno reducido con solamente la covariable edad:\n\nmodelo_8_2_solo_age <- coxph(Surv(time,delta)~age,data=larynx,ties = 'breslow')\n\nanova(modelo_8_2_age,modelo_8_2_solo_age)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time, delta)\n Model 1: ~ stage + age\n Model 2: ~ age\n   loglik  Chisq Df Pr(>|Chi|)   \n1 -188.18                        \n2 -195.91 15.453  3   0.001468 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nEs decir rechazamos esta hipótesis bajo los niveles usuales de significancia. Si queremos comprobar la misma hipótesis con la prueba de Wald calculamos:\n\nIb_inv <- modelo_8_2_age$var\n\nX2w <- t(modelo_8_2_age$coefficients[1:3])%*%\n\n  solve(Ib_inv[1:3,1:3])%*%\n\n  modelo_8_2_age$coefficients[1:3]\n\npchisq(X2w,df = 3,lower.tail = F)\n\n             [,1]\n[1,] 0.0005245945\n\n\ny llegamos a la misma conclusión.\nLas pruebas de Wald individuales en el modelo completo se obtienen directamente del mismo output:\n\nsummary(modelo_8_2_age)\n\nCall:\ncoxph(formula = Surv(time, delta) ~ stage + age, data = larynx, \n    ties = \"breslow\")\n\n  n= 90, number of events= 50 \n\n          coef exp(coef) se(coef)     z Pr(>|z|)    \nstage2 0.13856   1.14862  0.46231 0.300    0.764    \nstage3 0.63835   1.89335  0.35608 1.793    0.073 .  \nstage4 1.69306   5.43607  0.42221 4.010 6.07e-05 ***\nage    0.01890   1.01908  0.01425 1.326    0.185    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n       exp(coef) exp(-coef) lower .95 upper .95\nstage2     1.149     0.8706    0.4642     2.842\nstage3     1.893     0.5282    0.9422     3.805\nstage4     5.436     0.1840    2.3763    12.436\nage        1.019     0.9813    0.9910     1.048\n\nConcordance= 0.682  (se = 0.039 )\nLikelihood ratio test= 18.07  on 4 df,   p=0.001\nWald test            = 20.82  on 4 df,   p=3e-04\nScore (logrank) test = 24.33  on 4 df,   p=7e-05\n\n\nLa hipótesis nula \\(H_0:\\beta_1=\\beta_2=\\beta_3\\) puede ser comprobada a través de una matriz de contrastes y usando el estadístico de prueba de la ecuación 8.5.7:\n\nbetas <- coefficients(modelo_8_2_age)\n\nCmat <- matrix(c(1,-1,0,0,0,1,-1,0),nrow = 2,byrow = T)\n\nX_C2 <- t(Cmat%*%betas)%*%solve(Cmat%*%Ib_inv%*%t(Cmat))%*%Cmat%*%betas\n\npchisq(X_C2,df = 2,lower.tail = F)\n\n            [,1]\n[1,] 0.004671744\n\n\nen donde rechazamos \\(H_0\\) bajo los niveles de significancia usuales.\nSi consideramos la interacción entre la edad de diagnóstico con la etapa de la enfermedad el modelo se puede estimar con:\n\nmodelo_8_2_age_stage <- update(modelo_8_2_age,formula. = .~.+stage:age)\n\nsummary(modelo_8_2_age_stage)\n\nCall:\ncoxph(formula = Surv(time, delta) ~ stage + age + stage:age, \n    data = larynx, ties = \"breslow\")\n\n  n= 90, number of events= 50 \n\n                coef exp(coef)  se(coef)      z Pr(>|z|)  \nstage2     -7.946142  0.000354  3.678209 -2.160   0.0307 *\nstage3     -0.122500  0.884706  2.468331 -0.050   0.9604  \nstage4      0.846986  2.332605  2.425717  0.349   0.7270  \nage        -0.002559  0.997444  0.026051 -0.098   0.9218  \nstage2:age  0.120254  1.127783  0.052307  2.299   0.0215 *\nstage3:age  0.011351  1.011416  0.037449  0.303   0.7618  \nstage4:age  0.013673  1.013767  0.035967  0.380   0.7038  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n           exp(coef) exp(-coef) lower .95 upper .95\nstage2      0.000354  2824.6562 2.619e-07    0.4786\nstage3      0.884705     1.1303 7.011e-03  111.6467\nstage4      2.332605     0.4287 2.009e-02  270.7790\nage         0.997444     1.0026 9.478e-01    1.0497\nstage2:age  1.127783     0.8867 1.018e+00    1.2495\nstage3:age  1.011416     0.9887 9.398e-01    1.0884\nstage4:age  1.013767     0.9864 9.448e-01    1.0878\n\nConcordance= 0.694  (se = 0.039 )\nLikelihood ratio test= 24.27  on 7 df,   p=0.001\nWald test            = 24.11  on 7 df,   p=0.001\nScore (logrank) test = 28.59  on 7 df,   p=2e-04\n\n\ny podemos usar una prueba LRT para verificar la significancia de la interacción:\n\nanova(modelo_8_2_age,modelo_8_2_age_stage)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time, delta)\n Model 1: ~ stage + age\n Model 2: ~ stage + age + stage:age\n   loglik  Chisq Df Pr(>|Chi|)\n1 -188.18                     \n2 -185.08 6.2039  3     0.1021\n\n\nque con un nivel de significancia del 5% (una muestra de 90 sujetos podría sugerir ese nivel) no se podría rechazar la hipótesis de no significancia de la interacción.\nFinalmente vamos a estimar la función de sobrevivencia de un paciente con 60 años bajo los cuatro estados de la enfermedad. Recuerden que estamos usando la aproximación de Breslow:\n\nindividuo <- data.frame(age=rep(60,4),stage=factor(1:4))\n\nS_8_2_age <- survfit(modelo_8_2_age,newdata = individuo)\n\nplot(S_8_2_age,col=1:4)\n\n\n\n\n\n\n4.9.3 Tercer ejemplo (Ejemplo 8.3)\nEste tercer ejemplo consiste en 863 pacientes de transplante de riñón con covariables etnia (race: \\(R\\)) y sexo (gender: \\(G\\)). Cargamos los datos y transformamos las dos covariables en variables tipo factor:\n\ndata(\"kidtran\")\n\nsummary(kidtran)\n\n      obs             time          delta            gender     \n Min.   :  1.0   Min.   :   1   Min.   :0.0000   Min.   :1.000  \n 1st Qu.:216.5   1st Qu.: 426   1st Qu.:0.0000   1st Qu.:1.000  \n Median :432.0   Median :1269   Median :0.0000   Median :1.000  \n Mean   :432.0   Mean   :1380   Mean   :0.1622   Mean   :1.393  \n 3rd Qu.:647.5   3rd Qu.:2216   3rd Qu.:0.0000   3rd Qu.:2.000  \n Max.   :863.0   Max.   :3434   Max.   :1.0000   Max.   :2.000  \n      race            age       \n Min.   :1.000   Min.   : 1.00  \n 1st Qu.:1.000   1st Qu.:33.00  \n Median :1.000   Median :43.00  \n Mean   :1.175   Mean   :42.84  \n 3rd Qu.:1.000   3rd Qu.:54.00  \n Max.   :2.000   Max.   :75.00  \n\nkidtran <- kidtran %>% mutate(gender=factor(gender),race=factor(race))\n\nPrimero ajustamos un modelo en donde haya una interacción entre las dos covariables:\n\nmodelo_8_3 <- coxph(Surv(time,delta)~gender*race,data = kidtran)\n\nsummary(modelo_8_3)\n\nCall:\ncoxph(formula = Surv(time, delta) ~ gender * race, data = kidtran)\n\n  n= 863, number of events= 140 \n\n                  coef exp(coef) se(coef)      z Pr(>|z|)  \ngender2       -0.24848   0.77998  0.19854 -1.252   0.2107  \nrace2         -0.08878   0.91504  0.29182 -0.304   0.7609  \ngender2:race2  0.74549   2.10747  0.42711  1.745   0.0809 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n              exp(coef) exp(-coef) lower .95 upper .95\ngender2           0.780     1.2821    0.5285     1.151\nrace2             0.915     1.0928    0.5165     1.621\ngender2:race2     2.107     0.4745    0.9124     4.868\n\nConcordance= 0.54  (se = 0.024 )\nLikelihood ratio test= 4.37  on 3 df,   p=0.2\nWald test            = 4.64  on 3 df,   p=0.2\nScore (logrank) test = 4.74  on 3 df,   p=0.2\n\n\nNote que en este caso los niveles base en ambas covariables son Masculino y etnia blanca. Hay que tener cuidado en este caso al calcular los riesgos relativos, por ejemplo el riesgo relativo de ser hombre negro con respecto a una mujer blanca es:\n\\[\\frac{h(t|G=1,R=2)}{h(t|G=2,R=1)}=\\frac{e^{-0.08878}}{e^{-0.24848}}=\\frac{0.915}{0.78}=1.17\\]\ny el riesgo relativo de una mujer negra con respecto a una blanca:\n\\[\\frac{h(t|G=2,R=2)}{h(t|G=2,R=1)}=\\frac{e^{-0.8878-0.24848+0.74549}}{e^{-0.24848}}=0.915\\cdot 2.107=1.928\\]\nLas pruebas de Wald, score y LRT no rechazan la hipótesis de no-significancia de la interacción y efectos principales del sexo y etnia sobre la sobrevivencia de la población en estudio.\nSi ajustamos un modelo reducido con efectos principales solamente tenemos:\n\nmodelo_8_3_sInt <- update(modelo_8_3,formula. = .~.-gender:race)\n\nsummary(modelo_8_3_sInt)\n\nCall:\ncoxph(formula = Surv(time, delta) ~ gender + race, data = kidtran)\n\n  n= 863, number of events= 140 \n\n            coef exp(coef) se(coef)      z Pr(>|z|)\ngender2 -0.09347   0.91077  0.17441 -0.536    0.592\nrace2    0.21992   1.24597  0.21148  1.040    0.298\n\n        exp(coef) exp(-coef) lower .95 upper .95\ngender2    0.9108     1.0980    0.6471     1.282\nrace2      1.2460     0.8026    0.8232     1.886\n\nConcordance= 0.526  (se = 0.023 )\nLikelihood ratio test= 1.35  on 2 df,   p=0.5\nWald test            = 1.39  on 2 df,   p=0.5\nScore (logrank) test = 1.4  on 2 df,   p=0.5\n\n\ny podemos verificar a través de una prueba LRT si la interacción es significativa:\n\nanova(modelo_8_3_sInt,modelo_8_3)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time, delta)\n Model 1: ~ gender + race\n Model 2: ~ gender * race\n   loglik  Chisq Df Pr(>|Chi|)  \n1 -878.50                       \n2 -876.99 3.0222  1    0.08213 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDado que la muestra es relativamente grande (863 individuos) uno pensaría que la significancia debería ser menor al menos al 5%. En este caso no podríamos rechazar la hipótesis de no-significancia de la interacción entre las dos covariables.\nA pesar de esto el modelo reducido sigue siendo no significativo.\nUn último ejercicio es la discretización de la covariable edad, ante distintas combinaciones de las dos covariables sexo y etnia. La discretización de la variable edad en dos grupos la podemos hacer a travéś de la prueba de Contal y O’Quigley, para los hombres de raza negra:\n\nmuestraBM <- kidtran %>% filter(gender==1,race==2)\n\nmodel_c_BM <- coxph(Surv(time,delta)~age,data = muestraBM)\n\nsummary(model_c_BM)\n\nCall:\ncoxph(formula = Surv(time, delta) ~ age, data = muestraBM)\n\n  n= 92, number of events= 14 \n\n       coef exp(coef) se(coef)     z Pr(>|z|)\nage 0.03613   1.03679  0.02468 1.464    0.143\n\n    exp(coef) exp(-coef) lower .95 upper .95\nage     1.037     0.9645    0.9878     1.088\n\nConcordance= 0.6  (se = 0.084 )\nLikelihood ratio test= 2.43  on 1 df,   p=0.1\nWald test            = 2.14  on 1 df,   p=0.1\nScore (logrank) test = 2.2  on 1 df,   p=0.1\n\nContal_BM <- cutp(model_c_BM)\n\nContal_BM$age[1,]\n\n   age        U        Q         p\n1:  58 2.632404 0.802934 0.5393762\n\n\nen donde podemos observar que utilizar un umbral de 58 años permite obtener la mayor separabilidad entre los dos grupos a través del estadístico logrank. Usando la variable discreta y usando la variable continua no se rechaza la nula de no-significancia de la edad para este grupo.\nEl caso de hombres de raza blanca es:\n\nmuestraWM <- kidtran %>% filter(gender==1,race==1)\n\nmodel_c_WM <- coxph(Surv(time,delta)~age,data = muestraWM)\n\nsummary(model_c_WM)\n\nCall:\ncoxph(formula = Surv(time, delta) ~ age, data = muestraWM)\n\n  n= 432, number of events= 73 \n\n       coef exp(coef) se(coef)     z Pr(>|z|)    \nage 0.06029   1.06214  0.01021 5.903 3.56e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n    exp(coef) exp(-coef) lower .95 upper .95\nage     1.062     0.9415     1.041     1.084\n\nConcordance= 0.695  (se = 0.027 )\nLikelihood ratio test= 39.16  on 1 df,   p=4e-10\nWald test            = 34.85  on 1 df,   p=4e-09\nScore (logrank) test = 36.66  on 1 df,   p=1e-09\n\nContal_WM <- cutp(model_c_WM)\n\nContal_WM$age[1,]\n\n   age        U        Q            p\n1:  41 25.21247 3.054644 1.571653e-08\n\n\nen donde de manera contraria la edad sí es significativa al explicar la sobrevivencia, a través de una edad umbral de 41 años.\n\n\n4.9.4 Selección de variables\nLos datos de este primer ejemplo corresponden a la base de sobrevivencia de 137 pacientes con transplante de médula ósea, los cuales se han dividido en tres grupos de riesgo dependiendo de su condición al momento del trasplante (ALL, AML-Low, AML-high). El riesgo a considerar es la muerte durante el tratamiento o reaparición de la leucemia. A continuación la carga de paquetes y datos:\n\nlibrary(survival)\n\nlibrary(survMisc)\n\nlibrary(KMsurv)\n\nlibrary(tidyverse)\n\ndata(bmt)\n\nPrimero ajustamos un modelo de Cox en donde los grupos de riesgo son una covariable y comprobamos si la covariable aporta de forma significativa al explicar la sobrevivencia de la muestra:\n\nbmt <- bmt %>% mutate(group=factor(group))\n\nmodelo1 <- coxph(Surv(time=t2, event=d3) ~ group, data=bmt)\n\nsummary(modelo1)\n\nCall:\ncoxph(formula = Surv(time = t2, event = d3) ~ group, data = bmt)\n\n  n= 137, number of events= 83 \n\n          coef exp(coef) se(coef)      z Pr(>|z|)  \ngroup2 -0.5742    0.5632   0.2873 -1.999   0.0457 *\ngroup3  0.3834    1.4673   0.2674  1.434   0.1516  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n       exp(coef) exp(-coef) lower .95 upper .95\ngroup2    0.5632     1.7757    0.3207     0.989\ngroup3    1.4673     0.6815    0.8688     2.478\n\nConcordance= 0.625  (se = 0.03 )\nLikelihood ratio test= 13.45  on 2 df,   p=0.001\nWald test            = 13.03  on 2 df,   p=0.001\nScore (logrank) test = 13.81  on 2 df,   p=0.001\n\n\nen donde notamos que para las tres pruebas LRT, Wald y Score se rechaza la hipótesis de que la variable categórica grupo no es significativa bajo niveles de significancia usuales. Hay otras variables que también se van a considerar como posibles predictores: tiempo de espera del transplante (waiting), clasificador FAB (FAB), indicador de MTX (MTX), Sexo de paciente (SXPa), Sexo de Donante (SXDo), CMV de paciente (CMVPa), CMV de donante (CMVDo), Edad de paciente (AgePa), Edad de donante (AgeDo)\n\nbmt <- bmt %>% mutate(waiting=z7,FAB=factor(z8),\n\n                      MTX=factor(z10),SXPa=factor(z3),\n\n                      SXDo=factor(z4),CMVPa=factor(z5),                      CMVDo=factor(z6),AgePa=z1-28,AgeDo=z2-28)\n\nbmt_2 <- bmt %>% select(t2,d3,group,waiting,FAB,MTX,SXPa,SXDo,\n\n                       CMVPa,CMVDo,AgePa,AgeDo,ta,tc,tp)\n\nDefinimos los modelos aumentados en una variable o factor a la vez y usamos la técnica de selección para adelante (Forward selection) como método de selección de variables:\n\nmodelo1_1 <- update(modelo1,formula. = .~.+waiting)\n\nanova(modelo1,modelo1_1)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = t2, event = d3)\n Model 1: ~ group\n Model 2: ~ group + waiting\n   loglik  Chisq Df Pr(>|Chi|)\n1 -366.57                     \n2 -365.90 1.3356  1     0.2478\n\nmodelo1_2 <- update(modelo1,formula. = .~.+FAB)\n\nanova(modelo1,modelo1_2)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = t2, event = d3)\n Model 1: ~ group\n Model 2: ~ group + FAB\n   loglik  Chisq Df Pr(>|Chi|)   \n1 -366.57                        \n2 -362.42 8.2902  1   0.003986 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmodelo1_3 <- update(modelo1,formula. = .~.+MTX)\n\nanova(modelo1,modelo1_3)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = t2, event = d3)\n Model 1: ~ group\n Model 2: ~ group + MTX\n   loglik Chisq Df Pr(>|Chi|)\n1 -366.57                    \n2 -365.60  1.94  1     0.1637\n\nmodelo1_4 <- update(modelo1,formula. = .~.+SXPa*SXDo)\n\nanova(modelo1,modelo1_4)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = t2, event = d3)\n Model 1: ~ group\n Model 2: ~ group + SXPa + SXDo + SXPa:SXDo\n   loglik Chisq Df Pr(>|Chi|)\n1 -366.57                    \n2 -365.65 1.847  3     0.6048\n\nmodelo1_5 <- update(modelo1,formula. = .~.+CMVPa*CMVDo)\n\nanova(modelo1,modelo1_5)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = t2, event = d3)\n Model 1: ~ group\n Model 2: ~ group + CMVPa + CMVDo + CMVPa:CMVDo\n   loglik  Chisq Df Pr(>|Chi|)\n1 -366.57                     \n2 -366.48 0.1827  3     0.9803\n\nmodelo1_6 <- update(modelo1,formula. = .~.+AgePa*AgeDo)\n\nanova(modelo1,modelo1_6)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = t2, event = d3)\n Model 1: ~ group\n Model 2: ~ group + AgePa + AgeDo + AgePa:AgeDo\n   loglik  Chisq Df Pr(>|Chi|)  \n1 -366.57                       \n2 -361.50 10.135  3    0.01745 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLa variable con mayor significancia es FAB, por lo tanto la agregamos al modelo reducido. Repetimos el proceso una vez más con el nuevo modelo completo:\n\nmodelo1_2_1 <- update(modelo1_2,formula. = .~.+waiting)\n\nanova(modelo1_2,modelo1_2_1)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = t2, event = d3)\n Model 1: ~ group + FAB\n Model 2: ~ group + FAB + waiting\n   loglik  Chisq Df Pr(>|Chi|)\n1 -362.42                     \n2 -361.76 1.3375  1     0.2475\n\nmodelo1_2_2 <- update(modelo1_2,formula. = .~.+MTX)\n\nanova(modelo1_2,modelo1_2_2)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = t2, event = d3)\n Model 1: ~ group + FAB\n Model 2: ~ group + FAB + MTX\n   loglik Chisq Df Pr(>|Chi|)\n1 -362.42                    \n2 -361.45 1.958  1     0.1617\n\nmodelo1_2_3 <- update(modelo1_2,formula. = .~.+SXPa*SXDo)\n\nanova(modelo1_2,modelo1_2_3)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = t2, event = d3)\n Model 1: ~ group + FAB\n Model 2: ~ group + FAB + SXPa + SXDo + SXPa:SXDo\n   loglik Chisq Df Pr(>|Chi|)\n1 -362.42                    \n2 -361.97 0.901  3     0.8252\n\nmodelo1_2_4 <- update(modelo1_2,formula. = .~.+CMVPa*CMVDo)\n\nanova(modelo1_2,modelo1_2_4)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = t2, event = d3)\n Model 1: ~ group + FAB\n Model 2: ~ group + FAB + CMVPa + CMVDo + CMVPa:CMVDo\n   loglik  Chisq Df Pr(>|Chi|)\n1 -362.42                     \n2 -362.41 0.0208  3     0.9992\n\nmodelo1_2_5 <- update(modelo1_2,formula. = .~.+AgePa*AgeDo)\n\nanova(modelo1_2,modelo1_2_5)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = t2, event = d3)\n Model 1: ~ group + FAB\n Model 2: ~ group + FAB + AgePa + AgeDo + AgePa:AgeDo\n   loglik  Chisq Df Pr(>|Chi|)  \n1 -362.42                       \n2 -356.89 11.061  3     0.0114 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLa siguiente variable a incluir es la interacción de la edad del donante y paciente y sus efectos principales. Volvemos a hacer el análisis de nuevo:\n\nmodelo1_2_5_1 <- update(modelo1_2_5,formula. = .~.+waiting)\n\nanova(modelo1_2_5,modelo1_2_5_1)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = t2, event = d3)\n Model 1: ~ group + FAB + AgePa + AgeDo + AgePa:AgeDo\n Model 2: ~ group + FAB + AgePa + AgeDo + waiting + AgePa:AgeDo\n   loglik Chisq Df Pr(>|Chi|)\n1 -356.89                    \n2 -356.64 0.499  1     0.4799\n\nmodelo1_2_5_2 <- update(modelo1_2_5,formula. = .~.+MTX)\n\nanova(modelo1_2_5,modelo1_2_5_2)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = t2, event = d3)\n Model 1: ~ group + FAB + AgePa + AgeDo + AgePa:AgeDo\n Model 2: ~ group + FAB + AgePa + AgeDo + MTX + AgePa:AgeDo\n   loglik  Chisq Df Pr(>|Chi|)\n1 -356.89                     \n2 -356.20 1.3976  1     0.2371\n\nmodelo1_2_5_3 <- update(modelo1_2_5,formula. = .~.+SXPa*SXDo)\n\nanova(modelo1_2_5,modelo1_2_5_3)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = t2, event = d3)\n Model 1: ~ group + FAB + AgePa + AgeDo + AgePa:AgeDo\n Model 2: ~ group + FAB + AgePa + AgeDo + SXPa + SXDo + AgePa:AgeDo + SXPa:SXDo\n   loglik  Chisq Df Pr(>|Chi|)\n1 -356.89                     \n2 -356.21 1.3677  3     0.7131\n\nmodelo1_2_5_4 <- update(modelo1_2_5,formula. = .~.+CMVPa*CMVDo)\n\nanova(modelo1_2_5,modelo1_2_5_4)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = t2, event = d3)\n Model 1: ~ group + FAB + AgePa + AgeDo + AgePa:AgeDo\n Model 2: ~ group + FAB + AgePa + AgeDo + CMVPa + CMVDo + AgePa:AgeDo + CMVPa:CMVDo\n   loglik  Chisq Df Pr(>|Chi|)\n1 -356.89                     \n2 -356.61 0.5644  3     0.9045\n\n\ny por lo tanto no agregamos variables adicionales. El modelo final tendría el siguiente resumen:\n\nsummary(modelo1_2_5)\n\nCall:\ncoxph(formula = Surv(time = t2, event = d3) ~ group + FAB + AgePa + \n    AgeDo + AgePa:AgeDo, data = bmt)\n\n  n= 137, number of events= 83 \n\n                  coef  exp(coef)   se(coef)      z Pr(>|z|)    \ngroup2      -1.0906476  0.3359988  0.3542790 -3.078 0.002080 ** \ngroup3      -0.4039052  0.6677074  0.3627767 -1.113 0.265549    \nFAB1         0.8374156  2.3103883  0.2784644  3.007 0.002636 ** \nAgePa        0.0068204  1.0068437  0.0196830  0.347 0.728959    \nAgeDo        0.0038723  1.0038798  0.0182562  0.212 0.832021    \nAgePa:AgeDo  0.0031593  1.0031643  0.0009508  3.323 0.000891 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n            exp(coef) exp(-coef) lower .95 upper .95\ngroup2         0.3360     2.9762    0.1678    0.6728\ngroup3         0.6677     1.4977    0.3279    1.3595\nFAB1           2.3104     0.4328    1.3386    3.9876\nAgePa          1.0068     0.9932    0.9687    1.0464\nAgeDo          1.0039     0.9961    0.9686    1.0405\nAgePa:AgeDo    1.0032     0.9968    1.0013    1.0050\n\nConcordance= 0.665  (se = 0.033 )\nLikelihood ratio test= 32.8  on 6 df,   p=1e-05\nWald test            = 33.02  on 6 df,   p=1e-05\nScore (logrank) test = 35.75  on 6 df,   p=3e-06\n\n\n\n\n4.9.5 Covariables dependientes del tiempo\nAhora vamos a considerar una variable dependiente del tiempo definida por:\n\\[\\begin{align}\nZ_A(t)=\\begin{cases}\n0 & \\text{si $t<ta$}\\\\\n1 & \\text{si no.}\n\\end{cases}\n\\end{align}\\]\ndonde ta es el tiempo de ocurrencia de la enfermedad aguda de injerto contra huésped. Para incorporar esta covariable ajustamos la tabla de la siguiente forma:\n\nbmt_2 <- bmt_2 %>% mutate(id=1:n())\n\nnewbmt_2 <- tmerge(data1 = bmt_2,data2 = bmt_2,id = id,tstop = t2)\n\nnewbmt_2 <- tmerge(data1 = newbmt_2,data2 = bmt_2,id = id,ZA=tdc(ta))\n\nTambién tenemos las siguientes dos variables que dependen del tiempo:\n\\[\\begin{align}\nZ_P(t)=\\begin{cases}\n0 & \\text{si $t<tp$}\\\\\n1 & \\text{si no.}\n\\end{cases}\n\\end{align}\\]\ny\n\\[\\begin{align}\nZ_C(t)=\\begin{cases}\n0 & \\text{si $t<tc$}\\\\\n1 & \\text{si no.}\n\\end{cases}\n\\end{align}\\]\nson las indicadoras de recuperación de plaquetas y de enfermedad crónica de injerto contra huésped respectivamente. Las incluimos en la base:\n\nnewbmt_2 <- tmerge(data1 = newbmt_2,data2 = bmt_2,id = id,ZP=tdc(tp))\n\nnewbmt_2 <- tmerge(data1 = newbmt_2,data2 = bmt_2,id = id,ZC=tdc(tc),muerte=event(t2,d3))\n\ny la base queda así:\n\nhead(newbmt_2,10)\n\n     t2 d3 group waiting FAB MTX SXPa SXDo CMVPa CMVDo AgePa AgeDo   ta  tc tp\n1  2081  0     1      98   0   0    1    0     1     1    -2     5   67 121 13\n2  2081  0     1      98   0   0    1    0     1     1    -2     5   67 121 13\n3  2081  0     1      98   0   0    1    0     1     1    -2     5   67 121 13\n4  2081  0     1      98   0   0    1    0     1     1    -2     5   67 121 13\n5  1602  0     1    1720   0   0    1    1     0     0    -7     9 1602 139 18\n6  1602  0     1    1720   0   0    1    1     0     0    -7     9 1602 139 18\n7  1602  0     1    1720   0   0    1    1     0     0    -7     9 1602 139 18\n8  1496  0     1     127   0   0    1    1     1     0    -2     7 1496 307 12\n9  1496  0     1     127   0   0    1    1     1     0    -2     7 1496 307 12\n10 1496  0     1     127   0   0    1    1     1     0    -2     7 1496 307 12\n   id tstart tstop ZA ZP ZC muerte\n1   1      0    13  0  0  0      0\n2   1     13    67  0  1  0      0\n3   1     67   121  1  1  0      0\n4   1    121  2081  1  1  1      0\n5   2      0    18  0  0  0      0\n6   2     18   139  0  1  0      0\n7   2    139  1602  0  1  1      0\n8   3      0    12  0  0  0      0\n9   3     12   307  0  1  0      0\n10  3    307  1496  0  1  1      0\n\n\nAjustamos un modelo que incluya la primer covariable \\(Z_A(t)\\) sobre el modelo reducido que contiene solamente el grupo de riesgo:\n\nmodelo2 <- coxph(Surv(time = tstart,time2 = tstop,event = muerte)~group+ZA,data = newbmt_2)\n\nmodelo1 <- update(modelo2,formula. = .~.-ZA)\n\nanova(modelo1,modelo2)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = tstart, time2 = tstop, event = muerte)\n Model 1: ~ group\n Model 2: ~ group + ZA\n   loglik  Chisq Df Pr(>|Chi|)\n1 -366.57                     \n2 -365.97 1.2034  1     0.2726\n\n\ny hacemos lo mismo con modelos que incluyan de forma univariada las otras dos variables dependientes del tiempo:\n\nmodelo3 <- coxph(Surv(time = tstart,time2 = tstop,event = muerte)~group+ZC,data = newbmt_2)\n\nanova(modelo1,modelo3)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = tstart, time2 = tstop, event = muerte)\n Model 1: ~ group\n Model 2: ~ group + ZC\n   loglik  Chisq Df Pr(>|Chi|)\n1 -366.57                     \n2 -366.36 0.4152  1     0.5193\n\nmodelo4 <- coxph(Surv(time = tstart,time2 = tstop,event = muerte)~group+ZP,data = newbmt_2)\n\nanova(modelo1,modelo4)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = tstart, time2 = tstop, event = muerte)\n Model 1: ~ group\n Model 2: ~ group + ZP\n   loglik Chisq Df Pr(>|Chi|)   \n1 -366.57                       \n2 -361.86 9.421  1   0.002145 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nEn donde se puede notar que la variable \\(Z_P(t)\\) en significativa sobre un modelo reducido en donde solamente esté el grupo de riesgo de 3 niveles.\nAhora vamos a comparar el modelo completo que se obtuvo con selección para adelante con respecto al mismo modelo añadiendo la variable que depende del tiempo \\(Z_P(t)\\):\n\nmodeloc1 <- coxph(formula = Surv(time = tstart,time2 = tstop,event = muerte) ~ group + FAB + AgePa*AgeDo, data = newbmt_2)\n\nmodeloc2 <- update(modeloc1,formula. = .~.+ZP)\n\nanova(modeloc1,modeloc2)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = tstart, time2 = tstop, event = muerte)\n Model 1: ~ group + FAB + AgePa * AgeDo\n Model 2: ~ group + FAB + AgePa + AgeDo + ZP + AgePa:AgeDo\n   loglik  Chisq Df Pr(>|Chi|)   \n1 -356.89                        \n2 -353.33 7.1311  1   0.007576 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPor lo tanto la variable \\(Z_P(t)\\) sí es significativa sobre el modelo reducido con covariables fijas, ante los niveles usuales.\nAhora analizamos la inclusión de las interacciones de las covariables fijas con la variable \\(Z_P(t)\\) usando selección forward:\n\nmodeloc2_1 <- update(modeloc2,formula. = .~.+ZP:group)\n\nanova(modeloc2_1,modeloc2)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = tstart, time2 = tstop, event = muerte)\n Model 1: ~ group + FAB + AgePa + AgeDo + ZP + AgePa:AgeDo + group:ZP\n Model 2: ~ group + FAB + AgePa + AgeDo + ZP + AgePa:AgeDo\n   loglik  Chisq Df Pr(>|Chi|)  \n1 -349.89                       \n2 -353.33 6.8765  2    0.03212 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmodeloc2_2 <- update(modeloc2,formula. = .~.+ZP:FAB)\n\nanova(modeloc2_2,modeloc2)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = tstart, time2 = tstop, event = muerte)\n Model 1: ~ group + FAB + AgePa + AgeDo + ZP + AgePa:AgeDo + FAB:ZP\n Model 2: ~ group + FAB + AgePa + AgeDo + ZP + AgePa:AgeDo\n   loglik  Chisq Df Pr(>|Chi|)  \n1 -351.63                       \n2 -353.33 3.4025  1     0.0651 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmodeloc2_3 <- update(modeloc2,formula. = .~.+ZP*AgePa*AgeDo)\n\nanova(modeloc2_3,modeloc2)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = tstart, time2 = tstop, event = muerte)\n Model 1: ~ group + FAB + AgePa + AgeDo + ZP + AgePa:AgeDo + AgePa:ZP + AgeDo:ZP + AgePa:AgeDo:ZP\n Model 2: ~ group + FAB + AgePa + AgeDo + ZP + AgePa:AgeDo\n   loglik  Chisq Df Pr(>|Chi|)  \n1 -349.44                       \n2 -353.33 7.7836  3     0.0507 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\ncomo el valor p más pequeño se obtiene al incluir la interacción ZP-group, entonces aumentamos el modelo de esa forma. Seguimos con el proceso:\n\nmodeloc2_1_1 <- update(modeloc2_1,formula. = .~.+ZP:FAB)\n\nanova(modeloc2_1_1,modeloc2_1)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = tstart, time2 = tstop, event = muerte)\n Model 1: ~ group + FAB + AgePa + AgeDo + ZP + AgePa:AgeDo + group:ZP + FAB:ZP\n Model 2: ~ group + FAB + AgePa + AgeDo + ZP + AgePa:AgeDo + group:ZP\n   loglik  Chisq Df Pr(>|Chi|)  \n1 -347.76                       \n2 -349.89 4.2654  1     0.0389 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmodeloc2_1_2 <- update(modeloc2_1,formula. = .~.+ZP*AgePa*AgeDo)\n\nanova(modeloc2_1_2,modeloc2_1)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = tstart, time2 = tstop, event = muerte)\n Model 1: ~ group + FAB + AgePa + AgeDo + ZP + AgePa:AgeDo + group:ZP + AgePa:ZP + AgeDo:ZP + AgePa:AgeDo:ZP\n Model 2: ~ group + FAB + AgePa + AgeDo + ZP + AgePa:AgeDo + group:ZP\n   loglik  Chisq Df Pr(>|Chi|)   \n1 -343.81                        \n2 -349.89 12.157  3   0.006863 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAgregamos la interacción ZP-Edad, y finalmente vemos si la última interacción es signficativa sobre este modelo completo:\n\nmodeloc2_1_2_1 <- update(modeloc2_1_2,formula. = .~.+ZP:FAB)\n\nanova(modeloc2_1_2_1,modeloc2_1_2)\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(time = tstart, time2 = tstop, event = muerte)\n Model 1: ~ group + FAB + AgePa + AgeDo + ZP + AgePa:AgeDo + group:ZP + AgePa:ZP + AgeDo:ZP + FAB:ZP + AgePa:AgeDo:ZP\n Model 2: ~ group + FAB + AgePa + AgeDo + ZP + AgePa:AgeDo + group:ZP + AgePa:ZP + AgeDo:ZP + AgePa:AgeDo:ZP\n   loglik  Chisq Df Pr(>|Chi|)  \n1 -341.50                       \n2 -343.81 4.6133  1    0.03172 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\ny también lo incluimos asumiendo un nivel de significancia del 5%. El modelo final queda:\n\nsummary(modeloc2_1_2_1)\n\nCall:\ncoxph(formula = Surv(time = tstart, time2 = tstop, event = muerte) ~ \n    group + FAB + AgePa + AgeDo + ZP + AgePa:AgeDo + group:ZP + \n        AgePa:ZP + AgeDo:ZP + FAB:ZP + AgePa:AgeDo:ZP, data = newbmt_2)\n\n  n= 341, number of events= 83 \n\n                     coef  exp(coef)   se(coef)      z Pr(>|z|)    \ngroup2          1.3259769  3.7658623  0.8195521  1.618 0.105678    \ngroup3          1.1345132  3.1096595  1.2249850  0.926 0.354371    \nFAB1           -1.2506736  0.2863119  1.1125887 -1.124 0.260966    \nAgePa          -0.1537743  0.8574656  0.0545406 -2.819 0.004811 ** \nAgeDo           0.1163506  1.1233897  0.0434345  2.679 0.007389 ** \nZP             -0.2868383  0.7506331  0.6954226 -0.412 0.679998    \nAgePa:AgeDo     0.0025965  1.0025998  0.0019434  1.336 0.181543    \ngroup2:ZP      -3.0569781  0.0470296  0.9265028 -3.299 0.000969 ***\ngroup3:ZP      -1.8945809  0.1503814  1.2914215 -1.467 0.142362    \nAgePa:ZP        0.1932964  1.2132423  0.0587831  3.288 0.001008 ** \nAgeDo:ZP       -0.1467497  0.8635101  0.0480649 -3.053 0.002264 ** \nFAB1:ZP         2.4709992 11.8342655  1.1594144  2.131 0.033069 *  \nAgePa:AgeDo:ZP  0.0001393  1.0001393  0.0022979  0.061 0.951673    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n               exp(coef) exp(-coef) lower .95 upper .95\ngroup2           3.76586     0.2655  0.755545   18.7702\ngroup3           3.10966     0.3216  0.281841   34.3101\nFAB1             0.28631     3.4927  0.032345    2.5344\nAgePa            0.85747     1.1662  0.770534    0.9542\nAgeDo            1.12339     0.8902  1.031713    1.2232\nZP               0.75063     1.3322  0.192080    2.9334\nAgePa:AgeDo      1.00260     0.9974  0.998788    1.0064\ngroup2:ZP        0.04703    21.2632  0.007651    0.2891\ngroup3:ZP        0.15038     6.6498  0.011966    1.8900\nAgePa:ZP         1.21324     0.8242  1.081213    1.3614\nAgeDo:ZP         0.86351     1.1581  0.785877    0.9488\nFAB1:ZP         11.83427     0.0845  1.219680  114.8250\nAgePa:AgeDo:ZP   1.00014     0.9999  0.995645    1.0047\n\nConcordance= 0.735  (se = 0.027 )\nLikelihood ratio test= 63.58  on 13 df,   p=1e-08\nWald test            = 60.54  on 13 df,   p=4e-08\nScore (logrank) test = 74.92  on 13 df,   p=1e-10\n\n\n\n\n4.9.6 Prueba alternativa de riesgos proporcionales:\n\nmodelou1 <- coxph(Surv(time=t2, event=d3) ~ group+waiting+FAB+MTX+CMVPa+CMVDo+AgePa+AgeDo, data=bmt_2)\n\nresu1 <- cox.zph(modelou1)\n\nresu1$table\n\n             chisq df           p\ngroup    2.3343408  2 0.311246401\nwaiting  0.2570982  1 0.612120763\nFAB      0.3166363  1 0.573636142\nMTX      8.2423697  1 0.004092367\nCMVPa    0.2360214  1 0.627094548\nCMVDo    0.6284502  1 0.427924365\nAgePa    0.6954160  1 0.404328284\nAgeDo    3.5213560  1 0.060582862\nGLOBAL  18.0494765  9 0.034603845\n\n\nEsta prueba se basa en los residuos estandarizados de Schoenfeld y no en la prueba que aparece en el Klein. En unas semanas estaremos profundizando en este tema de residuos. La implementación de la prueba de riesgos proporcionales se ilustra para dos variables:\n\nmodelou2_1 <- coxph(Surv(time=t2, event=d3) ~ waiting+tt(waiting), data=bmt_2,tt=function(x,t, ...) x*log(t))\n\nsummary(modelou2_1)\n\nCall:\ncoxph(formula = Surv(time = t2, event = d3) ~ waiting + tt(waiting), \n    data = bmt_2, tt = function(x, t, ...) x * log(t))\n\n  n= 137, number of events= 83 \n\n                  coef  exp(coef)   se(coef)      z Pr(>|z|)\nwaiting      7.484e-06  1.000e+00  1.297e-03  0.006    0.995\ntt(waiting) -1.759e-05  1.000e+00  2.480e-04 -0.071    0.943\n\n            exp(coef) exp(-coef) lower .95 upper .95\nwaiting             1          1    0.9975     1.003\ntt(waiting)         1          1    0.9995     1.000\n\nConcordance= 0.453  (se = 0.031 )\nLikelihood ratio test= 0.08  on 2 df,   p=1\nWald test            = 0.07  on 2 df,   p=1\nScore (logrank) test = 0.07  on 2 df,   p=1\n\nbmt_3 <- bmt %>% mutate(MTX2=as.numeric(MTX)-1)\n\nmodelou2_2 <- coxph(Surv(time=t2, event=d3) ~ MTX2+tt(MTX2), data=bmt_3,tt=function(x,t, ...) x*log(t))\n\nsummary(modelou2_2)\n\nCall:\ncoxph(formula = Surv(time = t2, event = d3) ~ MTX2 + tt(MTX2), \n    data = bmt_3, tt = function(x, t, ...) x * log(t))\n\n  n= 137, number of events= 83 \n\n            coef exp(coef) se(coef)      z Pr(>|z|)  \nMTX2      2.6926   14.7706   1.1258  2.392   0.0168 *\ntt(MTX2) -0.4616    0.6303   0.2219 -2.080   0.0376 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n         exp(coef) exp(-coef) lower .95 upper .95\nMTX2       14.7706     0.0677     1.626  134.1903\ntt(MTX2)    0.6303     1.5865     0.408    0.9738\n\nConcordance= 0.58  (se = 0.027 )\nLikelihood ratio test= 7.78  on 2 df,   p=0.02\nWald test            = 7.02  on 2 df,   p=0.03\nScore (logrank) test = 8.6  on 2 df,   p=0.01\n\n\nA partir de los cálculos anteriores y la tabla 9.5 concluimos que la variable que tiene más evidencia de no seguir la hipótesis de riesgos proporcionales es MTX.\nUna posible forma de solucionar la dependencia temporal del riesgo relativo de MTX es a través de la estratificación del modelo anterior de Cox:\n\nmodeloc2_est <- update(modeloc2,formula. = .~.+strata(MTX))\n\nsummary(modeloc2_est)\n\nCall:\ncoxph(formula = Surv(time = tstart, time2 = tstop, event = muerte) ~ \n    group + FAB + AgePa + AgeDo + ZP + strata(MTX) + AgePa:AgeDo, \n    data = newbmt_2)\n\n  n= 341, number of events= 83 \n\n                  coef  exp(coef)   se(coef)      z Pr(>|z|)   \ngroup2      -0.9904320  0.3714162  0.3664891 -2.702  0.00688 **\ngroup3      -0.3602323  0.6975143  0.3712785 -0.970  0.33192   \nFAB1         0.8918863  2.4397273  0.2833168  3.148  0.00164 **\nAgePa        0.0093842  1.0094283  0.0198368  0.473  0.63616   \nAgeDo       -0.0015376  0.9984636  0.0179129 -0.086  0.93160   \nZP          -0.9951417  0.3696711  0.3458298 -2.878  0.00401 **\nAgePa:AgeDo  0.0025651  1.0025684  0.0009374  2.736  0.00621 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n            exp(coef) exp(-coef) lower .95 upper .95\ngroup2         0.3714     2.6924    0.1811    0.7618\ngroup3         0.6975     1.4337    0.3369    1.4441\nFAB1           2.4397     0.4099    1.4002    4.2511\nAgePa          1.0094     0.9907    0.9709    1.0494\nAgeDo          0.9985     1.0015    0.9640    1.0341\nZP             0.3697     2.7051    0.1877    0.7281\nAgePa:AgeDo    1.0026     0.9974    1.0007    1.0044\n\nConcordance= 0.712  (se = 0.029 )\nLikelihood ratio test= 38.2  on 7 df,   p=3e-06\nWald test            = 40.28  on 7 df,   p=1e-06\nScore (logrank) test = 44.49  on 7 df,   p=2e-07\n\n\neste resultado se puede comparar con la tabla 9.7. Como ejercicio les recomiendo completar la tabla 9.8 a través de la comparación de los coeficientes de los dos modelos con datos restringidos sobre MTX:\n\nmodeloc2_est_1 <- update(modeloc2,data=subset(newbmt_2,subset = MTX==1))\n\ncoefficients(modeloc2_est_1)\n\n      group2       group3         FAB1        AgePa        AgeDo           ZP \n-0.563717043 -0.858281947  0.344075277  0.011525761  0.034240833 -1.006880993 \n AgePa:AgeDo \n 0.001384428 \n\nmodeloc2_est_2 <- update(modeloc2,data=subset(newbmt_2,subset = MTX==0))\n\ncoefficients(modeloc2_est_2)\n\n      group2       group3         FAB1        AgePa        AgeDo           ZP \n-1.196548537 -0.290254448  1.088960082  0.027276837 -0.020204863 -0.867470829 \n AgePa:AgeDo \n 0.002270538 \n\n\n\n\n4.9.7 Datos truncados por la izquierda\nComo último cálculo se hará el ajuste del modelo estratificado con MTX pero considerando solamente pacientes que cuyas plaquetas hayan retornado a un nivel normal (variable \\(Z_P(t)\\)):\n\nnewbmt_2_ZP <- newbmt_2 %>% filter(ZP==1)\n\nmodeloc2_est_trunc <- update(modeloc2_est,formula. = .~.-ZP,data=newbmt_2_ZP)\n\nsummary(modeloc2_est_trunc)\n\nCall:\ncoxph(formula = Surv(time = tstart, time2 = tstop, event = muerte) ~ \n    group + FAB + AgePa + AgeDo + strata(MTX) + AgePa:AgeDo, \n    data = newbmt_2_ZP)\n\n  n= 195, number of events= 67 \n\n                 coef exp(coef)  se(coef)      z Pr(>|z|)    \ngroup2      -1.752137  0.173403  0.437522 -4.005 6.21e-05 ***\ngroup3      -0.747627  0.473489  0.407626 -1.834   0.0666 .  \nFAB1         1.278075  3.589722  0.324847  3.934 8.34e-05 ***\nAgePa        0.041660  1.042540  0.022294  1.869   0.0617 .  \nAgeDo       -0.034750  0.965846  0.020675 -1.681   0.0928 .  \nAgePa:AgeDo  0.002300  1.002302  0.001224  1.878   0.0603 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n            exp(coef) exp(-coef) lower .95 upper .95\ngroup2         0.1734     5.7669   0.07356    0.4088\ngroup3         0.4735     2.1120   0.21298    1.0526\nFAB1           3.5897     0.2786   1.89911    6.7853\nAgePa          1.0425     0.9592   0.99797    1.0891\nAgeDo          0.9658     1.0354   0.92749    1.0058\nAgePa:AgeDo    1.0023     0.9977   0.99990    1.0047\n\nConcordance= 0.72  (se = 0.033 )\nLikelihood ratio test= 37.3  on 6 df,   p=2e-06\nWald test            = 32.27  on 6 df,   p=1e-05\nScore (logrank) test = 36.19  on 6 df,   p=3e-06"
  },
  {
    "objectID": "DRSP.html#residuos-de-cox-snell",
    "href": "DRSP.html#residuos-de-cox-snell",
    "title": "5  Análisis de Diagnósticos en el Modelo de Cox",
    "section": "5.1 Residuos de Cox-Snell",
    "text": "5.1 Residuos de Cox-Snell\nSuponga que un modelo de Cox se ha ajustado a los datos \\((T_j,\\delta_j,Z_j)\\) para \\(j=1,\\ldots,n\\). Además asuma que las covariables son estáticas (no dependen del tiempo). Debido a que:\n\\[S(X_j|Z_j)=1-F_T(X_j|Z_j)\\sim \\text{Unif}(0,1)\\]\nEntonces:\n\\[U=H(X_j|Z_j)=-\\log S(X_j|Z_j)\\sim \\text{Exp}(1)\\] donde \\(X_j\\): tiempo de ocurrencia del riesgo del individuo \\(j\\)-ésimo. Si \\(b=(b_1,\\ldots,b_p)^T\\) es un estimador de \\(\\beta\\) entonces los residuos de Cox-Snell se definen como:\n\\[r_j=\\hat H_0(t)\\exp\\left(\\sum_{k=1}^pZ_{jk}b_k\\right),\\qquad j=1,\\ldots,n\\] donde \\(\\hat H_0(t)\\) es el estimador de Breslow de \\(H_0(t)\\).\nSi el modelo de Cox es correcto entonces \\(\\{r_j\\}_{j=1}^n\\) es una muestra censurada de \\(\\text{Exp}(1)\\).\n\nCalcule el estimador de Nelson-Aalen de \\(H(t)\\) usando la muestra \\(\\{r_t\\}\\). Bajo la hipótesis de bondad de ajuste:\n\n\\[H(t)=t\\] 2. Grafique \\(r_j\\) versus \\(\\hat H(r_j)\\) para \\(j=1,\\ldots,n\\):\n\n\n\n\n\nResiduos de Cox-Snell\n\n\n\n\nNota: el estimador de Cox-Snell se puede definir en casos en donde las covariables dependen del tiempo y/o modelos estratificados:\n\\[r_j=\\hat H_0(T_j)\\exp\\left(\\sum_{k=1}^pZ_{jk}(T_j)b_k\\right),\\qquad j=1,\\ldots,n\\]"
  },
  {
    "objectID": "DRSP.html#residuos-martingala",
    "href": "DRSP.html#residuos-martingala",
    "title": "5  Análisis de Diagnósticos en el Modelo de Cox",
    "section": "5.2 Residuos Martingala",
    "text": "5.2 Residuos Martingala\nObjetivo: definir posibles transformaciones sobre las covariables que permitan mejorar la capacidad explicativa de un modelo de Cox.\nSuponga que \\(Z_j(t)\\) son covariables del individuo \\(j\\)-ésimo en el tiempo \\(t\\). Defina:\n\\[N_j(t)=\\begin{cases}\n1 & \\text{individuo j-esimo ha experimentado el riesgo al tiempo t}\\\\\n0 & \\text{si no.}\n\\end{cases}\n\\]\n\\[Y_j(t)=\\begin{cases}\n1 & \\text{individuo j-esimo está bajo estudio inmediatamente antes del tiempo t}\\\\\n0 & \\text{si no.}\n\\end{cases}\n\\]\nEl residuo martingala se define como:\n\\[\\hat M_j=N_j(\\infty)-\\int_0^\\infty Y_j(t)\\exp[b^TZ_j(t)]d\\hat H_0(t)\\]\nsi los datos son censurados por la derecha y las covariables son fijas entonces:\n\\[\\hat M_j=\\delta_j-\\hat H_0(T_j)\\exp\\left(\\sum_{k=1}^pZ_{jk}b_k\\right)=\\delta_j-r_j \\qquad j=1,\\ldots,n\\]\nPropiedades:\n\n\\(\\sum_{j=1}^n \\hat M_j=0\\)\nPara muestras grandes \\(\\{\\hat M_j\\}\\) son variables independientes con medias 0.\nSi \\(b=\\beta\\) y \\(\\hat H=H_0\\) (valores reales) entonces \\(M_j\\) es martingala ya que:\n\n\\[\\hat M_j=\\text{número observado de eventos}-\\text{número esperado de eventos bajo el modelo de Cox}\\]\nEntonces:\n\\[E[\\hat M_j|\\text{Información hasta tiempo t}]=0\\]\nPor otro lado, con el fin de resolver el objetivo, suponga que la covariable \\(Z\\) se divide en dos partes: \\(Z^*\\) (covariables con forma funcional conocida) y \\(Z_1\\) (covariables sin forma funcional conocida).\nSuponga además que \\(Z_1\\) es independiente de \\(Z^*\\).\nSea \\(f(Z_1)\\) la mejor función de \\(Z_1\\) que explica su efecto en la sobrevivencia a través del modelo de Cox:\n\\[h(t|Z^*,Z_1)=h_0(t)\\exp[\\beta^*Z^*]\\exp[f(Z_1)]\\]\nProcedimiento para encontrar \\(f\\):\n\nAjuste un modelo de Cox usando \\(Z^*\\) y calcule \\(\\hat M_j\\) para \\(j=1,\\ldots,n\\)\nGrafique\n\n\n\n\n\n\nResiduos Martingala"
  },
  {
    "objectID": "DRSP.html#análisis-descriptivo-del-supuesto-de-riesgos-proporcionales",
    "href": "DRSP.html#análisis-descriptivo-del-supuesto-de-riesgos-proporcionales",
    "title": "5  Análisis de Diagnósticos en el Modelo de Cox",
    "section": "5.3 Análisis descriptivo del Supuesto de Riesgos Proporcionales",
    "text": "5.3 Análisis descriptivo del Supuesto de Riesgos Proporcionales\nAsuma que \\(Z=(Z_1^T,Z_2^T)^T\\) donde \\(Z_1\\): covariable a la que se le va a analizar el supuesto de riesgos proporcionales y \\(Z_2\\): vector de \\(p-1\\) restantes covariables. Asuma que no hay interacción entre \\(Z_1\\) y \\(Z_2\\).\nPrimer gráfico\n\nSepare \\(Z_1\\) en \\(k\\) estratos disjuntos (llámese \\(G_1,\\ldots,G_k\\) a los estratos en el caso continuo o bien en el caso discreto los valores de \\(Z_1\\) se pueden etiquetar como \\(1,\\ldots,k\\)).\nEstime un modelo de Cox estratificado sobre los niveles de \\(Z_1\\).\nSea \\(\\hat H_{g0}\\) la tasa acumulada base de riesgo en el estrato \\(g\\)-ésimo. (\\(\\hat H_{g0}(t)\\) debe ser proporcional entre distintos valores de \\(g=1,\\ldots,k\\)).\nGrafique \\(t\\) versus \\(\\log[\\hat H_{g0}(t)]\\). Bajo el supuesto de riesgos proporcionales los gráficos deberían ser lineales.\nOtro gráfico posible es \\(\\log[\\hat H_{g0}(t)]-\\log[\\hat H_{10}(t)]\\) versus \\(t\\). En este caso cada gráfico debería ser aproximadamente constante bajo el mismo supuesto.\n\nInconveniente: los gráficos no dan información detallada del tipo de desviación que tuvo una covariable con respecto al supuesto de riesgos proporcionales.\nSegundo gráfico (Gráfico de Andersen)\n\nGrafique \\(\\hat H_{g0}(t)\\) versus \\(\\hat H_{10}(t)\\) para \\(g=2,\\ldots,k\\). Bajo el supuesto de riesgos proporcionales, las curvas deben ser líneas rectas a través del origen.\n\nSi \\(H_{g0}(t)=e^{\\gamma_g}H_{10}(t)\\) entonces la pendiente de la curva es un estimador de \\(e^{\\gamma_g}\\).\nInconveniente: la varianza de \\(\\hat H_{g0}(t)\\) depende de \\(t\\), por lo tanto los tres gráficos deben ser interpretados con cuidado.\nTercer gráfico (Gráfico de Arjas)\nSuponga que un modelo de Cox ha sido ajustado con un vector \\(Z^*\\) de covariables (de tamaño \\(p\\)) y se quiere comprobar si una nueva covariable \\(Z\\):\n\nDebe ser incluida en el modelo.\n\\(Z\\) tiene riesgos proporcionales después de incluir \\(Z^*\\).\n\nSea \\(\\hat H(t|Z_j^*)\\) la tasa de riesgo del modelo ajustado para el\nindividuo \\(j\\)-ésimo. Bajo una agrupación de la covariable \\(Z\\) en \\(k\\)\nestratos se calcula para cada uno de ellos:\n\\[TOT_g(t_i)=\\sum_{Z_{1j}=g}\\hat H(\\min(t_i,T_j)|Z_j^*)\\] el cual es el\ntiempo total esperado a prueba. El número observado de eventos que han\nocurrido hasta tiempo \\(t_i\\) es:\n\\[N_{g}(t_i)=\\sum_{Z_{1j}=g}\\delta_j1(T_j\\leq t_i)\\]\nSi la covariable \\(Z\\) no necesita estar en el modelo entonces\n\\(N_g(t_i)-TOT_g(t_i)\\) es una martingala, para cada \\(g\\).\n\n\n\n\n\nGráfico de Arjas\n\n\n\n\nSi la covariable \\(Z\\) debe ser incluida en el modelo entonces:\n\\[h(t|Z=g,Z^*)=h_0(t)\\exp(\\gamma_g)\\exp(\\beta^TZ^*)\\] y las curvas son\naproximadamente lineales con pendientes distintas de 1. Si \\(Z\\) no\nsatisface el principio de riesgos proporcionales entonces las curvas no\nson lineales y su pendiente difiere de 1.\nCuarto gráfico (Residuos score)\nSe ajusta un modelo de Cox sobre las \\(p\\) covariables. Sea \\(b\\) el\nestimador de verosimilitud parcial de \\(\\beta\\) y \\(\\hat H_0(t)\\) la tasa de\nriesgo base estimada. Considere:\n\n\\(N_j(t)\\): indicadora de que el \\(j\\)-ésimo paciente/sujeto ha\nexperimentado el riesgo en tiempo \\(t\\)\n\\(Y_j(t)\\): indicadora de que el \\(j\\)-ésimo sujeto está bajo estudio\njusto antes del tiempo \\(t\\).\n\nPara la \\(k\\)-ésima covariable defina:\n\\[\\bar Z_k(t)=\\frac{\\sum_{j=1}^n Y_j(t)Z_{jk}(t)\\exp[b^TZ_j(t)]}{\\sum_{j=1}^n Y_j(t)\\exp[b^TZ_j(t)]}\\]\nel cual es un promedio ponderado de \\(Z_{jk}(t)\\) y sea \\(\\hat M_j(t)\\) el\nresiduo martingala al tiempo \\(t\\) para el individuo \\(j\\)-ésimo:\n\\[\\hat M_j(t)=N_j(t)-\\int_0^tY_j(u)\\exp[b^TZ_j(u)]d\\hat H_0(u)\\qquad j=1,\\ldots,n\\]\nEl residuo score para la \\(k\\)-ésima covariable y el individuo \\(j\\)-ésimo\nse define como:\n\\[S_{jk}(t)=\\int_0^t[Z_{jk}(u)-\\bar Z_k(u)]d\\hat M_j(u)\\] El proceso\nscore para la \\(k\\)-ésima covariable es:\n\\[U_k(t)=\\sum_{j=1}^n S_{jk}(t)\\] En el caso de que todas las\ncovariables son fijas en tiempo 0 entonces:\n\\[U_k(t)=\\sum_{\\text{muertes}\\leq t}\\underbrace{[Z_{jk}-\\bar Z_k(T_j)]}_\\text{residuos de Schoenfeld}\\]\nNota: el proceso score \\(U_k(t)\\) es la primera derivada parcial de la\nverosimilitud parcial del modelo de Cox ajustado con información hasta\ntiempo \\(t\\). Además:\n\\[U_k(0)=0 \\qquad \\text{y} \\qquad U_k(\\infty)=0\\] dado que \\(b\\) resuelve\nla ecuación score. Además bajo la hipótesis de que el modelo ajusta bien\nentonces:\n\\[W_k(t)=U_k(t)\\cdot \\text{Error estándar}(b_k)\\] y la expresión\nanterior converge a un puente browniano que se anula en 0 y en \\(\\infty\\),\nsiempre y cuando \\(\\text{Cov}(b_k,b_{k'})=0\\) para \\(k\\neq k'\\).\n\n\n\n\n\nResiduos de Schoenfeld\n\n\n\n\nEn el gráfico anterior, en el cuadrante superior se nota que existe\nevidencia en contra de \\(H_0\\) ya que \\(W_k(t)\\) es superior al cuantil\nsuperior bajo \\(H_0\\), es decir el supuesto de riesgos proporcionales para\n\\(Z_k\\) no es cierto."
  },
  {
    "objectID": "DRSP.html#identificación-de-outliers",
    "href": "DRSP.html#identificación-de-outliers",
    "title": "5  Análisis de Diagnósticos en el Modelo de Cox",
    "section": "5.4 Identificación de Outliers",
    "text": "5.4 Identificación de Outliers\nCon el fin de detectar outliers podemos usar un gráfico con los residuos\nmartingala (\\(\\hat M_j\\)) vs \\(j\\).\nPrincipal problema: valor máximo del residuo=1 y el valor mínimo del\nresiduo=\\(-\\infty\\). Por lo tanto los residuos martingala son muy\nasimétricos.\nSolución: modificar \\(\\hat M_j\\) a través del residuo de devianza:\n\\[D_j=\\text{signo}[\\hat M_j]\\cdot \\left\\{-2\\left[\\hat M_j+\\delta_j\\log(\\delta_j-\\hat M_j)\\right] \\right\\}^{1/2}\\]\n\nSi \\(\\hat M_j=0\\) entonces \\(D_j=0\\)\nSi \\(\\hat M_j\\longrightarrow 1\\) entonces \\(D_j\\longrightarrow \\infty\\)\nSi \\(\\hat M_j\\longrightarrow -\\infty\\) entonces\n\\(D_j\\longrightarrow -\\infty\\) (a una menor tasa).\n\nGráfico sugerido (misma interpretación de un gráfico de residuos en\nregresión):\n\n\n\n\n\nResiduos de devianza\n\n\n\n\ndonde el score de riesgo es:\n\\[\\text{Score de riesgo}_j=\\sum_{k=1}^p b_kZ_{jk}\\] La identificación de\noutliers se puede realizar bajo el supuesto de normalidad en los\nresiduos \\(N(0,1)\\)."
  },
  {
    "objectID": "DRSP.html#gráfico-de-influencia",
    "href": "DRSP.html#gráfico-de-influencia",
    "title": "5  Análisis de Diagnósticos en el Modelo de Cox",
    "section": "5.5 Gráfico de Influencia",
    "text": "5.5 Gráfico de Influencia\nCon el fin de verificar el grado de influencia de cada observación en\nlos estimadores de \\(\\beta\\), se compara \\(b\\) con \\(b_{(j)}\\): estimador de\n\\(\\beta\\) quitando la \\(j\\)-ésima observación. Esto se hace simplemente a\ntravés de la diferencia \\(b-b_{(j)}\\), en el sentido de que si \\(b-b_{(j)}\\)\nes pequeño, entonces la observación tiene poca influencia.\nProblema: el procedimiento anterior implica realizar \\(n+1\\) regresiones\nde Cox.\nSolución: usar una aproximación para no tener que calcular todas las\nregresiones.\nSea \\(S_{jk}=S_{jk}(\\infty)\\) (residuo score). Si todas las covariables\nson fijas en tiempo 0:\n\\[S_{jk}=\\underbrace{\\delta_j[Z_{jk}-\\bar Z_k(T_j)]}_{\\text{Residuo parcial de Schoenfeld}}-\\sum_{t_b\\leq T_j}[Z_{jk}-\\bar Z_k(T_b)]\\exp(b^TZ_j)\\cdot [\\hat H_0(t_b)-\\hat H_0(t_{b-1})]\\]\npara \\(j=1,\\ldots,n\\) y \\(k=1,\\ldots,p\\).\nSe puede comprobar que \\(b-b_{(j)}\\approx \\Delta_j\\) donde:\n\\[\\Delta_j=I(b)^{-1}(S_{j1},\\ldots,S_{jp})^T\\]\ndonde \\(I(b)\\) es la información de Fisher observada.\nGráficos:\n\n\n\n\n\nGráficos de Influencia\n\n\n\n\nen donde el gráfico de la derecha muestra el nivel de influencia de las\nobservaciones sobre la \\(k\\)-ésima covariable."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referencias",
    "section": "",
    "text": "Klein, John P., and Melvin L. Moeschberger. 2003. Survival analysis : techniques for censored and truncated\ndata. Springer.\n\n\nTsai, Wei-Yann, Nicholas P Jewell, and Mei-Cheng Wang. 1987. “A\nNote on the Product-Limit Estimator Under Right Censoring and Left\nTruncation.” Biometrika 74 (4): 883–86."
  }
]