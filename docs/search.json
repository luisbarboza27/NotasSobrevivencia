[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Análisis de Sobrevivencia",
    "section": "",
    "text": "Introducción\nEstas notas de clase corresponden al material teórico y práctico del curso Análisis de Sobrevivencia (Modelos de Vida) (CA0503) durante el I-2023."
  },
  {
    "objectID": "Preliminares.html#características-de-x",
    "href": "Preliminares.html#características-de-x",
    "title": "1  Preliminares",
    "section": "1.1 Características de \\(X\\):",
    "text": "1.1 Características de \\(X\\):\nA continuación explicamos cada característica:\n\n1.1.1 Función de Sobrevivencia\n\nDefinition 1.1 (Función de sobrevivencia) \\[S(x)=P(X>x)\\]\n\nEn un contexto de tiempo de vida de aparatos o máquinas, a la función \\(S(x)\\) también se le llama función de utilidad o fiabilidad.\nNote que si \\(X\\) es una variable aleatoria continua entonces \\(S(x)\\) es una función monótona decreciente. Además, si \\(f\\) es la función de densidad de \\(X\\):\n\\[S(x)=1-F(x)=\\int_x^{\\infty} f(t)dt\\] y por lo tanto: \\[f(x)=-\\frac{dS(x)}{dx}\\]\n\n\n\n\n\n\nEjemplo: Distribución Weibull\n\n\n\nEn este caso \\(S(x)=\\exp(-\\lambda x^{\\alpha})\\), para \\(\\lambda>0\\) y \\(\\alpha>0\\).\nNote que si \\(\\alpha=1\\) entonces \\(X\\sim \\text{Exponencial}(\\lambda)\\).\n\n\nA continuación se ilustra \\(S(x)\\) cuando \\(\\lambda=\\alpha=2\\):\n\nSWeibull <- function(x,lambda,alpha){\n  exp(-lambda*x^(alpha))\n}\n\nggplot()+\n  xlim(0,3)+\n  geom_function(fun = SWeibull,args= list(lambda = 2, alpha = 2))+\n  ylab('S')+\n  theme_bw()\n\n\n\n\nEn términos generales \\(S(0)=1\\) y \\(S(\\infty)=0\\), para cualquier función de sobrevivencia \\(S\\). Además, es importante recalcar que una tabla de vida o una tabla de decrementos en general es un estimador de \\(S\\) bajo un cierto conjunto de datos observados.\nNote que en el caso discreto: \\[S(x)=\\sum_{x_j>x}p(x_j)\\]\ndonde \\(p(x_j)\\) es la función de masa evaluada en \\(x_j\\).\n\n\n1.1.2 Función o Tasa de Riesgo\nEsta función se conoce en otros contextos con otros nombres:\n\nTasa de fallo condicional (aparatos electrónicos, ingeniería)\nFuerza de mortalidad (demografía)\nTasa de fallo específica por edad (epidemiología)\nHazard (en inglés)\n\n\nDefinition 1.2 (Función de riesgo) \\[h(x)=\\lim_{\\Delta x\\rightarrow 0}\\frac{P[x\\leq X < x+\\Delta x|X\\geq x]}{\\Delta x}\\]\n\nEn el caso en que \\(X\\) es una variable aleatoria continua: \\[\\begin{align*}\nh(x)&=\\lim_{\\Delta x\\rightarrow 0}\\frac{F(x+\\Delta x)-F(x)}{\\Delta x}\\cdot \\frac{1}{S(x)}\\\\\n&=\\frac{f(x)}{S(x)}=-\\frac{d}{dx}\\log (S(x))\n\\end{align*}\\]\nSi la función de riesgo se acumula en el intervalo \\([0,x]\\), se obtiene la función de riesgo acumulativo:\n\\[\\begin{align*}\nH(x)=\\int_0^xh(u)du&=-\\int_0^x \\frac{d}{du}\\log(S(u))du\\\\\n&=-\\log(S(x)).\n\\end{align*}\\]\nEntonces: \\[\nS(x)=\\exp[-H(x)]=\\exp\\left[-\\int_0^th(u)du\\right]\n\\tag{1.1}\\]\nen donde a la expresión \\(h(u)du\\) dentro de la integral se le llama probabilidad instantánea del riesgo.\nLa función de riesgo \\(h(x)\\) necesita ser solamente positiva para asegurar de que la función de sobrevivencia esté bien definida. Por lo tanto no hay muchas restricciones en la forma que tiene la función de riesgo en \\((0,\\infty)\\). Por ejemplo la función de riesgo es monótona creciente en la mayoría de situaciones en donde hay desgaste en las condiciones de existencia en seres o aparatos. También puede ser monótona decreciente en situaciones en donde el riesgo del evento disminuye conforme pasa el tiempo, por ejemplo en el caso de la mortalidad infantil. También se puede tener funciones de riesgo combinadas al tener episodios de riesgo creciente y después de un evento el riesgo disminuye hasta un cierto valor, por ejemplo cuando un paciente es intervenido en un momento de riesgo máximo y después se recupera disminuyendo su riesgo hasta un valor esperable.\n\n\n\n\n\n\nEjemplo: Distribución Weibull\n\n\n\nEn este caso la función de densidad es: \\[f(x)=-\\frac{dS(x)}{dx}=\\lambda \\alpha x^{\\alpha-1}\\exp(-\\lambda x^{\\alpha})\\] entonces: \\[h(x)= \\lambda \\alpha x^{\\alpha-1}\\] Note que si \\(\\alpha=1\\) entonces \\(h(x)=h\\alpha\\), si \\(\\alpha>1\\) la función de riesgo es creciente y si \\(\\alpha<1\\) es decreciente.\n\n\nEn el caso en que \\(\\alpha=\\lambda=2\\)\n\nhWeibull <- function(x,lambda,alpha){\n  lambda*alpha*x^(alpha-1)\n}\n\nggplot()+\n  xlim(0,3)+\n  geom_function(fun = hWeibull,args= list(lambda = 2, alpha = 2))+\n  ylab('h')+\n  theme_bw()\n\n\n\n\nPara otro caso, ver ejemplo 2.2 del (Klein and Moeschberger 2003).\nEn el caso en que \\(X\\) es una variable aleatoria discreta: \\[h(x_j)=P[X=x_j|X\\geq x_j]=\\frac{p(x_j)}{S(x_{j-1})}\\] para \\(j=1,2,\\ldots\\) y donde \\(S(x_0)=1\\). Como \\(p(x_j)=S(x_{j-1})-S(x_j)\\) entonces: \\[h(x_j)=1-\\frac{S(x_j)}{S(x_{j-1})}\\]\nAdemás:\n\\[\\begin{align*}\nS(x)&=\\prod_{x_j\\leq x}\\frac{S(x_j)}{S(x_{j-1})}\\\\\n&=\\prod_{x_j\\leq x}[1-h(x_j)]\n\\end{align*}\\]\n\n\n\n\n\n\nEjemplo: Distribución Discreta\n\n\n\nSi \\(p(x_j)=\\frac 1 3\\) para \\(j=1,2,3\\) entonces: \\[S(x)=P(X>x)=\n  \\begin{cases}\n  1 & 0\\leq x <1\\\\\n  2/3 & 1\\leq x <2 \\\\\n  1/3 & 2\\leq x <3 \\\\\n  0 & x\\geq 3\n  \\end{cases}\n\\]\ny \\[h(x)=\n    \\begin{cases}\n  1/3 & j=1 \\\\\n  1/2 & j=2 \\\\\n  1 & j=3\n    \\end{cases}\n  \\]\n\n\nEn términos generales la función de riesgo es más informativa que la función de sobrevivencia.\nSiguiendo con el caso discreto: \\[H(x)=\\sum_{x_j\\leq x}h(x_j)\\] y la relación Equation 1.1 no aplica. Otros autores prefieren definir la función de riesgo acumulada: \\[H(x)=-\\sum_{x_j\\leq x}\\log(1-h(x_j))\\] y en este caso la relación exponencial entre \\(S(x)\\) y \\(H(x)\\) sí se preserva. Note que si \\(h(x_j)\\approx 0\\) entonces la definición anterior de \\(H(x)\\) es una aproximación de Taylor de la definición original.\n\n\n1.1.3 Vida Residual Media\nEn muchas aplicaciones se requiere una estimación del tiempo esperado en que el evento va a ocurrir, dadas las condiciones actuales:\n\nDefinition 1.3 (Vida Residual Media)  \n\\[\\begin{align*}\n    mrl(x)&=E[X-x|X>x]=\\frac{\\int_x^{\\infty}(t-x)f(t)dt}{S(x)}\\\\\n    &=\\frac{\\int_x^{\\infty}S(t)dt}{S(x)}\n\\end{align*}\\]\n\nCuando \\(x=0\\), entonces \\(mrl(0)=\\int_0^{\\infty}S(t)dt=EX\\). Por otro lado se puede comprobar (Ejercicio):\n\\[\\begin{align*}\n    \\text{Var}(X)=2\\int_0^{\\infty}tS(t)dt-\\left[\\int_0^{\\infty}S(t)dt\\right]^2\n\\end{align*}\\]\nAdemás a partir de la función de sobrevivencia, también se puede calcular el cuantil correspondiente:\n\nDefinition 1.4 (Cuantil-p) Mínimo \\(x_p\\) tal que \\(S(x_p)\\leq 1-p\\): \\[\\inf\\{t:S(t)\\leq 1-p\\}\\] En el caso continuo: \\(S(x_p)=1-p\\).\n\n\n\n\n\n\n\nEjemplo: Ejemplos de vida media\n\n\n\nExponencial: Vida media \\(\\mu=EX=\\frac 1 \\lambda\\). Vida mediana \\(S(x_{0.5})=0.5\\), entonces:\n\\[S(x_{0.5})=e^{-\\lambda x_{0.5}}=\\frac 1 2 \\Rightarrow x_{0.5}=\\frac{\\log 2}{\\lambda}\\]\nVida media residual (usando la propiedad de pérdida de memoria): \\[mrl(x)=E[X-x|X>x]=E[X]=\\frac 1 \\lambda\\]\nWeibull:: \\[1-p=\\exp(-\\lambda x^{\\alpha}_p)\\Rightarrow x_p=\\left[-\\frac{\\log(1-p)}{\\lambda}\\right]^{1/\\alpha}\\]\n\n\nEn el ejemplo desarrollado anteriormente, en donde \\(\\alpha=\\lambda=2\\):\n\nalpha <- lambda <- 2\nx_05 <- (-log(1-0.5)/lambda)^(1/alpha)\nshow(x_05)\n\n[1] 0.588705\n\n\nes la vida mediana bajo el supuesto Weibull.\nEn el caso discreto: \\[mrl(x)=\\frac{(x_{i+1}-x)S(x_i)+\\sum_{j\\geq i+1}(x_{j+1}-x_j)S(x_j)}{S(x)}\\qquad \\text{para }x_i\\leq x<x_{i+1}\\]"
  },
  {
    "objectID": "Preliminares.html#modelos-paraméricos-usuales",
    "href": "Preliminares.html#modelos-paraméricos-usuales",
    "title": "1  Preliminares",
    "section": "1.2 Modelos Paraméricos Usuales",
    "text": "1.2 Modelos Paraméricos Usuales\nAdemás del caso Weibull, existen otras escogencias para modelar la función de sobrevivencia. Las más usuales son:\n\n1.2.1 Exponencial\n\\[\\begin{align*}\n    S(x)&=e^{-\\lambda x}, \\qquad x>0, \\lambda>0\\\\\n    f(x)&=\\lambda e^{-\\lambda x}\\\\\n    h(x)&=\\lambda\n\\end{align*}\\]\nRecuerden además que en el caso exponencial se cumple la propiedad de pérdida de memoria: \\(P(X\\geq x+z|X\\geq x)=P(X\\geq z)\\).\n\n\n1.2.2 Weibull\n\\[\\begin{align*}\n    S(x)&=e^{-\\lambda x^\\alpha}, \\qquad x>0, \\lambda>0, \\alpha>0\\\\\n    h(x)&=\\lambda\\alpha x^{\\alpha-1}\n\\end{align*}\\]\na los parámetros \\(\\lambda\\) y \\(\\alpha\\) se les llama de escala y forma respectivamente.\nBajo la transformación \\(Y=\\log X\\) si \\(X\\sim Weibull\\) se puede escribir \\(Y=\\mu+\\sigma E\\) donde \\(\\mu=\\frac{-\\log \\lambda}{\\alpha}\\) y \\(\\sigma=\\frac 1 \\alpha\\) y \\(E\\sim\\) Valor Extremo Estándar, es decir: \\[f_e(w)=e^{w-e^w}, \\quad w\\in  \\mathbb R\\] y \\[S_E(w)=e^{-e^w}\\]\n\n\n1.2.3 Log-normal\n\\(X\\) es una LogNormal\\((\\mu,\\sigma^2)\\) si \\(Y=\\log X\\sim N(\\mu,\\sigma^2)\\). En este caso:\n\\[\\begin{align*}\n    S(x)&=1-\\Phi\\left(\\frac{\\log x-\\mu}{\\sigma}\\right)\\\\\n    h(x)&=\\frac{\\phi(x)}{S(x)}\n\\end{align*}\\]\nEn general la tasa de riesgo \\(h(x)\\) no es monótona, por ejemplo tomando \\(\\mu=0\\) y \\(\\sigma=1\\):\n\nhLNormal <- function(x,mu,sigma){\n  dnorm(x)/plnorm(x,meanlog = mu,sdlog = sigma,lower.tail = F)\n}\n\nggplot()+\n  xlim(0,3)+\n  geom_function(fun = hLNormal,args= list(mu = 0, sigma = 1))+\n  ylab('h')+\n  theme_bw()\n\n\n\n\nlo cual no necesariamente tiene sentido en muchas aplicaciones.\n\n\n1.2.4 Log-logístico\n\\(X\\) es una variable aleatoria log-logística si \\(Y=\\log X\\sim\\) logístico: \\[f_Y(y)=\\frac{e^{\\frac{y-\\mu}{\\sigma}}}{\\sigma\\left[1+e^{\\frac{y-\\mu}{\\sigma}}\\right]^2},\\qquad y \\in \\mathbb R\\]\ncon función de tasa y función de sobrevivencia:\n\\[\\begin{align*}\n    h(x)&=\\frac{\\alpha \\lambda x^{\\alpha-1}}{1+\\lambda x^\\alpha}\\qquad \\text{más flexible que Weibull}\\\\\n    S(x)&=\\frac{1}{1+\\lambda x^\\alpha}\n\\end{align*}\\]\ncon \\(\\alpha=\\frac 1 \\sigma>0\\), \\(\\lambda=e^{-\\mu/\\sigma}\\)\n\n\n1.2.5 Gamma\n\\[f(x)=\\frac{\\lambda^\\beta x^{\\beta-1}e^{-\\lambda x}}{\\Gamma(\\beta)},\\qquad \\lambda,\\beta,x>0\\] Si \\(\\beta=1\\): exponencial, \\(\\beta\\longrightarrow \\infty\\): Normal. Además \\(h(x)\\) tiene una forma complicada (ver Klein) pero no es muy flexible (solamente crece o decrece).\n\n\n1.2.6 Gompertz\n\\[\\begin{align*}\n    f(x)&=\\theta \\exp(\\alpha x)\\exp \\left(\\frac \\theta \\alpha (1-e^{\\alpha x})\\right)\\\\\n    h(x)&=\\theta \\exp(\\alpha x)\n\\end{align*}\\]\nen este caso si \\(\\alpha>1\\) y \\(\\theta>0\\) entonces \\(h\\) es monótona creciente. Además podemos generalizar levemente la ley anterior por medio del modelo de Makeham: \\[h(x)=\\theta \\exp(\\alpha x)+\\lambda\\]\nla cual permite que \\(h\\) sea más flexible.\n\nhGompertz <- function(x,alpha,theta,lambda){\n  theta*exp(alpha*x)+lambda\n}\n\nggplot()+\n  xlim(0,3)+\n  geom_function(fun = hGompertz,args= list(alpha = 0.5, theta = 0.5,lambda = 0.2))+\n  ylab('h')+\n  theme_bw()"
  },
  {
    "objectID": "Preliminares.html#modelos-de-regresión-para-datos-de-sobrevivencia",
    "href": "Preliminares.html#modelos-de-regresión-para-datos-de-sobrevivencia",
    "title": "1  Preliminares",
    "section": "1.3 Modelos de regresión para datos de sobrevivencia",
    "text": "1.3 Modelos de regresión para datos de sobrevivencia\nSea \\(X\\) la variable aleatoria de tiempo de fallo u ocurrencia de riesgo. Usualmente la distribución de la variable \\(X\\) se asocia con variables explicativas o covariables:\n\\[Z^T=(Z_1,\\ldots,Z_p)\\]\ndonde estas covariables pueden ser cuantitativas o categóricas, y no se descarta la posibilidad de que estas dependan del tiempo \\(x\\):\n\\[Z^T(x)=(Z_1(x),\\ldots,Z_p(x))\\]\nUsualmente los modelos de regresión en este contexto se definen de dos formas:\nEnfoque 1\nUsar la variable dependiente \\(X\\) como variable transformada según \\(Y=\\log(X)\\) y hacer la regresión lineal múltiple:\n\\[Y=\\mu+\\gamma^TZ+\\sigma \\epsilon\\]\ndonde \\(\\gamma^T=(\\gamma_1,\\ldots,\\gamma_p)\\) es un vector de coeficientes y \\(\\epsilon\\) es un error independiente que se puede distribuir según:\n\nUna normal estándar (Regresión log-normal).\nUna distribución de valor extremo estándar (Regresión Weibull)\nUna distribución logística (Regresión log-logística).\n\nMétodo de estimación: Máxima Verosimilitud.\nSea \\(S_0(x)\\) la función de sobrevivencia de \\(X=e^Y\\) cuando \\(Z=0\\), es decir es la función de sobrevivencia de \\(\\exp(\\mu+\\sigma \\epsilon)\\). Entonces:\n\\[\\begin{align*}\n    P[X>x|Z]&=P[Y>\\log x|Z]=P[\\mu+\\gamma^TZ+\\sigma \\epsilon>\\log x|Z]\\\\\n    &=P[\\exp(\\mu+\\sigma \\epsilon)>x\\exp(-\\gamma^T Z)|Z]=S_0(x\\exp(-\\gamma^T Z)).\n\\end{align*}\\]\nConclusión: el efecto de las covariables \\(Z\\) en la función de sobrevivencia de \\(X\\) es el escalamiento del tiempo \\(x\\) a través del factor \\(\\exp(-\\gamma^T Z)\\). Por este motivo a este modelo se le llama modelo de tiempo de fallo acelerado. Su función de riesgo es (ejercicio): \\[h(x|Z)=h_0\\left[x\\exp(-\\gamma^T Z)\\right]\\exp(-\\gamma^T Z)\\]\n\n\n\n\n\n\nEjemplo: Regresión Weibull\n\n\n\nSea \\(X\\sim Weibull(\\lambda, \\alpha)\\). Si \\(Y=\\log X\\) entonces \\(Y=\\mu+\\sigma W\\) donde \\(\\mu=-\\frac{\\log \\lambda}{\\alpha}\\), \\(\\sigma=\\frac 1 \\alpha\\) y \\(W\\sim \\text{VE-Standard}\\), es decir: \\[f_W(w)=\\exp\\left(w-e^w\\right)\\qquad w\\in \\mathbb R\\]\nSi \\(Z_1=1\\) en el vector de covariables \\(Z\\), entonces bajo el modelo de regresión Weibull, se puede calcular:\n\\[\\begin{align*}\n    S_Y(y|Z)&=P[Y>y|Z]=P\\left[W>\\frac{y-\\gamma^T Z}{\\sigma}|Z\\right]\\\\\n    &=\\exp\\left[-\\exp\\left[\\frac{y-\\gamma^T Z}{\\sigma}\\right]\\right]\n\\end{align*}\\]\ny cambiando a la variable original \\(X\\):\n\\[\\begin{align*}\nS_X(x|Z)&=\\exp\\left[-\\exp\\left[\\frac{\\log x-\\gamma^T Z}{\\sigma}\\right]\\right]=\\exp\\left[-x^{1/\\sigma}\\exp\\left[-\\frac{\\gamma^T Z}{\\sigma}\\right]\\right]\\\\\n&=\\exp\\left[-\\left[x\\exp(-\\gamma^T Z)\\right]^\\alpha\\right]=S_0(x\\exp(-\\gamma^T Z))\n\\end{align*}\\] donde \\(S_0\\) es la función de sobrevivencia Weibull.\n\n\nEnfoque 2\nModelación de la tasa de riesgo condicional\nEn este enfoque se trabaja con dos tipos de modelos:\n\nModelos con tasa de riesgo multiplicativa:\n\n\\[\nh(x|Z)=h_0(x)c(\\beta^T Z)\n\\tag{1.2}\\]\ndonde \\(h_0\\) puede ser una función paramétrica o arbitraria y \\(c\\) es una función arbitraria no-negativa. Cuando\n\\[c(\\beta^T Z)=\\exp(\\beta^T Z)\\]\nal modelo en Equation 1.2 se le llama Modelo de Cox. Para este último modelo, si existe dos individuos con distinto conjunto de covariables \\(Z_1\\) y \\(Z_2\\). Entonces:\n\\[\\frac{h(x|Z_1)}{h(x|Z_2)}=\\frac{c(\\beta^TZ_1)}{c(\\beta^TZ_2)}\\]\nlo cual es independiente de \\(x\\) (propiedad de riesgos proporcionales). Además, note que\n\\[\\begin{align*}\n    S(x|Z)&=\\exp\\left[-\\int_0^xh(u|Z)du\\right]=\\exp\\left[-c(\\beta^T Z)\\int_0^xh_0(u)du\\right]\\\\\n    &=S_0(x)^{c(\\beta^T Z)}.\n\\end{align*}\\]\n\n\n\n\n\n\nEjemplo: Regresión Weibull\n\n\n\nEn el caso Weibull: \\(h_0(x)=\\alpha \\lambda x^{\\alpha-1}\\) y la función de riesgo condicional en el caso de un modelo de Cox es: \\[h(x|Z)=\\alpha \\lambda x^{\\alpha-1}\\exp(\\beta^T Z)\\]\nNote que en este caso: \\[\\begin{align*}\n    S(x|Z)&=S_0(x)^{c(\\beta^T Z)}\\\\\n    &=\\exp[-\\lambda (x\\exp(\\beta^T Z/\\alpha))^\\alpha]=S_0(x\\exp(\\beta^T Z/\\alpha))\n\\end{align*}\\]\npor lo cual el modelo de regresión Weibull se puede expresar como modelo de tiempo de fallo acelerado o bien como modelo de riesgos proporcionales. (único caso)\n\n\n\nModelos con tasa de riesgo aditiva: \\[h(x|Z)=h_0(x)+\\sum_{j=1}^pZ_j(x)\\beta_j(x)\\]\n\nEste tipo de modelo tiene dificultades extra, por ejemplo los parámetros \\(\\beta_j(x)\\) deben ser seleccionados de manera que la tasa de riesgo \\(h(x|Z)\\) sea positiva. Por otro lado también \\(\\beta_j(x)\\) puede depender del tiempo \\(x\\)."
  },
  {
    "objectID": "Preliminares.html#modelos-de-riesgos-en-competencia",
    "href": "Preliminares.html#modelos-de-riesgos-en-competencia",
    "title": "1  Preliminares",
    "section": "1.4 Modelos de riesgos en competencia",
    "text": "1.4 Modelos de riesgos en competencia\nSi \\(T\\) denota el tiempo de fallo o bien el tiempo hasta que ocurre un evento. En este contexto, puede ser que existan \\(K\\) distintas causas del fallo. Por ejemplo, ante el evento de muerte a los 65 años, esta se puede deber a muchas causas.\nSea \\(X_i\\) el tiempo hasta que ocurra el \\(i\\)-ésimo riesgo en competencia. Sea \\(T=\\min(X_1,\\ldots,X_K)\\) y considere la variable \\(\\delta\\) que asume el valor \\(i\\) si \\(T=X_i\\). Definimos la tasa del riesgo \\(i\\)-ésimo como:\n\\[\\begin{align*}\n   h_i(t)&=\\lim_{\\Delta t\\rightarrow 0}\\frac{P[t\\leq T < t+\\Delta t, \\delta=i|T\\geq t]}{\\Delta t}\\\\\n   &=\\lim_{\\Delta t\\rightarrow 0}\\frac{P[t\\leq X_i < t+\\Delta t|X_j\\geq t, \\quad j=1,\\ldots,K]}{\\Delta t}\n\\end{align*}\\]\nEntonces, si \\(S(t_1,\\ldots,t_K)=P[X_1>t_1,\\ldots,X_K>t_K]\\)\n\\[\\begin{align*}\n   h_T(t)=\\sum_{i=1}^Kh_i(t) \\quad \\text{y} \\quad h_i(t)=\\frac{-\\frac{\\delta}{\\delta t_i}S(t_1,\\ldots,t_k)|_{t_1=\\cdots=t_K=t}}{S(t,\\ldots,t)}\n\\end{align*}\\]\nCaso especial: si los \\(K\\) riesgos en competencia son independientes:\n\\[h_i(t)=\\frac{-\\frac{\\delta}{\\delta t_i}\\prod_{j=1}^KS_j(t_j)|_{t_1=\\cdots=t_K=t}}{\\prod_{j=1}^KS_j(t)}=\\frac{-\\frac{\\delta}{\\delta t_i}S_i(t_i)|_{t_i=t}}{S_i(t)}\\]\nEn el caso no independiente (ver Ejemplo 2.7 del Klein).\nNota: es fundamental hacer algún supuesto sobre la estructura de dependencia en los tiempos de fallo, ya que al acontecer el riesgo en una causa especifica no se observó el tiempo de fallo en los riesgos restantes.\nEn el contexto de riesgos en competencia, no siempre se utiliza la tasas de riesgo para sintetizar la información, sino que también se utiliza probabilidades con distinta interpretación:\n\nProbabilidades crudas: probabilidad de muerte de un individuo bajo una causa en particular, cuando el resto de las causas también influyen en el comportamiento de sobrevivencia del individuo.\n\nSe calculan a través de la función de incidencia acumulativa:\n\\[\\begin{align*}\n   F_i(t)&=P[T\\leq t, \\delta = i]\\\\\n   &=\\int_0^th_i(u)\\exp[-H_T(u)]du\n\\end{align*}\\]\ndonde el último término exponencial es la tasa acumulativa de todos los riesgos en competencia. Note que \\(F_i\\) no es una distribución ya que:\n\\[F_i(\\infty)=P[\\delta = i]\\neq 1\\]\nAl aplicar la función \\(F_i\\) se puede calcular las probabilidades crudas directamente.\n\nProbabilidades netas: Probabilidad de muerte de un individuo donde la causa de muerte o riesgo de interés es el único. Usando la notación:\n\n\\[S_i(t)=S(0,\\ldots,0,\\stackrel{\\text{posicion }i}{t},0,\\ldots,0)\\]\nEn el caso independiente:\n\\[\\begin{align*}\n   S_i(t)&=\\exp(0)\\cdots \\exp\\left(-\\int_0^th_i(u)du\\right)\\cdots \\exp(0)\\\\\n   &=\\exp\\left[-\\int_0^t\\frac{dF_i(u)}{S_T(u)}du\\right]\n\\end{align*}\\]\n\nProbabilidades parciales crudas: Probabilidades de muerte en un contexto en donde algunos riesgos han sido eliminados. Sean \\(J\\): conjunto de causas o riesgos de interés. Defina:\n\n\\[T^J=\\min(X_i,i\\in J)\\quad \\text{y} \\quad F_i^J(t)=P[T^J\\leq t,\\delta=i]\\]\npara \\(i \\in J\\). Definimos la tasa de riesgo cruda parcial:\n\\[\\lambda_i^J=\\frac{-\\frac{\\delta S(t_1,\\ldots,t_K)}{\\delta t_i}\\Big \\vert_{t_j=t, j\\in J; t_j=0, j\\in J^C}}{S(t_1,\\ldots,t_K)\\Big \\vert_{t_j=t, j\\in J; t_j=0, j\\in J^C}}\\]\nEntonces:\n\\[F_i^J(t)=P[T^J\\leq t, \\delta=i]=\\int_0^t\\lambda^J_i(x)\\exp\\left[-\\sum_{j\\in J}\\int_0^t\\lambda_j^J(u)du\\right]dx\\]\nNote que en el caso independiente, la tasa de riesgo cruda parcial es:\n\\[\\lambda_i^J(t)=\\frac{dF_i(t)/dt}{S_T(t)}\\]"
  },
  {
    "objectID": "Preliminares.html#censura-y-truncamiento",
    "href": "Preliminares.html#censura-y-truncamiento",
    "title": "1  Preliminares",
    "section": "1.5 Censura y Truncamiento",
    "text": "1.5 Censura y Truncamiento\nConceptos de censura y truncamiento:\n\nDefinition 1.5 (Censura) Información de sobrevivencia de un individuo, que solamente se conoce con respecto a un intervalo y no a un punto fijo de occurrencia del evento de riesgo.\n\n\nDefinition 1.6 (Truncamiento) Restricción de entrada o salida a un estudio de sobrevivencia.\n\n\n1.5.1 Censura por la derecha\nTambién conocida como Censura Tipo I:\n\nDefinition 1.7 (Censura Tipo I) Evento de interés es observado solamente si ocurre antes de un tiempo específico.\n\nRecordando la notación que hemos usando hasta el momento, si \\(X\\) es el tiempo aleatorio en que ocurre el riesgo, \\(X\\sim f(x)\\) con función de sobrevivencia \\(S(x)\\) y además \\(C_r\\) denota el tiempo de censura fijo, entonces \\(X\\) es observado solamente si \\(X\\leq C_r\\) y si \\(X>C_r\\) decimos que el evento es “censurado”.\nEn este caso los datos pueden ser representados en pares:\n\\[(T,\\delta)\\]\ndonde \\(\\delta=1\\) indica que el evento se observa y \\(\\delta=0\\) indica que el evento es censurado. Además \\(T=\\min(X,C_r)\\).\n\n\n\n\n\n\nEjemplo: Ejemplo de Censura\n\n\n\nEn un estudio clínico, hay una serie de ratones alimentados con un agente cancerígeno. Se rastrea el tiempo de vida en cada ratón, hasta la muerte o bien hasta una censura pre-establecida (sacrificio):\n\n\n\n\n\nCensura Tipo I\n\n\n\n\nTambién se puede dar el caso de que el tiempo de censura entre observaciones no sea único (censura progresiva):\n\n\n\n\n\nCensura Tipo I-progresiva\n\n\n\n\nTambién se puede dar el caso de que no todos los sujetos de prueba (ratones) estuvieron al inicio del estudio (Censura Tipo I-generalizada):\n\n\n\n\n\nCensura Tipo I-generalizada\n\n\n\n\n\n\nOtra forma de representar los tiempos de sobrevivencia y censura en una muestra es a través de un Diagrama de Lexis, en donde se representa en el eje x el tiempo transcurrido (calendario) del estudio y en el eje y el tiempo transcurrido de cualquier individuo en el estudio:\n\n\n\n\n\nDiagrama de Lexis\n\n\n\n\nOtro tipo de esquema de censura por la derecha es la Censura Tipo II: en donde un estudio termina cuando fallan los primeros \\(r\\) individuos en un grupo de \\(n\\) individuos. Este tipo de esquema se suele aplicar en lotes de equipo electrónico por ejemplo o sistemas que están conectados en red. En este caso \\(r\\): número de fallos, \\(n-r\\): número de censuras y \\(T_{(r)}\\): tiempo de censura del estudio.\nTambién se puede utilizar un esquema progresivo para la censura tipo II. Suponga que hay \\(r_1\\) fallos de un total de \\(n\\) individuos. Además asuma que se censuran \\(n_1-r_1\\) individuos (\\(n_1<n\\)) con un primer tiempo de censura \\(T_{(r_1)}\\). El proceso puede continuar con los \\(n-n_1\\) individuos restantes, ocurre \\(r_2\\) fallos (\\(r_2<n-n_1\\)), \\(n_2-r_2\\) censuras (\\(n_1+n_2<n\\)) y \\(T_{(n_1+r_2)}\\) es el segundo tiempo de censura y así sucesivamente.\n\n\n1.5.2 Censura por la izquierda o de intervalo\nSuponga que para un tiempo de vida \\(X\\) existe un tiempo \\(C_\\ell\\) en donde el evento de riesgo ocurrió antes de que el sujeto fuera observado. En este caso el tiempo \\(X\\) es observado si \\(X>C_\\ell\\). Al igual que en el caso de censura por la derecha, podemos usar la notación:\n\\[(T,\\epsilon)\\]\ndonde \\(T=X\\) si \\(\\epsilon=1\\) (observado) y \\(T=C_\\ell\\) si \\(\\epsilon=0\\) (censurado), es decir \\(T=\\max(X,C_\\ell)\\). Por ejemplo, si un estudio busca cuantificar el riesgo de fumar marihuana por primera vez (Klein and Moeschberger 2003), un individuo tendría una censura por la izquierda si no recuerda la primera vez que fumó, pero afirma que sí la ha consumido antes del inicio del estudio.\nSi por otro lado se combina la censura por la derecha y por la izquierda, se denomina censura doble, y en este caso los datos son:\n\\[(T,\\delta)\\quad \\text{donde} \\quad T=\\max\\left(\\min(X,C_r),C_\\ell\\right)\\]\ny\n\\[\\begin{align*}\n\\delta=\\begin{cases}\n1 & \\text{si $T$ ocurre entre $C_\\ell$ y $C_r$}\\\\\n0 & \\text{censura por la derecha}\\\\\n-1 & \\text{censura por la izquierda}\n\\end{cases}\n\\end{align*}\\]\nFinalmente, la censura por intervalo se utiliza en estudios en donde un paciente o individuo en general es visitado periódicamente y lo único que se sabe es que el evento de interés ocurrió en un intervalo \\((L_i,R_i]\\) cuyos extremos corresponde a los momentos de visitas consecutivas.\n\n\n1.5.3 Truncamiento\nEl truncamiento ocurre cuando en un estudio solamente se incluyen y observan individuos cuyos eventos ocurren en \\((Y_L,Y_R)\\). Si el evento ocurriera fuera de ese intervalo entonces no se incluye en el estudio.\nSi \\(Y_R=\\infty\\) entonces X es observado \\(\\Leftrightarrow Y_L<X\\) (truncamiento por la izquierda). Por ejemplo: (1) si se estudia la aparición de una enfermedad desde una fecha fija o (2) si se estudia el evento de muerte desde el inicio de un estudio clínico.\nNota: Muchas veces el truncamiento por la izquierda es acompañado con censura por la derecha.\nPara el caso de truncamiento por la derecha: si \\(Y_L=0\\): \\(X\\) es observado \\(\\Leftrightarrow X\\leq Y_R\\) (ver Ejemplo 3.8 del (Klein and Moeschberger 2003))."
  },
  {
    "objectID": "Preliminares.html#verosimilitud-bajo-censura-y-truncamiento",
    "href": "Preliminares.html#verosimilitud-bajo-censura-y-truncamiento",
    "title": "1  Preliminares",
    "section": "1.6 Verosimilitud bajo censura y truncamiento",
    "text": "1.6 Verosimilitud bajo censura y truncamiento\nSupuesto: tiempos de ocurrencia de evento y tiempos de censura son independientes. Cada tipo de censura/truncamiento aporta distintos factores a la verosimilitud completa de los datos:\n\nTiempo exacto del evento en estudio: \\(f(x)\\)\nCensura por la derecha: \\(P(X>C_r)=S(C_r)\\)\nCensura por la izquierda: \\(P(X<C_\\ell)=1-S(C_\\ell)\\)\nCensura en intervalo: \\(P(L<X<R)=S(L)-S(R)\\)\nTruncamiento por la izquierda: \\(f(x|X>Y_L)=\\frac{f(x)}{S(Y_L)}\\)\nTruncamiento por la derecha: \\(f(x|X<Y_R)=\\frac{f(x)}{1-S(Y_R)}\\)\n\nPor lo tanto la verosimilitud con datos censurados se puede escribir como:\n\\[L\\propto \\prod_{i \\in D}f(x_i)\\prod_{i \\in R}S(C_r)\\prod_{i \\in L}\\left(1-S(C_\\ell)\\right) \\prod_{i \\in I}[S(L_i)-S(R_i)]\\]\ndonde\n\n\\(D\\): conjunto de eventos observables.\n\\(R\\): conjunto de observaciones con censura por la derecha.\n\\(L\\): conjunto de observaciones con censura por la izquierda.\n\\(I\\): conjunto de observaciones con censura por intervalo.\n\nPara datos truncados por la izquierda y censurados por la derecha con intervalo de truncamiento \\((Y_{L_i},Y_{R_i})\\) independientes del \\(i\\)-ésimo momento de muerte, se reemplaza \\(f(x_i)\\) y \\(S(C_i)\\) (\\(C_i\\): tiempo de censura \\(i\\)-ésima) por:\n\\[\\frac{f(x_i)}{S(Y_{L_i})-S(Y_{R_i})} \\quad \\text{y} \\quad \\frac{S(C_i)}{S(Y_{L_i})-S(Y_{R_i})}\\]\nEn el caso en donde cada individuo tiene una distribución de riesgo distinta (Ejemplo: regresión):\n\\[L\\propto \\prod_{i \\in D}f_i(x_i)\\prod_{i \\in R}S_i(C_r)\\prod_{i \\in L}\\left(1-S_i(C_\\ell)\\right) \\prod_{i \\in I}[S_i(L_i)-S_i(R_i)]\\]\nCaso particular: censura tipo I (por la derecha)\nSi \\(\\delta=0\\) (censura):\n\\[\\begin{align*}\n   P[T,\\delta=0]&=P[T=C_r|\\delta=0]P[\\delta=0]=P[\\delta=0]\\\\\n   &=P[X>C_r]=S(C_r).\n\\end{align*}\\]\nSi \\(\\delta = 1\\):\n\\[\\begin{align*}\n   P[T,\\delta=1]&=P[T=X|\\delta=1]P[\\delta=1]\\\\\n   &=P[T=X|X\\leq C_r]P[X\\leq C_r]\\\\\n   &=\\frac{f(t)}{1-S(C_r)}[1-S(C_r)]=f(t).\n\\end{align*}\\]\nEntonces el aporte de \\(T=t\\) a la verosimilitud es:\n\\[[f(t)]^\\delta[S(t)]^{1-\\delta}\\]\nSi se tiene una muestra aleatoria de pares \\((T_i,\\delta_i)\\), para \\(i=1,\\ldots,n\\):\n\\[L=\\prod_{i=1}^nf(t_i)^{\\delta_i}[S(t_i)]^{1-\\delta_i}\\]\nComo \\(f(t_i)=h(t_i)S(t_i)\\) entonces:\n\\[L=\\prod_{i=1}^nh(t_i)^{\\delta_i}S(t_i)^{\\delta_i}[S(t_i)]^{1-\\delta_i}=\\prod_{i=1}^nh(t_i)^{\\delta_i}\\exp(-H(t_i))\\]\n\n\n\n\n\n\nEjemplo: Caso Exponencial\n\n\n\nAsuma que \\(X\\sim \\text{Exponencial}(\\lambda)\\) con \\(f(x)=\\lambda \\exp(-\\lambda x)\\), entonces:\n\\[\\begin{align*}\n   L&=\\prod_{i=1}^n [\\lambda \\exp(-\\lambda t_i)]^{\\delta_i}[\\exp(-\\lambda t_i)]^{(1-\\delta_i)}\\\\\n   &=\\lambda^r\\exp(-\\lambda S_T)\n\\end{align*}\\]\ndonde \\(r=\\sum \\delta_i\\) (total de eventos observados) y \\(S_T=\\sum_{i=1}^n t_i\\) (total de tiempo en el estudio)."
  },
  {
    "objectID": "Preliminares.html#laboratorio",
    "href": "Preliminares.html#laboratorio",
    "title": "1  Preliminares",
    "section": "1.7 Laboratorio",
    "text": "1.7 Laboratorio\n\n1.7.1 Ejemplos de datos de análisis de sobrevivencia\n\nlibrary(tidyverse)\nlibrary(KMsurv)\n\n\n1.7.1.1 Ejemplo 1\nEnsayo clínico de un fármaco, 6-mercaptopurina (6-MP), frente a un placebo en 42 niños con leucemia aguda. El ensayo se llevó a cabo en 11 hospitales estadounidenses. Se seleccionaron pacientes que habían experimentado una remisión completa o parcial de su leucemia inducida por el tratamiento con el fármaco prednisona. (Una remisión completa o parcial significa que la mayoría o todos los signos de la enfermedad habían desaparecido de la médula ósea). El ensayo se realizó emparejando pares de pacientes en un hospital determinado por estado de remisión (completa o parcial) y aleatorizando dentro del par para recibir terapia de mantenimiento con 6-MP o placebo. Los pacientes fueron seguidos hasta que su leucemia regresó (relapse) o hasta el final del estudio (en meses).\n\ndata(\"drug6mp\")\n#help(\"drug6mp\")\n\nglimpse(drug6mp)\n\nRows: 21\nColumns: 5\n$ pair    <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,…\n$ remstat <int> 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2\n$ t1      <int> 1, 22, 3, 12, 8, 17, 2, 11, 8, 12, 2, 5, 4, 15, 8, 23, 5, 11, …\n$ t2      <int> 10, 7, 32, 23, 22, 6, 16, 34, 32, 25, 11, 20, 19, 6, 17, 35, 6…\n$ relapse <int> 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0\n\n\n\nggplot()+geom_histogram(data = drug6mp,mapping = aes(t2),bins = 6,fill='white',col = 'black')+\n  theme_bw()\n\n\n\n\n\ntable(drug6mp$relapse)\n\n\n 0  1 \n12  9 \n\n\n\n\n1.7.1.2 Ejemplo 2\nEvaluación del tiempo hasta la primera infección del sitio de salida (en meses) en pacientes con insuficiencia renal, 43 pacientes utilizaron un catéter colocado quirúrgicamente (Grupo 1), y 76 pacientes utilizaron una colocación percutánea de su catéter (Grupo 2).\n\ndata(kidney)\n#help(kidney)\n\nglimpse(kidney)\n\nRows: 119\nColumns: 3\n$ time  <dbl> 1.5, 3.5, 4.5, 4.5, 5.5, 8.5, 8.5, 9.5, 10.5, 11.5, 15.5, 16.5, …\n$ delta <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ type  <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n\n\n\nggplot()+geom_histogram(data = kidney,mapping = aes(time),bins = 6,fill='white',col = 'black')+\n  theme_bw()\n\n\n\n\n\ntable(kidney$delta)\n\n\n 0  1 \n93 26 \n\n\n\n\n1.7.1.3 Ejemplo 3\nEstudio diseñado para determinar si las pacientes con cáncer de mama, clasificadas originalmente como negativas en los ganglios linfáticos por microscopía de luz estándar (SLM), podrían ser clasificadas de manera más precisa mediante examen inmunohistoquímico (IH) de sus ganglios linfáticos con un cóctel de anticuerpos monoclonales anticitokeratina. Se seleccionaron 45 pacientes con cáncer de mama femenino y ganglios linfáticos axilares negativos y un seguimiento mínimo de 10 años del Registro de Cáncer de los Hospitales de la Universidad Estatal de Ohio. De las 45 pacientes, 9 fueron positivas para inmunoperoxidasa, y las 36 restantes permanecieron negativas.\n\ndata(btrial)\n#help(btrial)\n\nglimpse(btrial)\n\nRows: 45\nColumns: 3\n$ time  <int> 19, 25, 30, 34, 37, 46, 47, 51, 56, 57, 61, 66, 67, 74, 78, 86, …\n$ death <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0…\n$ im    <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n\n\n\ntabla_1 <- btrial %>% group_by(death,im) %>% summarise(total = n()) %>%\n  ungroup() %>% mutate(total = round(total / sum(total)*100,2))\n\n`summarise()` has grouped output by 'death'. You can override using the\n`.groups` argument.\n\nshow(tabla_1)\n\n# A tibble: 4 × 3\n  death    im total\n  <int> <int> <dbl>\n1     0     1 44.4 \n2     0     2  2.22\n3     1     1 35.6 \n4     1     2 17.8 \n\n\n\ntabla_2 <- btrial %>% group_by(death,im) %>% summarise(total = round(mean(time),2)) \n\n`summarise()` has grouped output by 'death'. You can override using the\n`.groups` argument.\n\nshow(tabla_2)\n\n# A tibble: 4 × 3\n# Groups:   death [2]\n  death    im total\n  <int> <int> <dbl>\n1     0     1 148. \n2     0     2 144  \n3     1     1  52.1\n4     1     2  59.9\n\n\n\n\n1.7.1.4 Ejemplo 4\nMuestra de 101 pacientes con leucemia mieloide aguda avanzada reportados en el Registro Internacional de Trasplante de Médula Ósea. 51 de estos pacientes recibieron un trasplante autólogo de médula ósea en el que, después de altas dosis de quimioterapia, su propia médula fue reinfundida para reemplazar su sistema inmunológico destruido. 50 pacientes recibieron un trasplante alogénico de médula ósea en el que se utilizó médula de un hermano compatible en cuanto a antígenos leucocitarios humanos (HLA) para reponer sus sistemas inmunológicos. Una pregunta importante en el trasplante de médula ósea es la comparación de la efectividad de estos dos métodos de trasplante medida por la duración de la supervivencia libre de leucemia de los pacientes, el tiempo que viven y cuánto tiempo permanecen libres de enfermedad después de sus trasplantes.\n\ndata(\"alloauto\")\n#help(\"alloauto\")\n\nglimpse(alloauto)\n\nRows: 101\nColumns: 3\n$ time  <dbl> 0.030, 0.493, 0.855, 1.184, 1.283, 1.480, 1.776, 2.138, 2.500, 2…\n$ type  <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ delta <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1…\n\n\n\nalloauto <- alloauto %>% mutate(type = factor(type))\n\nggplot()+geom_histogram(data = alloauto,aes(x = time),bins = 7,fill='white',col = 'black')+\n  facet_wrap(facets = vars(type),nrow = 2)+\n  theme_bw()\n\n\n\n\n\nlibrary(asaur)\nhead(gastricXelox)\n\n  timeWeeks delta\n1         4     1\n2         8     1\n3         8     1\n4         8     1\n5         9     1\n6        11     1\n\ndim(gastricXelox)\n\n[1] 48  2\n\n\n\n\n1.7.1.5 Ejemplo 5\nEste es un ensayo clínico de Fase II (muestra única) de quimioterapia Xeloda y oxaliplatino (XELOX) administrado antes de la cirugía a 48 pacientes con cáncer gástrico avanzado con metástasis en los ganglios linfáticos paraaórticos (Wang et al.).\n\ntimeWeeks: tiempo de sobrevivencia en semanas.\ndelta: variable de censura: (1) muerte, (2) censura.\n\n\nhead(prostateSurvival)\n\n  grade stage ageGroup survTime status\n1  mode   T1c      80+       18      0\n2  mode  T1ab    75-79       23      0\n3  poor   T1c    75-79       37      0\n4  mode    T2    70-74       27      0\n5  mode   T1c    70-74       42      0\n6  poor    T2    75-79       38      2\n\ndim(prostateSurvival)\n\n[1] 14294     5\n\n\n\n\n1.7.1.6 Ejemplo 6\nDatos simulados de 14,294 pacientes con cáncer de próstata basados en análisis detallados de riesgos competitivos publicados por Lu-Yao et al. Para cada paciente, tenemos la clasificación histológica (poco o moderadamente diferenciado), la edad del diagnóstico (66-70, 71-75, 76-80 y 80+), el estadio del cáncer (T1c si se diagnosticó mediante una prueba de detección de antígeno específico de próstata, T1ab si se diagnosticó clínicamente sin cribado, o T2 si fue palpable en el momento del diagnóstico), el tiempo de supervivencia (días desde el diagnóstico hasta la muerte o la última fecha de seguimiento) y un indicador (“estado”) que indica si el paciente murió de cáncer de próstata (estado = 1), murió de otra causa (estado = 2) o seguía vivo en la última fecha de seguimiento (estado = 0).\n\nageGroup: edad de diagnóstico.\nstage: etapa del cáncer.\nsurvTime: tiempo de sobrevivencia.\nstatus: Muerte por cáncer de próstata (1), muerte por otra causa (2), sobrevivencia al final del estudio (0).\n\n\nhead(pharmacoSmoking)\n\n   id ttr relapse         grp age gender     race employment yearsSmoking\n1  21 182       0   patchOnly  36   Male    white         ft           26\n2 113  14       1   patchOnly  41   Male    white      other           27\n3  39   5       1 combination  25 Female    white      other           12\n4  80  16       1 combination  54   Male    white         ft           39\n5  87   0       1 combination  45   Male    white      other           30\n6  29 182       0 combination  43   Male hispanic         ft           30\n  levelSmoking ageGroup2 ageGroup4 priorAttempts longestNoSmoke\n1        heavy     21-49     35-49             0              0\n2        heavy     21-49     35-49             3             90\n3        heavy     21-49     21-34             3             21\n4        heavy       50+     50-64             0              0\n5        heavy     21-49     35-49             0              0\n6        heavy     21-49     35-49             2           1825\n\ndim(pharmacoSmoking)\n\n[1] 125  14\n\n\n\n\n1.7.1.7 Ejemplo 7\nEl propósito de este estudio (Steinberg et al. [63]) fue evaluar la duración prolongada de una combinación de tres medicamentos versus la terapia con parche de nicotina sola en fumadores con enfermedades médicas. Los pacientes con antecedentes de tabaquismo fueron asignados al azar a la combinación de tres medicamentos o a la terapia con parche, y se siguieron durante un máximo de seis meses. La variable de resultado primaria fue el tiempo desde la asignación aleatoria hasta la recaída (vuelta al tabaquismo); las personas que permanecieron sin fumar durante seis meses fueron censuradas.\n\nttr: tiempo en dias hasta una recaída (volver a fumar).\nrelapse: (1): volvió a fumar vs (0): censura.\nemployment: jornada laboral.\n\n\n\n1.7.1.8 Ejemplo 8\nTasas de riesgo (Tablas de vida en USA) expresadas por día calendario:\n\nlibrary(survival)\n\n\nAttaching package: 'survival'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    kidney\n\ndim(survexp.us)\n\n[1] 110   2  75\n\nhazMale <- survexp.us[,\"male\",\"2010\"]\nhazFemale <- survexp.us[,\"female\",\"2010\"]\ntm <- 1:110\ntm.diff <- c(1,diff(tm))\nsurvMale <- exp(-cumsum(hazMale*tm.diff)*365.24)\nsurvFemale <- exp(-cumsum(hazFemale *tm.diff)*365.24)\ndata.tot <- data.frame(tm,hMale = as.numeric(hazMale),\n                       hFemale = as.numeric(hazFemale),\n                       sMale = survMale, sFemale = survFemale)\ndata.tot.long <- pivot_longer(data.tot,cols = hMale:sFemale)\n\nGrafico de tasas de riesgo:\n\ndata.tot.long.h <- data.tot.long %>% filter(name == 'hMale' | name == 'hFemale')\nggplot(data = data.tot.long.h)+geom_line(mapping = aes(x = tm,y = value,col = name)) + theme_bw() + xlab('Age')+ylab('Hazard')\n\n\n\n\nGrafico de probabilidades de sobrevivencia:\n\ndata.tot.long.s <- data.tot.long %>% filter(name == 'sMale' | name == 'sFemale')\nggplot(data = data.tot.long.s)+geom_line(mapping = aes(x = tm,y = value,col = name)) + theme_bw() + xlab('Age')+ylab('Hazard')\n\n\n\n\n\n\n\n\nKlein, John P., and Melvin L. Moeschberger. 2003. Survival analysis : techniques for censored and truncated data. Springer."
  },
  {
    "objectID": "estNP.html#intervalos-de-confianza-puntuales-de-st",
    "href": "estNP.html#intervalos-de-confianza-puntuales-de-st",
    "title": "2  Estimación No-Paramétrica",
    "section": "2.1 Intervalos de confianza puntuales de \\(S(t)\\)",
    "text": "2.1 Intervalos de confianza puntuales de \\(S(t)\\)\nSea \\(\\sigma_S(t)^2=\\frac{\\hat V[\\hat S(t)]}{\\hat S(t)^2}\\). Si \\(t_0\\) es un punto fijo de tiempo, definimos el intervalo de confianza lineal al \\(100\\cdot (1-\\alpha)\\)% para \\(S(t_0)\\) como:\n\\[\\hat S(t_0)\\pm z_{1-\\alpha/2}\\sigma_S(t_0)\\hat S(t_0)\\]\nCon el fin de mejorar el intervalo de confianza anterior, se puede considerar un intervalo de confianza sobre el logaritmo de \\(H(t)\\):\n\\[\\log \\hat H(t_0)\\pm z_{1-\\alpha/2}\\cdot \\sigma^*(t_0)\\]\ndonde \\(\\sigma^*(t_0)\\) lo tenemos que calcular o bien aproximar. Como \\(\\text{Var}(\\hat S(t))\\approx \\hat S(t)^2\\sigma_S(t)^2\\) entonces por el método delta (Ejercicio):\n\\[\\begin{align*}\n   \\text{Var}[\\log H(t_0)]&=\\text{Var}[\\log(-\\log S(t_0))]\\\\\n   &\\approx \\frac{1}{[\\log \\hat S(t_0)]^2}\\underbrace{\\sum_{t_i\\leq t}\\frac{d_i}{Y_i(Y_i-d_i)}}_{\\sigma_S(t_0)^2}\n\\end{align*}\\]\nentonces podemos aproximar el término \\(\\sigma^*(t_0)\\) y obtener:\n\\[\\log \\hat H(t_0)\\pm z_{1-\\alpha/2}\\cdot \\frac{1}{\\log S(t_0)}\\sigma_S(t_0)\\]\nes un intervalo de confianza al \\(100(1-\\alpha)\\)’% para \\(\\log[-\\log S(t_0)]\\). Entonces:\n\\[\\hat H(t_0)\\exp\\left[\\pm\\frac{z_{1-\\alpha/2}\\sigma_S(t_0)}{\\log S(t_0)}\\right]\\]\nes un IC para \\(H(t_0)\\) y \\([\\hat S(t_0)^{1/\\theta},\\hat S(t_0)^\\theta]\\) donde \\(\\theta=\\exp\\left[\\frac{z_{1-\\alpha/2}\\sigma_S(t_0)}{\\log \\hat S(t_0)}\\right]\\) es el IC al \\(100(1-\\alpha)\\)% para \\(S(t_0)\\).\nOtra posibilidad es utilizar la transformación \\(\\text{arcsen}[\\hat S(t_0)^{1/2}]\\)\nVentaja: ambas posibilidades permiten que el IC de \\(S(t_0)\\) no salga del intervalo \\([0,1]\\).\nPor otro lado, para muestras pequeñas, el IC con la transformación arcsen es más conservador, seguido del IC con transformación log-log y de último el lineal (sin transformación).\nNota: los intervalos log-log y arcsen no son simétricos."
  },
  {
    "objectID": "estNP.html#bandas-de-confianza-para-st",
    "href": "estNP.html#bandas-de-confianza-para-st",
    "title": "2  Estimación No-Paramétrica",
    "section": "2.2 Bandas de confianza para \\(S(t)\\)",
    "text": "2.2 Bandas de confianza para \\(S(t)\\)\nQueremos encontrar dos funciones aleatorias \\(L(t)\\) y \\(U(t)\\) tal que:\n\\[P[L(t)\\leq S(t)\\leq U(t)\\quad \\forall t: t_L\\leq t\\leq t_U]=1-\\alpha\\]\nA \\([L(t),U(t)]\\) le llamamos banda de confianza al \\(100(1-\\alpha)\\)% para \\(S(t)\\).\nNair(1984) define el concepto de Bandas EP, las cuales son proporcionales a los intervalos puntuales. Sean \\(t_L<t_U\\) tal que \\(t_L\\geq \\text{tiempo más pequeño del evento observado}\\) y \\(t_U\\leq \\text{tiempo más grande del evento observado}\\). Si \\(n\\) es el tamaño de muestra, defina:\n\\[a_L=\\frac{n\\sigma_S(t_L)^2}{1+n\\sigma_S(t_L)^2},\\qquad a_U=\\frac{n\\sigma_S(t_U)^2}{1+n\\sigma_S(t_U)^2}\\]\ny tomando \\(c_\\alpha(a_L,a_U)\\) de la tabla C.3 del Klein (también se puede obtener de R) entonces los tres tipos de Banda de confianza al \\(100(1-\\alpha)\\)% son:\n\nLineal: \\(\\hat S(t)\\pm c_\\alpha(a_L,a_U)\\sigma_S(t)\\hat S(t)\\)\nLog-log; \\((\\hat S(t)^{1/\\theta},\\hat S(t)^\\theta)\\), donde \\(\\theta=\\exp\\left[\\frac{c_\\alpha(a_L,a_U)\\sigma_S(t)}{\\log[\\hat S(t)]}\\right]\\).\nArcsen-raíz cuadrada: ver fórmula 4.4.4 del Klein.\n\nOtro método para construir las bandas es el de Hall y Wellner (1980) (ver Klein).\nNotas:\n\nSe pueden construir bandas de confianza para la tasa de riesgo acumulativo.\nIgual que en el caso de los intervalos puntuales, los intervalos log-log y arcsen se comportan mejor bajo muestras pequeñas."
  },
  {
    "objectID": "estNP.html#estimación-del-tiempo-medio-y-mediano-de-sobrevivencia",
    "href": "estNP.html#estimación-del-tiempo-medio-y-mediano-de-sobrevivencia",
    "title": "2  Estimación No-Paramétrica",
    "section": "2.3 Estimación del tiempo medio y mediano de sobrevivencia",
    "text": "2.3 Estimación del tiempo medio y mediano de sobrevivencia\nRecuerden que el tiempo medio de sobrevivencia es:\n\\[\\mu=\\int_0^\\infty S(t)dt\\]\nUn estimador plug-in para este caso es:\n\\[\\hat \\mu=\\int_0^\\infty\\hat S(t)dt\\]\ncon el principal inconveniente de que el estimador de Kaplan-Meier está definido hasta un valor de \\(t\\) máximo, llámese \\(\\tau\\) (tiempo de sobrevivencia máximo condicionado con respecto a censuras):\n\\[\\hat \\mu_\\tau=\\int_0^\\tau \\hat S(t)dt\\]\nNormalmente \\(\\tau\\) es el tiempo de muerte máximo o bien el tiempo máximo de censura asumiendo muerte del individuo (corrección de Efron). Para el estimador \\(\\mu_\\tau\\), su varianza es:\n\\[\\hat V[\\hat \\mu_\\tau]=\\sum_{i=1}^D\\left[\\int_{t_i}^\\tau \\hat S(t)dt\\right]^2\\frac{d_i}{Y_i(Y_i-d_i)}\\]\ny un intervalo de confianza para \\(\\mu\\) al \\(100(1-\\alpha)\\)% es:\n\\[\\hat \\mu_\\tau\\pm z_{1-\\alpha/2}\\sqrt{\\hat V[\\hat \\mu_\\tau]}\\]\nPor otro lado, también es posible estimar cuantiles de la distribución de \\(T\\):\n\\[\\text{cuantil-}p = x_p = \\inf\\{t:S(t)\\leq 1-p\\}\\]\nel cual puede ser estimado con un estimador plug-in:\n\\[\\hat x_p = \\inf\\{t:\\hat S(t)\\leq 1-p\\}\\]\nLa varianza del estimador anterior se pueden estimar como:\n\\[\\hat V(\\hat x_p)=\\frac{\\hat V[\\hat S(\\hat x_p)]}{\\hat f(\\hat x_p)^2}\\]\ndonde \\(\\hat f(\\hat x_p)\\) es un estimador no-paramétrico de \\(f(\\hat x_p)\\) (densidad). Por ejemplo, cualquier estimador por kernel de \\(f\\) es una opción válida.\nAproximación de Brookmeyer y Crowley\n\\[-z_{1-\\alpha/2}\\leq \\frac{\\hat S(t)-(1-p)}{\\hat V^{1/2}[\\hat S(t)]}\\leq z_{1-\\alpha/2}\\]\nes un intervalo de confianza al \\(100(1-\\alpha)\\)% para \\(x_p\\). Un IC para \\(x_p\\) basado en la transformación log-log es:\n\\[-z_{1-\\alpha/2}\\leq \\frac{\\log(-\\log \\hat S(t))-\\log(-\\log(1-p))}{\\frac{\\hat V^{1/2}(\\hat S(t))}{\\hat S(t)\\log \\hat S(t)}}\\leq z_{1-\\alpha/2}\\]\nNota: caso más usual es \\(p=1/2\\)."
  },
  {
    "objectID": "estNP.html#estimadores-para-datos-censurados-por-la-derecha-y-truncados-por-la-izquierda",
    "href": "estNP.html#estimadores-para-datos-censurados-por-la-derecha-y-truncados-por-la-izquierda",
    "title": "2  Estimación No-Paramétrica",
    "section": "2.4 Estimadores para datos censurados por la derecha y truncados por la izquierda",
    "text": "2.4 Estimadores para datos censurados por la derecha y truncados por la izquierda\nConsidere para cada individuo:\n\n\\(L_j\\): edad aleatoria de ingreso del individuo \\(j\\)-ésimo.\n\\(T_j\\): tiempo de ocurrencia del evento o censura para el individuo \\(j\\)-ésimo.\n\nSea \\(t_1<t_2<\\cdots <t_D\\) los tiempos distintos de ocurrencia de los eventos. Además, siguiendo la notación de las secciones anteriores:\n\n\\(d_i\\): número de individuos que experimentan el evento o riesgo de interés en tiempo \\(t_i\\) (\\(i=1,\\ldots,D\\))\n\\(Y_i\\): individuos en riesgo al tiempo \\(t_i\\).\n\nCon el fin de considerar esquemas de censura/truncamiento más amplios, se tienen las siguientes dos definiciones para la población en riesgo:\n\n\\(Y_i\\): número de individuos en el estudio en tiempo \\(0\\) y que están en riesgo al momento \\(t_i\\) (esquema sin truncamiento )\n\\(Y_i\\): número de individuos en riesgo al momento \\(t_i\\) tales que (Truncamiento por la izquierda) (Tsai, Jewell, and Wang 1987):\n\n\\[L_j\\leq t_i \\leq T_j\\]\nTodos los estimadores de \\(S(t)\\) vistos hasta ahora aplican, pero la interpretación debe hacerse con cuidado. Por ejemplo, el estimador de KM se debe interpretar como el estimador de la función de sobrevivencia en tiempo \\(t\\), pero condicional en \\(L=\\min_j\\{L_j\\}\\):\n\\[P[X>t|X\\geq L]=\\frac{S(t)}{S(L)}\\]\nPor lo tanto el estimador de KM sería:\n\\[\\hat S_L(t)=\\prod_{L\\leq t_i \\leq t}\\left[1-\\frac{d_i}{Y_i}\\right]\\qquad t\\geq L\\]\nes decir se estaía incluyendo solamente eventos o censuras que estén después de \\(a\\), donde \\(a=L\\).\nNota: las fórmulas de Nelson-Aalen y Greenwood también se pueden calcular en este contexto."
  },
  {
    "objectID": "estNP.html#estimadores-para-riesgos-en-competencia",
    "href": "estNP.html#estimadores-para-riesgos-en-competencia",
    "title": "2  Estimación No-Paramétrica",
    "section": "2.5 Estimadores para riesgos en competencia",
    "text": "2.5 Estimadores para riesgos en competencia\nPara modelos de riesgos de competencia, el supuesto de independencia entre tiempos de eventos y censuras no necesariamente se puede aplicar. En este caso, definimos tres formas distintas de resumir información:\nEstimador de Kaplan-Meier complementario\nSi existieran dos riesgos en competencia (A y B) se define el estimador:\n\\[\\hat S_A(t)=KM(\\text{ocurrencias de A como eventos, ocurrencias de B como censuras})\\]\nLa idea se generaliza muy fácilmente para el caso de más de dos riesgos. Inconveniente: estimador muy crudo para generar interpretaciones apropiadas.\nFunción acumulada de incidencia\nSea \\(t_1,\\ldots,t_k\\) los tiempos distintos en los cuales uno de los riesgos en competencia ocurre. En tiempo \\(t_i\\) definimos lo siguiente:\n\n\\(Y_i\\): número de sujetos en riesgo al momento \\(t_i\\).\n\\(r_i\\): número de sujetos que les ocurrió el evento de interés.\n\\(d_i\\): número de sujetos que les ocurrió otro evento que no sea el de interés (sin incluir censuras).\n\nLa función acumulada de incidencia se define:\n\\[\\begin{align*}\n   CI(t)=\\begin{cases}\n     0 & t\\leq t_1\\\\\n     \\sum_{t_i\\leq t}\\underbrace{\\left[\\prod_{j=1}^{i-1}\\frac{1-(d_j+r_j)}{Y_j}\\right]}_{\\hat S(t_{i-})}\\frac{r_i}{Y_i} & t_1\\leq t\n  \\end{cases}\n\\end{align*}\\]\ndonde \\(\\hat S(t_{i-})\\) es el estimador KM evaluado justo antes de \\(t_i\\).\nInterpretación de \\(CI(t)\\): probabilidad de que el evento de interés ocurra antes de tiempo \\(t\\) y antes de cualquier otro evento en competencia. La varianza de \\(CI(t)\\) es: (fórmula 4.7.2-Klein)\n\\[V[CI(t)]=\\sum_{t_i\\leq t}\\hat S(t_i)^2\\left[(CI(t)-CI(t_i))^2\\cdot \\frac{r_i+d_i}{Y_i^2}+[1-2(CI(t)-CI(t_i))]\\cdot \\frac{r_i}{Y_i^2}\\right]\\]\nde lo anterior es posible construir un intervalo de confianza al \\(100(1-\\alpha)\\)% para la incidencia acumulada:\n\\[CI(t)\\pm z_{1-\\alpha/2}V[CI(t)]^{1/2}\\]\nProbabilidad condicional para un riesgo en competencia\nSi \\(CI_k(t)\\) es la función acumulada de incidencia para el riesgo \\(k\\)-ésimo y \\(CI_{k^c}(t)\\) es la función acumulada de incidencia para todos los riesgos excepto el \\(k\\)-ésimo. Entonces definimos la probabilidad condicional para el riesgo \\(k\\)-ésimo como:\n\\[CP_k(t)=\\frac{CI_k(t)}{1-CI_{k^c}(t)}\\]\ncon varianza:\n\\[V[CP_k(t)]=\\frac{\\hat S(t_{-})^2}{[1-CI_{k^c}(t)]^4}\\sum_{t_i\\leq t}\\frac{[1-CI_{k^c}(t_i)]^2r_i+CI_k(t_i)^2d_i}{Y_i^2}\\]\nInterpretación de \\(CP_k(t)\\): estima la probabilidad condicional de que el evento \\(k\\) ocurre en tiempo \\(t\\) si ninguna de las otras causas de riesgo han ocurrido antes de \\(t\\)."
  },
  {
    "objectID": "estNP.html#estimación-de-st-para-otros-esquemas-de-censura",
    "href": "estNP.html#estimación-de-st-para-otros-esquemas-de-censura",
    "title": "2  Estimación No-Paramétrica",
    "section": "2.6 Estimación de \\(S(t)\\) para otros esquemas de censura",
    "text": "2.6 Estimación de \\(S(t)\\) para otros esquemas de censura\n\n2.6.1 Censura por la izquierda\nEn este caso los individuos experimentan el evento antes del periodo de observación, o bien lo experimentan dentro del periodo de observacion.\nSolución: redefinir el tiempo al fijar para \\(\\tau>0\\) (grande):\n\\[\\tilde t=\\tau-t\\]\ny transformar entonces la censura por la izquierda por censura por la derecha. Como estimadores se pueden utilizar KM o Nelson-Aalen con la particularidad de que:\n\\[P[\\tau-X>t]=P[X<t-\\tau]\\]\n\n\n2.6.2 Censura doble\nPara estimar \\(S(t)\\) bajo este esquema, usaremos el Proceso o algoritmo de Turnbull:\nSuponga una grilla de puntos en el tiempo:\n\\[0=t_0<t_1<t_2<\\cdots<t_m\\]\ny defina:\n\n\\(d_i\\): número de eventos en tiempo \\(t_i\\) (\\(d_i\\) puede ser 0).\n\\(r_i\\): número de individuos con censura por la derecha en tiempo \\(t_i\\).\n\\(c_i\\): número de individuos con censura por la izquierda en tiempo \\(t_i\\).\n\nAlgoritmo\n\nPaso 0: Produzca un estimador inicial de \\(S(t)\\) en cada \\(t_j\\) llamado \\(S_0(t_j)\\). Turnbull (1974): tome \\(S_0(t)=KM(t)\\) ignorando la censura por la izquierda.\nPaso \\(k+1\\):\n\nCon \\(S_k(\\cdot)\\) calcule, para \\(j\\leq i\\):\n\n\n\\[p_{ij}=P[t_{j-1}<X\\leq t_j|X\\leq t_i]= \\frac{S_k(t_{j-1})-S_k(t_j)}{1-S_k(t_i)}\\]\n\nEstime el número de eventos en tiempo \\(t_i\\) como:\n\n\\[\\hat d_i=d_i+\\sum_{i=j}^m c_ip_{ij}\\]\n\nCalcule el estimador KM con datos censurados por la derecha usando \\(\\hat d_i\\) como eventos y \\(r_i\\) como censuras.\nSi \\(S_{k+1}(t)\\) es cercano a \\(S_k(t)\\) para todo \\(t_i\\) entonces el proceso termina.\n\n\n\n2.6.3 Censura por intervalo\nPara este esquema cada individuo tiene un intervalo \\((L_i,R_i]\\) en donde el evento ocurre, pero el tiempo exacto es desconocido (\\(i=1,\\ldots,n\\))\nPara estimar la función de sobrevivencia, se utiliza una modificación del algoritmo de Turnbull. Considere una grilla de tiempos \\(0=\\tau_0<\\tau_1<\\cdots<\\tau_m\\) que incluyen a \\(L_i,R_i\\) para todo \\(i=1,\\ldots,n\\).\nPara la observación \\(i\\)-ésima, defina:\n\\[\\begin{align*}\n\\alpha_{ij}=\n   \\begin{cases}\n       1 & \\text{si } (\\tau_{j-1},\\tau_j]\\subseteq (L_i,R_i] \\\\\n       0 & \\text{otro caso}\n   \\end{cases}\n\\end{align*}\\]\ny dado un estimador inicial de \\(S(\\tau_j)\\):\n\nPaso 1: Calcule la probabilidad de que el evento ocurre en tiempo \\(\\tau_j\\):\n\n\\[p_j=S(\\tau_{j-1})-S(\\tau_j) \\qquad j=1,\\ldots,m\\]\n\nPaso 2: Estime el número de eventos al tiempo \\(\\tau_i\\):\n\n\\[d_i=\\sum_{i=1}^n \\frac{\\alpha_{ij}p_j}{\\sum_k \\alpha_{ik}p_k}\\]\n\nPaso 3: Calcule una estimación de los sujetos en riesgo al tiempo \\(\\tau_i\\):\n\n\\[Y_i=\\sum_{k=i}^m d_k\\]\n\nPaso 4: Calcule el estimador KM con los datos en los pasos 3 y 4 hasta que haya convergencia de \\(S\\) uniformemente en \\(\\tau_i\\)."
  },
  {
    "objectID": "estNP.html#laboratorio",
    "href": "estNP.html#laboratorio",
    "title": "2  Estimación No-Paramétrica",
    "section": "2.7 Laboratorio",
    "text": "2.7 Laboratorio\n\n2.7.1 Ajustes básicos\nPaquete base de análisis de sobrevivencia: survival. Junto con el paquete KMsurv que contiene los datos del libro de Klein y M.\n\nlibrary(survival)\nlibrary(KMsurv)\nlibrary(survMisc)\n\n\nAttaching package: 'survMisc'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    autoplot\n\nlibrary(tidyverse)\n\nPara ilustrar el cálculo de los estimadores no paramétricos de sobrevivencia con el paquete survival, trabajamos con la base de la sección 1.2 del Klein: Estudio clínico de la droga 6-MP vs un placebo en 42 niños con leucemia aguda. Todos los pacientes presentaban una remisión en el cańcer a nivel de la médula ósea, gracias a un tratamiento con prednisona. A los pacientes se agruparon en pares y se les administró 6-MP o el placebo y se monitoreó hasta que la leucemia regresaba o hasta el fin del estudio (meses). A continuación un vistazo de los datos:\n\ndata(\"drug6mp\")\nhead(drug6mp)\n\n  pair remstat t1 t2 relapse\n1    1       1  1 10       1\n2    2       2 22  7       1\n3    3       2  3 32       0\n4    4       2 12 23       1\n5    5       2  8 22       1\n6    6       1 17  6       1\n\n\nPara una explicación de las variables ver la ayuda de drug6mp o bien la tabla 1.1 en el Klein. Noten que la última columna corresponde al indicador del evento (recaída de los pacientes) para el grupo que se le administró el tratamiento (6-MP).\nComo un primer ejercicio, se calcula el estimador de Kaplan-Meier para el grupo tratamiento (6_MP). Para eso primero calculamos el objeto Surv que contiene los tiempos de ocurrencia junto con las censuras:\n\nsurv_6MP <- Surv(time = drug6mp$t2,event = drug6mp$relapse)\n\nsurv_6MP\n\n [1] 10   7  32+ 23  22   6  16  34+ 32+ 25+ 11+ 20+ 19+  6  17+ 35+  6  13   9+\n[20]  6+ 10+\n\n\ny después calculamos el estimador de Kaplan-Meier:\n\nKM_6MP <- survfit(surv_6MP~1)\n\nsummary(KM_6MP)\n\nCall: survfit(formula = surv_6MP ~ 1)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    6     21       3    0.857  0.0764        0.720        1.000\n    7     17       1    0.807  0.0869        0.653        0.996\n   10     15       1    0.753  0.0963        0.586        0.968\n   13     12       1    0.690  0.1068        0.510        0.935\n   16     11       1    0.627  0.1141        0.439        0.896\n   22      7       1    0.538  0.1282        0.337        0.858\n   23      6       1    0.448  0.1346        0.249        0.807\n\n\nComparen esta tabla con Tabla 4.1A del Klein. La quinta columna con el error estándar corresponde a \\(\\sigma_S(t)\\). Un gráfico de \\(\\hat S(t)\\) es:\n\nplot(KM_6MP)\n\n\n\n\nPor default, los intervalos de confianza se calculan sobre el logaritmo de \\(S(t)\\). Para calcular los intervalos con la transformación log-log al 95% de confianza:\n\nKM_6MP_loglog <- survfit(surv_6MP~1,conf.type='log-log',)\n\nsummary(KM_6MP_loglog)\n\nCall: survfit(formula = surv_6MP ~ 1, conf.type = \"log-log\")\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    6     21       3    0.857  0.0764        0.620        0.952\n    7     17       1    0.807  0.0869        0.563        0.923\n   10     15       1    0.753  0.0963        0.503        0.889\n   13     12       1    0.690  0.1068        0.432        0.849\n   16     11       1    0.627  0.1141        0.368        0.805\n   22      7       1    0.538  0.1282        0.268        0.747\n   23      6       1    0.448  0.1346        0.188        0.680\n\n\nAsimismo se puede calcular bandas de confianza a través del paquete km.ci:\n\nlibrary(km.ci)\n\nbandasEP_KM_6MP <- km.ci(KM_6MP,conf.level = 0.95,tl = NA,tu = NA,\n                         method = 'epband')\nbandasHall_KM_6MP <- km.ci(KM_6MP,conf.level = 0.95,tl = NA,tu = NA,\n                         method = 'hall-wellner')\nplot(bandasEP_KM_6MP,lty = 2,lwd=2)\nlines(bandasHall_KM_6MP,lty = 3,lwd=2)\nlines(KM_6MP_loglog,lty=1,lwd=2)\nlines(KM_6MP_loglog,lty=4,lwd=2,conf.int = T)\nlinetype<-c(1, 2, 3, 4)\nlegend(0, .4, c(\"Kaplan-Meier\", \"EP\",\"Hall-Wellner\", \"Pointwise\"),\n       lty=(linetype))\n\n\n\n\ny también pueden utilizar la función ci del paquete survMisc.\nTambién se puede estimar \\(S(t)\\) a través del estimador de Nelson-Aalen:\n\nNA_6MP <- survfit(coxph(surv_6MP~1), type=\"aalen\")\n\nsummary(NA_6MP)\n\nCall: survfit(formula = coxph(surv_6MP ~ 1), type = \"aalen\")\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    6     21       3    0.867  0.0715        0.737        1.000\n    7     17       1    0.817  0.0828        0.670        0.997\n   10     15       1    0.765  0.0927        0.603        0.970\n   13     12       1    0.704  0.1035        0.527        0.939\n   16     11       1    0.642  0.1111        0.458        0.902\n   22      7       1    0.557  0.1249        0.359        0.864\n   23      6       1    0.471  0.1317        0.273        0.815\n\n\no bien se puede calcular el riesgo acumulado \\(H\\) y su varianza a través de la función sf de survMisc:\n\nt_6MP <- ten(surv_6MP)\nH_6MP <- sf(x = t_6MP$e,n = t_6MP$n,what = 'H')\nHv_6MP <- sf(x = t_6MP$e,n = t_6MP$n,what = 'Hv')\nTabla4_2 <- data.frame(tiempo=t_6MP$t,d=t_6MP$e,H_6MP,Hv_6MP)\nTabla4_2 <- Tabla4_2 %>% filter(d>0) %>% mutate(ErrorS=sqrt(Hv_6MP))\nround(Tabla4_2,4)\n\n  tiempo d  H_6MP Hv_6MP ErrorS\n1      6 3 0.1429 0.0068 0.0825\n2      7 1 0.2017 0.0103 0.1013\n3     10 1 0.2683 0.0147 0.1213\n4     13 1 0.3517 0.0217 0.1471\n5     16 1 0.4426 0.0299 0.1730\n6     22 1 0.5854 0.0503 0.2243\n7     23 1 0.7521 0.0781 0.2795\n\n\nComparen este resultado con la Tabla 4.2 del Klein.\nOtro aspecto a calcular es el tiempo medio de sobrevivencia de este grupo de pacientes. Para ello usamos la función print del paquete survival:\n\nprint(KM_6MP,print.rmean = T)\n\nCall: survfit(formula = surv_6MP ~ 1)\n\n      n events rmean* se(rmean) median 0.95LCL 0.95UCL\n[1,] 21      9   23.3      2.83     23      16      NA\n    * restricted mean with upper limit =  35 \n\n\ny al igual que en el Klein obtenemos un valor estimado de 23.29 días usando corrección de Efron, y un error estándar de 2.83 días. La mediana del tiempo de sobrevivencia usando la transformación log-log se puede obtener también con:\n\nquantile(KM_6MP_loglog,probs = c(0.5,0.15))\n\n$quantile\n50 15 \n23  7 \n\n$lower\n50 15 \n13  6 \n\n$upper\n50 15 \nNA 13 \n\n\nen donde también calculamos el cuantil 0.15 de la misma distribución junto con sus intervalos de confianza usando la definición de Klein. Note que para el caso de la mediana, la intersección con el límite superior del intervalo de confianza es nula, por eso nos da un NA.\nPara ilustrar el esquema de truncamiento por la izquierda y censura por la derecha, usaremos los datos de la sección 1.16 del Klein, en donde se tiene la edad de muerte (en meses) o su salida de 462 ancianos en un centro de retiro en California y además la edad cuando entraron al mismo centro. Los datos deben ser truncados para medir la mortalidad dentro del centro de retiro, y no debido a otras causas. Un vistazo de los datos es el siguiente:\n\ndata(\"channing\")\n\nhead(channing)\n\n  obs death ageentry  age time gender\n1   1     1     1042 1172  130      2\n2   2     1      921 1040  119      2\n3   3     1      885 1003  118      2\n4   4     1      901 1018  117      2\n5   5     1      808  932  124      2\n6   6     1      915 1004   89      2\n\n\nNote que la variable ageentry es la edad de entrada en meses a la casa de retiro y age es la edad de muerte o censura por la derecha. De nuevo el truncamiento por la izquierda es la mejor opción cuando se tiene un subconjunto de edades más limitado como el que se tiene en esta muestra. Los estimadores de Kaplan-Meier condicionados en 68 y 80 años para hombres y mujeres se ilustra a continuación (transformando los datos a datos anuales):\n\nchanning_Years <- channing %>% mutate(ageentry=ageentry/12,age=age/12)\nattach(channing_Years)\nKM_Chan_68 <- survfit(Surv(time = ageentry,time2 = age,event = death,\n                           type = 'counting')~gender,start.time=68,\n                      data=channing_Years)\n\nWarning in Surv(time = ageentry, time2 = age, event = death, type =\n\"counting\"): Stop time must be > start time, NA created\n\nplot(KM_Chan_68,conf.int = F,col = c(1,2))\nKM_Chan_80 <- survfit(Surv(time = ageentry,time2 = age,event = death,\n                           type = 'counting')~gender,start.time=80,\n                      data=channing_Years)\n\nWarning in Surv(time = ageentry, time2 = age, event = death, type =\n\"counting\"): Stop time must be > start time, NA created\n\nlines(KM_Chan_80,conf.int = F,col = c(3,4))\nlegend(90, 1, c(\"Male-68\", \"Female-68\",\"Male-80\", \"Female-80\"), \n       col=1:4,lty=1)\n\n\n\n\n\n\n2.7.2 Riesgos en competencia\n1384 Pacientes con gammapatía monoclonal de significado incierto (MGUS) a los cuales se les hace un seguimiento hasta la aparición de neoplasia de células plasmáticas (PCM) o la muerte (en meses). Por ejemplo, el estimador KM de la sobrevivencia (riesgo de muerte) de los pacientes clasificado por sexo es:\n\nmfit1 <- survfit(Surv(futime, death) ~ sex, data=mgus2)\nplot(mfit1, col=c(1,2), xscale=12, mark.time=FALSE, lwd=2,\n     xlab=\"Years post diagnosis\", ylab=\"Survival\")\nlegend(\"topright\", c(\"female\", \"male\"), col=1:2, lwd=2, bty='n')\n\n\n\n\nConsidere dos riesgos en competencia: PCM y muerte no relacionada a PCM.\n\nmgus3 <- mgus2 %>% mutate(etime=ifelse(pstat==0, futime,ptime),\n                          event = ifelse(pstat==0, 2*death, 1))\nmgus3$event <- factor(mgus3$event, 0:2, \n                      labels=c(\"censor\", \"pcm\", \"death\"))\ntable(mgus3$event)\n\n\ncensor    pcm  death \n   409    115    860 \n\n\ncon el cálculo correspondiente de la incidencia cumulada:\n\nmfit2 <- survfit(Surv(etime, event) ~ sex, data=mgus3)\nprint(mfit2, rmean=240, scale=12)\n\nCall: survfit(formula = Surv(etime, event) ~ sex, data = mgus3)\n\n               n nevent    rmean*\nsex=F, (s0)  631      0  9.853608\nsex=M, (s0)  753      0  8.675012\nsex=F, pcm   631     59  1.323284\nsex=M, pcm   753     56  1.064693\nsex=F, death 631    370  8.823108\nsex=M, death 753    490 10.260294\n   *restricted mean time in state (max time = 20 )\n\n\n\nplot(mfit2, col=c(1,2,1,2), lty=c(2,2,1,1),\n     mark.time=FALSE, lwd=2, xscale=12,\nxlab=\"Years post diagnosis\", ylab=\"Probability in State\")\nlegend(240, .6, c(\"death:female\", \"death:male\", \"pcm:female\", \"pcm:male\"),\ncol=c(1,2,1,2), lty=c(1,1,2,2), lwd=2, bty='n')\n\n\n\n\n\n\n2.7.3 Otros esquemas de muestreo\nEn esta segunda clase, se calculará empíricamente la función de sobrevivencia bajo tres distintos esquemas de muestreo.\n\n2.7.3.1 Censura doble (Censura por derecha y por izquierda)\nVamos a replicar aproximadamente el ejemplo 5.1 del Klein. A continuación la carga de datos:\n\nedades <- 10:18\neventos <- c(4,12,19,24,20,13,3,1,4)\ncensuras_izq <- c(0,0,0,1,2,3,2,3,1)\ncensuras_der <- c(0,0,2,15,24,18,14,6,0)\ntabla_5_1 <- data.frame(edades,censuras_izq,eventos,censuras_der)\ntabla_5_1\n\n  edades censuras_izq eventos censuras_der\n1     10            0       4            0\n2     11            0      12            0\n3     12            0      19            2\n4     13            1      24           15\n5     14            2      20           24\n6     15            3      13           18\n7     16            2       3           14\n8     17            3       1            6\n9     18            1       4            0\n\n\ncomparen esta tabla con la Tabla 5.1 del Klein. El ajuste de este tipo de datos se hace con el paquete survival con el algoritmo de Turnbull ajustado a través de EM (Método de Esperanza-Maximización). Antes, hay que convertir los datos a intervalos individualizados según el tipo de censura:\n\ncensuras_izq_v <- NULL\nfor(i in 1:dim(tabla_5_1)[1]){\n  if(tabla_5_1[i,2]>0){\n    censuras_izq_v <- rbind(censuras_izq_v,\n                            matrix(rep(c(-Inf,tabla_5_1[i,1]),\n                                       each=tabla_5_1[i,2]),\n                                   nrow=tabla_5_1[i,2]))\n    }\n}\neventos_v <- NULL\n\nfor(i in 1:dim(tabla_5_1)[1]){\n  if(tabla_5_1[i,3]>0){\n    eventos_v <- rbind(eventos_v,\n                       matrix(rep(c(tabla_5_1[i,1],\n                                    tabla_5_1[i,1]),\n                                  each=tabla_5_1[i,3]),\n                              nrow = tabla_5_1[i,3]))\n  }\n}\n\ncensuras_der_v <- NULL\n\nfor(i in 1:dim(tabla_5_1)[1]){\n  if(tabla_5_1[i,4]>0){\n    censuras_der_v <- rbind(censuras_der_v,\n                            matrix(rep(c(tabla_5_1[i,1],Inf),\n                          each=tabla_5_1[i,4]),nrow = tabla_5_1[i,4]))\n    }\n}\n\ndatos_5_1 <- rbind(censuras_der_v,censuras_izq_v,eventos_v)\nhead(datos_5_1)\n\n     [,1] [,2]\n[1,]   12  Inf\n[2,]   12  Inf\n[3,]   13  Inf\n[4,]   13  Inf\n[5,]   13  Inf\n[6,]   13  Inf\n\ntail(datos_5_1)\n\n       [,1] [,2]\n[186,]   16   16\n[187,]   17   17\n[188,]   18   18\n[189,]   18   18\n[190,]   18   18\n[191,]   18   18\n\n\ny ya con los datos convertidos se puede estimar la función de sobrevivencia:\n\nsurv_obj_5_1 <- Surv(time = datos_5_1[,1],time2 = datos_5_1[,2],\n                     type = 'interval2')\nS_5_1 <- survfit(surv_obj_5_1~1)\nsummary(S_5_1)\n\nCall: survfit(formula = surv_obj_5_1 ~ 1)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n   10 191.00    4.48    0.977  0.0104        0.956        0.998\n   11 186.52   13.43    0.906  0.0194        0.865        0.949\n   12 173.09   21.27    0.795  0.0241        0.738        0.857\n   13 149.82   26.91    0.652  0.0236        0.585        0.727\n   14 107.91   22.37    0.517  0.0200        0.446        0.599\n   15  61.54   14.65    0.394  0.0161        0.321        0.483\n   16  28.89    3.39    0.348  0.0149        0.273        0.443\n   17  11.50    1.19    0.312  0.0152        0.229        0.423\n   18   4.31    4.31    0.000  0.0000           NA           NA\n\nplot(S_5_1)\n\n\n\n\n\n\n2.7.3.2 Censura por intervalo\nEn el caso de censura por intervalo, se ilustrará el algoritmo de Turnbull-EM con los datos del ejemplo 5.2. Estos datos consisten en la comparación de dos tratamientos de cáncer de mama a nivel de 95 mujeres (Variable treat: 1-Radioterapia, 2-Radioterapia+quimioterapia). Durante visitas periodicas, los médicos midieron el deterioro cosmético en el seno de cada mujer bajo los dos tratamientos. Lo único que se guarda en cada caso en el periodo de tiempo en donde el deterioro fue severo o moderado entre dos visitas sucesivas. El tiempo se mide en meses.\n\ndata(\"bcdeter\")\nhead(bcdeter)\n\n  lower upper treat\n1     0     5     1\n2     0     7     1\n3     0     8     1\n4     4    11     1\n5     5    11     1\n6     5    12     1\n\n\nLa estimación de la función de sobrevivencia para el riesgo de deterioro se estima por tipo de tratamiento:\n\nsurv_obj_5_2 <- Surv(time = bcdeter$lower,time2 = bcdeter$upper,\n                     type = 'interval2')\nS_5_2 <- survfit(surv_obj_5_2~treat,data = bcdeter)\nsummary(S_5_2)\n\nCall: survfit(formula = surv_obj_5_2 ~ treat, data = bcdeter)\n\n                treat=1 \n time n.risk  n.event survival std.err lower 95% CI upper 95% CI\n  4.5 46.000 2.13e+00    0.954  0.0431        0.869        1.000\n  6.5 43.868 1.54e+00    0.920  0.0505        0.819        1.000\n  7.5 42.332 4.08e+00    0.832  0.0769        0.669        1.000\n 11.5 38.255 3.25e+00    0.761  0.0791        0.582        0.994\n 15.5 34.000 2.27e-15    0.761  0.0791        0.582        0.994\n 17.5 33.000 9.07e-04    0.761  0.0791        0.582        0.994\n 24.5 28.999 3.53e+00    0.668  0.0783        0.474        0.942\n 25.5 25.469 3.11e-08    0.668  0.0783        0.474        0.942\n 33.5 23.469 2.87e+00    0.586  0.0705        0.392        0.876\n 34.5 19.596 1.85e-10    0.586  0.0705        0.392        0.876\n 36.5 17.596 1.43e-04    0.586  0.0705        0.392        0.876\n 39.0 13.596 2.79e+00    0.466  0.0594        0.272        0.797\n 42.0  9.801 6.71e-03    0.466  0.0594        0.272        0.796\n 47.0  0.794 7.94e-01    0.000  0.0000           NA           NA\n\n                treat=2 \n time n.risk  n.event survival std.err lower 95% CI upper 95% CI\n  4.5  49.00 2.08e+00    0.958 0.04029       0.8786        1.000\n  6.5  46.92 2.08e+00    0.915 0.05401       0.8065        1.000\n  8.5  44.84 2.55e-05    0.915 0.05401       0.8065        1.000\n 11.5  42.84 3.15e+00    0.848 0.07262       0.6955        1.000\n 12.5  39.69 2.40e-06    0.848 0.07262       0.6955        1.000\n 16.5  36.69 6.28e+00    0.703 0.09750       0.4773        1.000\n 18.5  30.41 4.99e+00    0.588 0.08670       0.3591        0.961\n 19.5  25.43 5.52e+00    0.460 0.06488       0.2522        0.839\n 21.5  18.91 4.19e-05    0.460 0.06488       0.2522        0.839\n 22.5  18.91 6.10e-06    0.460 0.06488       0.2522        0.839\n 23.5  17.91 1.50e-07    0.460 0.06488       0.2522        0.839\n 24.5  17.91 5.05e+00    0.330 0.03922       0.1632        0.668\n 30.5  12.85 3.33e-02    0.329 0.03907       0.1626        0.667\n 31.5  11.82 1.07e-07    0.329 0.03907       0.1626        0.667\n 34.0  10.82 3.29e+00    0.229 0.02279       0.0979        0.536\n 34.5   5.53 1.93e-11    0.229 0.02279       0.0979        0.536\n 35.5   4.53 2.40e+00    0.108 0.00806       0.0275        0.421\n 48.0   2.13 2.13e+00    0.000 0.00000           NA           NA\n\n\ny gráficamente:\n\nplot(S_5_2,col = c(1,2))\nlegend(0,0.4,legend = c('T-1','T-2'),col=c(1,2),lty=1)\n\n\n\n\n\n\n2.7.3.3 Estimación de \\(S(x)\\) con una tabla de vida de un cohorte .\nA manera de resumen (les recomiendo que estudien esta sección por su propia cuenta, ya que no presenta diferencias sustanciales con respecto al resto del curso), estos son los principales indicadores que se calculan en una tabla de vida de forma no-paramétrica:\n\nCohorte: grupo de individuos con un origen en común en cuanto al tiempo en el cual un evento es calculado (por ejemplo, la misma edad al momento de inicial el estudio)\nSe considera intervalos disjuntos \\(I_j=(a_{j-1},a_j]\\), \\(j=1,\\ldots,k+1\\) con \\(a_0=0\\) y \\(a_{k+1}=\\infty\\), en donde cada individuo del cohorte tendrá el evento de interés.\nSea \\(Y_j'\\): número de individuos que no han experimentado el evento en el \\(j\\)-ésimo intervalo.\n\\(W_j\\): número de individuos del cohorte que no presentan el evento en el intervalo \\(j\\)-ésimo (censuras).\n\\(d_j\\): número de individuos del cohorte que presentan el evento en el intervalo \\(j\\)-ésimo (eventos).\nLa población en riesgo del intervalo \\(j\\)-ésimo se estima asumiendo una distribución uniforme de las censuras:\n\n\\[\\begin{align*}\nY_j=Y_j'-W_j/2\n\\end{align*}\\]\n\nLa función de sobrevivencia estimada es análoga al estimador de Kaplan-Meier:\n\n\\[\\begin{align*}\n\\hat S(a_j)=\\prod_{i=1}^j\\left(1-d_i/Y_i\\right)\n\\end{align*}\\]\n\nLa densidad estimada en el punto medio del intervalo \\(j\\)-ésimo (\\(a_{mj}=(a_j+a_{j-1})/2\\)) es:\n\n\\[\\begin{align*}\n\\hat f(a_{mj})=\\frac{\\hat S(a_{j-1})-\\hat S(a_j)}{a_{j-1}-a_j}\n\\end{align*}\\]\n\nLa tasa de riesgo estimada en el punto medio del intervalo \\(j\\)-ésimo:\n\n\\[\\begin{align*}\n\\hat h(a_{mj})&=\\frac{\\hat f(a_{mj})}{\\hat S(a_{mj})}\\\\\n&=\\frac{2\\hat f(a_{mj})}{\\hat S(a_{j})+\\hat S(a_{j-1})}\n\\end{align*}\\]\nusando interpolación lineal para calcular \\(\\hat S(a_{mj})\\).\n\nLas probabilidad condicionales de sobrevivencia en el \\(j\\)-ésimo intervalo es:\n\n\\[\\begin{align*}\n\\hat p_j=1-\\hat q_j=1-d_j/Y_j\n\\end{align*}\\]\ndonde \\(\\hat q_j\\) es la probabilidad condicional de ocurrencia del evento en el mismo intervalo.\nVamos a replicar el ejemplo 5.4 en donde se tiene datos de 927 recién nacidos cuyas madres los alimentaron con lactancia materna. La duración de lactancia materna se midió en semanas, y el evento de interés es la interrupción de la lactancia materna. En cada intervalo también hubo salidas del estudio.\nExtraemos los datos y hacemos el cálculo de la tabla de sobreviencia del cohorte:\n\ndata(\"bfeed\")\nlibrary(tidyverse)\nhead(bfeed)\n\n  duration delta race poverty smoke alcohol agemth ybirth yschool pc3mth\n1       16     1    1       0     0       1     24     82      14      0\n2        1     1    1       0     1       0     26     85      12      0\n3        4     0    1       0     0       0     25     85      12      0\n4        3     1    1       0     1       1     21     85       9      0\n5       36     1    1       0     1       0     22     82      12      0\n6       36     1    1       0     0       0     18     82      11      0\n\nninit <- dim(bfeed)[1]\ntis <- c(0,2,3,5,7,11,17,25,37,53,NA)\ntis_2 <- c(0,2,3,5,7,11,17,25,37,53,Inf)\npretablas <- bfeed %>% dplyr::select(duration,delta) %>%\n  mutate(intervalo=cut(duration,breaks = tis_2))%>%\n  group_by(delta,intervalo)%>%\n  summarise(conteo=n())\n\n`summarise()` has grouped output by 'delta'. You can override using the\n`.groups` argument.\n\ntabla_resumen <- data.frame(intervalos=unique(pretablas$intervalo),\n                            eventos=pretablas$conteo[pretablas$delta==1],\n                            censuras=c(pretablas$conteo[pretablas$delta==0],\n                                       rep(0,3)))\n\ntabla_resumen$Yprima <- 0\ntabla_resumen$Yprima[1] <-ninit\n\nfor(i in 2:dim(tabla_resumen)[1]){\n  tabla_resumen$Yprima[i]<-tabla_resumen$Yprima[i-1]-\n    tabla_resumen$eventos[i]-\n    tabla_resumen$censuras[i]\n}\n\nLa tabla resultante y el cálculo de la función de sobrevivencia:\n\nshow(tabla_resumen)\n\n   intervalos eventos censuras Yprima\n1       (0,2]     148        5    927\n2       (2,3]      49        3    875\n3       (3,5]      89        6    780\n4       (5,7]      71        9    700\n5      (7,11]      96        4    600\n6     (11,17]     147        5    448\n7     (17,25]     107        3    338\n8     (25,37]      73        0    265\n9     (37,53]      85        0    180\n10   (53,Inf]      27        0    153\n\ntabla_vida <- lifetab(tis,ninit,\n                      nlost = tabla_resumen$censuras,\n                      nevent = tabla_resumen$eventos)\nshow(tabla_vida)\n\n      nsubs nlost nrisk nevent       surv         pdf     hazard     se.surv\n0-2     927     5 924.5    148 1.00000000 0.080043267 0.08700764 0.000000000\n2-3     774     3 772.5     49 0.83991347 0.053276065 0.06550802 0.012059831\n3-5     722     6 719.0     89 0.78663740 0.048686181 0.06597480 0.013484256\n5-7     627     9 622.5     71 0.68926504 0.039307484 0.06047700 0.015262465\n7-11    547     4 545.0     96 0.61065007 0.026891012 0.04828974 0.016123102\n11-17   447     5 444.5    147 0.50308602 0.027729151 0.06603774 0.016605169\n17-25   295     3 293.5    107 0.33671112 0.015344161 0.05572917 0.015796965\n25-37   185     0 185.0     73 0.21395783 0.007035550 0.04096521 0.013792960\n37-53   112     0 112.0     85 0.12953123 0.006144059 0.07643885 0.011350812\n53-NA    27     0  27.0     27 0.03122628          NA         NA 0.005907255\n            se.pdf   se.hazard\n0-2   0.0060299154 0.007124861\n2-3   0.0074051486 0.009353268\n3-5   0.0049023311 0.006978078\n5-7   0.0044762921 0.007164162\n7-11  0.0025903363 0.004905511\n11-17 0.0020829076 0.005338742\n17-25 0.0013843547 0.005251978\n25-37 0.0007849941 0.004647529\n37-53 0.0006300324 0.006560105\n53-NA           NA          NA\n\n\nLas columnas de desviaciones estándar de las función de sobrevivencia, tasa de riesgo y función de densidad se calculan según las fórmulas 5.4.5, 5.4.6 y 5.4.7 del Klein.\n\n\n\n\nTsai, Wei-Yann, Nicholas P Jewell, and Mei-Cheng Wang. 1987. “A Note on the Product-Limit Estimator Under Right Censoring and Left Truncation.” Biometrika 74 (4): 883–86."
  },
  {
    "objectID": "PH.html#pruebas-de-hipótesis-de-una-muestra",
    "href": "PH.html#pruebas-de-hipótesis-de-una-muestra",
    "title": "3  Pruebas de Hipótesis",
    "section": "3.1 Pruebas de Hipótesis de una muestra",
    "text": "3.1 Pruebas de Hipótesis de una muestra\nSupongamos una muestra con censura de tamaño \\(n\\). Se quiere probar las siguientes hipótesis:\n\n\\(H_0:\\) La tasa de riesgo de la población es \\(h_0(t)\\) para todo \\(t \\leq \\tau\\).\n\\(H_1:\\) La tasa de riesgo de la población es distinta a \\(h_0(t)\\) para algún \\(t \\leq \\tau\\).\n\nDonde \\(h_0(t)\\) es una tasa de riesgo conocida en \\([0,\\tau]\\) y \\(\\tau\\): máximo de los tiempo de estudio observados.\nConsidere el estimador de Nelson-Aalen de \\(H(t)\\):\n\\[\\hat H(t)=\\sum_{t_i\\leq t}\\frac{d_i}{Y(t_i)}\\] donde \\(d_i:\\) número de eventos en los tiempos observados \\(t_1<t_2<\\cdots < t_D\\) y \\(Y(t_i)\\): número de individuos en riesgo al tiempo \\(t_i\\). Un estimador (muy crudo) de \\(h(t_i)\\) es\n\\[\\frac{d_i}{Y(t_i)}\\]\ny este estadístico nos permite definir un estadístico de prueba que busca comparar las tasas de riesgo observadas y esperadas usado diferencias ponderadas. Sea \\(W(t)\\): función de pesos tal que \\(W(t)=0\\) si \\(Y(t)=0\\). Defina el siguiente estadístico de prueba:\n\\[Z(\\tau)=O(\\tau)-E(\\tau)=\\sum_{i=1}^DW(t_i)\\frac{d_i}{Y(t_i)}-\\int_0^\\tau W(s)h_0(s)ds\\] Bajo \\(H_0\\), la varianza de \\(Z(\\tau)\\) es:\n\\[V[Z(\\tau)]=\\int_0^\\tau W^2(s)\\frac{h_0(s)}{Y(s)}ds\\] Si \\(n\\) es grande:\n\\[\\frac{Z(\\tau)^2}{V[Z(\\tau)]}\\underset{H_0}{\\sim}\\chi_1^2\\] Por lo tanto se rechaza \\(H_0\\) si \\(\\frac{Z(\\tau)^2}{V[Z(\\tau)]}>\\chi_{1,1-\\alpha}^2\\) bajo un nivel de significancia de \\(\\alpha\\).\nSi se quiere probar \\(H_0: h(t)>h_0(t)\\) entonces se rechaza \\(H_0\\) si:\n\\[\\frac{Z(\\tau)}{\\sqrt{V[Z(\\tau)]}}>z_{1-\\alpha}\\] con nivel \\(\\alpha\\). La función de pesos se puede seleccionar de muchas formas, por ejemplo la forma más usual es (Gehan):\n\\[W(t)=Y(t)\\] con lo cual se genera una prueba de rango (Prueba de bondad de ajuste no-paramétrica). Otros casos: (Harrington-Fleming):\n\\[W(t)=Y(t)S_0(t)^p[1-S_0(t)]^q, \\qquad p,q\\geq 0\\] y \\(S_0(t)=\\exp[-H_0(t)]\\).\nEn el caso de truncamiento por la izquierda, sea:\n\n\\(T_j\\): tiempo de ocurrencia del evento en el \\(j\\)-ésimo paciente.\n\\(L_j\\): tiempo de truncamiento por la izquierda en el \\(j\\)-ésimo paciente. Este tiempo se puede interpretar como el momento de entrada en el estudio.\n\nSi se usa la opción \\(W(t)=Y(t)\\), entonces:\n\\[O(\\tau)=\\sum_{i=1}^D d_i\\]\ny\n\\[E(\\tau)=\\int_0^\\tau Y(s)h_0(s)ds = V[Z(\\tau)]=\\sum_{j=1}^n H_0(T_j)-H_0(L_j)\\]"
  },
  {
    "objectID": "PH.html#pruebas-de-hipótesis-para-más-de-una-muestra",
    "href": "PH.html#pruebas-de-hipótesis-para-más-de-una-muestra",
    "title": "3  Pruebas de Hipótesis",
    "section": "3.2 Pruebas de Hipótesis para más de una muestra",
    "text": "3.2 Pruebas de Hipótesis para más de una muestra\nQueremos probar las siguientes alternativas:\n\n\\(H_0: h_1(t)=h_2(t)=\\cdots=h_k(t)\\) para todo \\(t\\leq \\tau\\)\n\\(H_1\\): al menos uno de los \\(h_j(t)\\) es diferente para algún \\(t\\leq \\tau\\).\n\nSea \\(\\tau\\): tiempo máximo en donde todos los grupos tienen al menos un individuo en riesgo. Normalmente \\(\\tau=\\min_k \\{\\max \\{ \\text{tiempos de estudio}\\}\\}\\).\nLos datos en este caso constituyen muestras independientes de datos censurados, truncados por la izquierda para cada una de las \\(k\\) poblaciones. Sea \\(t_1<t_2<\\cdots <t_D\\) los distintos tiempos de ocurrencia del evento de interés en la muestra combinada.\nEn tiempo \\(t_i\\) se observa \\(d_{ij}\\) eventos en la \\(j\\)-ésima muestra con \\(Y_{ij}\\): individuos en riesgo de la población \\(j\\)-ésima (\\(j=1,\\ldots,k\\), \\(i=1,\\ldots,D\\)).\nAdemás:\n\\[d_i=\\sum_{j=1}^k d_{ij}\\qquad \\text{y} \\qquad Y_i=\\sum_{j=1}^k Y_{ij}\\] Si \\(H_0\\) es cierto, un estimador de la tasa de riesgo para la población \\(j\\)-ésima es el estimador combinado:\n\\[\\frac{d_i}{Y_i}\\]\nSi \\(W_j(t_i)\\) denota una función de pesos tal que es cero si \\(Y_{ij}=0\\), entonces defina el estadístico:\n\\[Z_j(\\tau)=\\sum_{j=1}^D W_j(t_i)\\left[\\frac{d_{ij}}{Y_{ij}}-\\frac{d_i}{Y_i}\\right]\\] Interpretación del estadístico \\(Z_j(\\tau)\\): valores altos dan evidencia de que \\(H_0\\) no es cierto.\nEn general, se simplifica la ponderación de \\(Z_j\\) al escoger:\n\\[W_j(t_i)=Y_{ij}W(t_i)\\] en donde \\(W(t_i)\\) es un peso en común para toda la muestra combinada. En este caso la diferencia ponderada quedaría:\n\\[Z_j(\\tau)=\\sum_{i=1}^D W(t_i)\\left[d_{ij}-\\underbrace{Y_{ij}\\left(\\frac{d_i}{Y_i}\\right)}_{**}\\right]\\] donde \\(**\\) es el número de eventos esperados bajo \\(H_0\\). La varianza de \\(Z_j(\\tau)\\) es:\n\\[\\hat \\sigma_{jj}=\\sum_{i=1}^D W(t_i)^2\\frac{Y_{ij}}{Y_i}\\left(1-\\frac{Y_{ij}}{Y_i}\\right)\\left(\\frac{Y_i-d_i}{Y_i-1}\\right)d_i\\] para \\(j=1,\\ldots,k\\). La covarianza entre \\(Z_j(\\tau)\\) y \\(Z_g(\\tau)\\) es:\n\\[\\hat \\sigma_{jg}=-\\sum_{i=1}^D W(t_i)^2\\frac{Y_{ij}}{Y_i}\\frac{Y_{ig}}{Y_i}\\left(\\frac{Y_i-d_i}{Y_i-1}\\right)d_i\\] El término \\(\\frac{Y_i-d_i}{Y_i-1}\\) es igual a 1 si no hay individuos que tengan un tiempo en común de ocurrencia del evento, por lo tanto se puede considerar este término como un factor de correción a la estructura de varianza ante la presencia de múltiples ocurrencias en un mismo tiempo (ties).\nNote que \\((Z_1(\\tau),\\ldots,Z_k(\\tau))\\) cumple que:\n\\[\\sum_{j=1}^k Z_j(\\tau)=0\\]\nSeleccionamos entonces \\(k-1\\) de las poblaciones y sea \\(\\Sigma\\) la matriz de varianza-covarianza con elementos \\(\\hat \\sigma_{jg}\\). Se define el estadístico:\n\\[\\chi^2=(Z_1(\\tau),\\ldots,Z_{k-1}(\\tau))\\Sigma^{-1}(Z_1(\\tau),\\ldots,Z_{k-1}(\\tau))^T\\]\nBajo \\(H_0\\) se tiene que \\(\\chi^2\\sim \\chi_{k-1}^2\\). En el caso en que \\(k=2\\):\n\\[\\begin{align*}\n    Z&=\\frac{\\sum_{i=1}^D W(t_i)\\left[d_{i1}-Y_{i1}\\left(\\frac{d_i}{Y_i}\\right)\\right]}{\\sqrt{\\sum_{i=1}^D W(t_i)^2\\frac{Y_{i1}}{Y_i}\\left(1-\\frac{Y_{i1}}{Y_i}\\right)\\left(\\frac{Y_i-d_i}{Y_i-1}\\right)}}\\\\\n    &\\underset{H_0}{\\sim} N(0,1)\n\\end{align*}\\]\nPor lo tanto se rechaza \\(H_0: h_1(t)=h_2(t)\\) si \\(|Z|>z_{1-\\alpha/2}\\) o se rechaza \\(H_0: h_1(t)>h_2(t)\\) si \\(Z>z_{1-\\alpha}\\).\nEscogencias de \\(W(t)\\):\n1- \\(W(t)=1\\): Prueba de log-rango.\n2- \\(W(t_i)=Y_i\\): similar a la prueba de Wilcoxon-Mann-Whitney.\n3- \\(W(t_i)=Y_i^{1/2}\\) (otorga más peso donde hay más datos).\n4- Considere\n\\[\\tilde S(t)=\\prod_{t_i\\leq t}\\left(1-\\frac{d_i}{Y_i+1}\\right)\\] tome \\(W(t_i)=\\tilde S(t_i)\\) (Peto-Peto, (1972)).\n5- Modificación de Andersen (1982) (Peto-Peto Modificada)\n\\[W(t_i)=\\frac{\\tilde S(t_i)Y_i}{Y_i+1}\\] 6- Fleming and Harrington\nSea \\(\\hat S(t)\\) el estimador de Kaplan-Meier usando la muestra combinada. Defina:\n\\[W_{p,q}(t_i)=\\hat S(t_{i-1})^p[1-\\hat S(t_{i-1})]^q, \\qquad p\\geq 0, q\\geq 0\\]\n2 casos: \\(p=q=0\\) (log-rango) y \\(p=1, q=0\\) (Mann-Whitney-Wilcoxon)"
  },
  {
    "objectID": "PH.html#pruebas-de-tendencia",
    "href": "PH.html#pruebas-de-tendencia",
    "title": "3  Pruebas de Hipótesis",
    "section": "3.3 Pruebas de tendencia",
    "text": "3.3 Pruebas de tendencia\nPrincipal objetivo: detectar alternativas ordenadas a la hipótesis nula:\n\n\\(H_0:h_1(t)=h_2(t)=\\cdots=h_k(t)\\) para todo \\(t\\leq \\tau\\)\n\\(H_1: h_1(t)\\leq h_2(t)\\leq \\cdots\\leq h_k(t)\\) para \\(t\\leq \\tau\\) con al menos una desigualdad estricta.\n\nNote que\n\\[h_1(t)\\leq \\cdots \\leq h_k(t) \\Leftrightarrow S_1(t)\\geq \\cdots \\geq S_k(t)\\] Usando la notación anterior, sea \\(a_1<a_2<\\cdots <a_k\\) una secuencia de scores (usualmente \\(a_j=j\\) o algún estadístico representativo para la población \\(j\\)-ésima):\n\\[Z=\\frac{\\sum_{j=1}^k a_jZ_j(\\tau)}{\\sqrt{\\sum_{j=1}^k \\sum_{g=1}^k a_ja_g\\hat \\sigma_{jg}}}\\underset{H_0}{\\sim} N(0,1)\\]"
  },
  {
    "objectID": "PH.html#pruebas-estratificadas",
    "href": "PH.html#pruebas-estratificadas",
    "title": "3  Pruebas de Hipótesis",
    "section": "3.4 Pruebas estratificadas",
    "text": "3.4 Pruebas estratificadas\nSuponga que se tiene un conjunto de covariables que definen \\(M\\) estados o configuraciones sobre el conjunto de \\(k\\) poblaciones. Se quiere probar:\n\\[H_0: h_{1s}(t)=h_{2s}(t)=\\cdots=h_{ks}(t), \\qquad s=1,\\ldots,M\\qquad t<\\tau\\] Para un estrato \\(s\\) fijo, sea \\(Z_{js}(\\tau)\\):\n\\[Z_{js}(\\tau)=\\sum_{i=1}^DW(t_i)\\left[\\underbrace{d_{ij}-Y_{ij}\\left(\\frac{d_i}{Y_i}\\right)}_{\\text{solamente estrato s}}\\right]\\]\ny \\(\\hat \\Sigma_s\\) es la matriz de varianza-covarianza de \\(Z_{js}\\). La prueba estratificada se construye definiendo:\n\\[Z_{j.}(\\tau)=\\sum_{s=1}^MZ_{js}(\\tau)  \\qquad \\text{y} \\qquad \\hat \\sigma_{jg.}=\\sum_{s=1}^M \\hat \\sigma_{jgs}\\]\ny \\(\\hat \\sigma_{jgs}\\) es la entrada \\(jg\\) del \\(\\hat \\Sigma_s\\). El estadístico de prueba estaría dado por:\n\\[X_.=(Z_{1.}(\\tau),\\ldots,Z_{k-1,.}(\\tau))\\Sigma_.^{-1}(Z_{1.}(\\tau),\\ldots,Z_{k-1,.}(\\tau))^T\\]\ndonde \\(\\Sigma_.\\) es la matriz con entradas \\(\\hat \\sigma_{jg.}\\). Bajo \\(H_0\\):\n\\[X_.\\sim \\chi_{k-1}^2\\]\nEn el caso de dos muestras el estadístico se puede escribir:\n\\[\\frac{\\sum_{s=1}^M Z_{1s}(\\tau)}{\\sqrt{\\sum_{s=1}^M \\hat \\sigma_{11s}}}\\underset{H_0}{\\sim}N(0,1)\\] y este estadístico también permite probar hipótesis de una cola en el caso de dos muestras.\nOtro tipo de prueba basada en pruebas estratificadas es una prueba pareada. Si \\((T_{1i},T_{2i})\\) son pares de eventos de interés con indicadores de eventos \\((\\delta_{1i},\\delta_{2i})\\) para \\(i=1,\\ldots,M\\). Queremos probar las hipótesis:\n\\[H_0: h_{1i}(t)=h_{2i}(t), \\qquad i=1,\\ldots,M\\] (misma interpretación en términos de estratos). En este caso el estadístico \\(Z_{js}\\) es: (\\(j=1,2\\))\n\\[\\begin{align*}\nZ_{1i}(\\tau)=\n    \\begin{cases}\n        W(T_{1i})\\left(1-\\frac 1 2\\right)=\\frac{W(T_{1i})}{2} & \\text{bajo Escenario A}\\\\\n        W(T_{2i})\\left(0-\\frac 1 2\\right)=-\\frac{W(T_{2i})}{2} & \\text{bajo Escenario B}\\\\\n        0 & \\text{otro caso}\n    \\end{cases}\n\\end{align*}\\]\n\nEscenario A: si \\(T_{1i}<T_{2i}\\), \\(\\delta_{1i}=1\\) o \\(T_{1i}=T_{2i}\\), \\(\\delta_{1i}=1\\), \\(\\delta_{2i}=0\\).\nEscenario B: \\(T_{2i}<T_{1i}\\), \\(\\delta_{2i}=1\\) o \\(T_{1i}=T_{2i}\\), \\(\\delta_{2i}=1\\), \\(\\delta_{1i}=0\\).\n\ny\n\\[\\begin{align*}\n\\hat \\sigma_{11i}=\n    \\begin{cases}\n        W(T_{1i})^2/4 & \\text{bajo Escenario A}\\\\\n        W(T_{2i})^2/4 & \\text{bajo Escenario B}\\\\\n        0 & \\text{otro caso}\n    \\end{cases}\n\\end{align*}\\]\nSumando sobre los estratos (\\(i=1,\\ldots,M\\)):\n\\[Z_{1.}(\\tau)=w \\cdot \\frac{D_1-D_2}{2}\\] y\n\\[\\hat \\sigma_{11.}=w^2\\cdot \\frac{D_1+D_2}{4}\\] donde:\n\n\\(D_1\\): número de parejas en donde el evento aparece en el sujeto de la primera muestra.\n\\(D_2\\): número de parejas en donde el evento aparece en el sujeto de la segunda muestra.\n\\(w\\): peso evaluado en el tiempo más pequeño de ocurrencia del evento.\n\nEntonces:\n\\[\\frac{Z_{1.}(\\tau)}{\\sqrt{\\hat \\sigma_{11.}}}=\\frac{D_1-D_2}{\\sqrt{D_1+D_2}}\\underset{H_0}{\\sim}N(0,1)\\]"
  },
  {
    "objectID": "PH.html#pruebas-de-renyi",
    "href": "PH.html#pruebas-de-renyi",
    "title": "3  Pruebas de Hipótesis",
    "section": "3.5 Pruebas de Renyi",
    "text": "3.5 Pruebas de Renyi\nInconveniente de las pruebas anteriores: algunas veces las diferencias en las tasas de riesgo son simétricas (un primer grupo sobrepasa al otro en riesgo un número similar de veces al que el primer grupo es sobrepasado por el otro grupo). Esto provoca problemas de potencia en la prueba. Solución: utilizar otras medidas de comparación.\nSuponga que se tiene dos muestras independientes de tamaño \\(n_1\\) y \\(n_2\\) respectivamente.\nSea \\(n=n_1+n_2\\) y \\(t_1<t_2<\\cdots<t_D\\) los distintos tiempo de ocurrencia en la muestra combinada y \\(Y_{ij}\\): número de individuos en riesgo en tiempo \\(t_i\\) (\\(j=1,2\\)). Al igual que antes \\(Y_i=Y_{i1}+Y_{i2}\\), \\(d_i=d_{i1}+d_{i2}\\) (eventos ocurridos). Sea \\(W(t)\\) la función de pesos (como las consideradas anteriormente). En este caso se calcula:\n\\[Z(t_i)=\\sum_{t_k\\leq t_i}W(t_k)\\left[d_{k1}-Y_{k1}\\left(\\frac{d_k}{Y_k}\\right)\\right]\\qquad i=1,\\ldots,D\\] y\n\\[\\sigma(\\tau)=\\sum_{t_k\\leq \\tau}W(t_k)^2\\left(\\frac{Y_{k1}}{Y_k}\\right)\\left(\\frac{Y_{k2}}{Y_k}\\right)\\left(\\frac{Y_{k}-d_k}{Y_k-1}\\right)d_k\\] donde \\(\\tau\\) es el \\(t_k\\) máximo tal que \\(Y_{k1}, Y_{k2}>0\\).\nBajo la hipótesis:\n\n\\(H_0: h_1(t)=h_2(t),\\qquad t<\\tau\\)\n\\(H_1: h_1(t)\\neq h_2(t)\\)\n\nel estadístico de prueba es:\n\\[Q=\\sup_{t\\leq \\tau}\\frac{|Z(t)|}{\\sigma(\\tau)}\\] cuya distribución bajo \\(H_0\\) se aproxima con la distribución de \\(\\sup_{0\\leq x\\leq 1}|B(x)|\\) donde \\(B\\) es un proceso Browniano estándar."
  },
  {
    "objectID": "PH.html#pruebas-en-un-punto-fijo-en-el-tiempo",
    "href": "PH.html#pruebas-en-un-punto-fijo-en-el-tiempo",
    "title": "3  Pruebas de Hipótesis",
    "section": "3.6 Pruebas en un punto fijo en el tiempo",
    "text": "3.6 Pruebas en un punto fijo en el tiempo\nObjetivo: hacer comparaciones de funciones de sobrevivencia o curvas de incidencia de \\(k\\) poblaciones en un punto fijo en el tiempo \\(t_0\\).\nSea \\(\\Theta^T=(\\theta_1,\\ldots,\\theta_p)\\) un vector de parámetros de dimensión \\(p\\). Definimos un contraste como con conjunto de coeficientes \\(c=(c_1,\\ldots,c_p)\\) que definen una combinación lineal de parámetros \\(\\theta^c=c\\Theta=c_1\\theta_1+\\cdots+c_p\\theta_p\\).\nEjemplo: si \\(p=3\\) y \\(c=(1,-1,0)\\), entonces \\(\\theta^c=\\theta_1-\\theta_2\\). Decir que \\(H_0: \\theta^c=0\\) es equivalente a decir que \\(H_0:\\theta_1=\\theta_2\\).\nSuponga que se tiene \\(q\\) contrastes \\(c_k=(c_{k1},\\ldots,c_{kp})\\) para \\(k=1,\\ldots,q\\) y se tiene que probar las hipótesis:\n\\[H_0: c_k\\Theta=0\\qquad \\forall k\\] Defina la matriz de contrastes:\n\\[\\begin{align*}\nC=\n    \\begin{pmatrix}\n    c_1\\\\\n    \\vdots \\\\\n    c_q\n    \\end{pmatrix}\n\\end{align*}\\]\nSi \\(\\hat \\theta_j\\) es el estimador de \\(\\theta_j\\) con matriz de varianza \\(V\\) (con entradas \\(\\hat V(\\hat \\theta_j,\\hat \\theta_k)\\)) (\\(V\\): varianza). Entonces si se quiere probar:\n\\[H_0: C\\Theta^T=0\\]\nEl estadístico de prueba es:\n\\[X^2=[C\\Theta]^T[CVC^T]^{-1}[C\\Theta]\\underset{H_0}{\\sim}\\chi_q^2\\] Caso particular:\n\n\\(H_0: S_1(t_0)=S_2(t_0)=\\cdots S_k(t_0)\\) vs \\(H_1\\): al menos uno de los \\(S_j(t_0)\\) es distinto.\n\\(H_0: CI_1(t_0)=CI_2(t_0)=\\cdots =CI_k(t_0)\\) vs \\(H_1\\): al menos uno de los \\(CI_j(t_0)\\) es distinto.\n\nSea \\(\\hat \\theta_j\\) el estimador de Kaplan-Meier de \\(S_j(t_0)\\) o la curva de incidencia estimada en \\(t_0\\). Sea\n\\[\\begin{align*}\nC=\n    \\begin{pmatrix}\n      1 & 0 & 0 & \\cdots & 0 & -1 \\\\\n      0 & 1 & 0 & \\cdots & 0 & -1 \\\\\n      \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n      0 & 0 & 0 & \\cdots & 1 & -1\n    \\end{pmatrix}\n\\end{align*}\\]\ny \\(V=\\text{diag}(\\hat V(\\hat \\theta_k(t_0)))\\). Entonces:\n\\[\\begin{align*}\nX^2&=\n    \\begin{pmatrix}\n        \\hat \\theta_1-\\hat \\theta_p\\\\\n        \\vdots\\\\\n        \\hat \\theta_{p-1}-\\hat \\theta_p\n    \\end{pmatrix}^T\n    \\begin{pmatrix}\n        V_1+V_p & V_p & \\cdots & V_p \\\\\n        V_p & V_2+V_p & \\cdots & V_p \\\\\n        \\vdots & \\vdots & \\vdots & \\vdots \\\\\n        V_p & V_p & \\cdots & V_{p-1}+V_p\n    \\end{pmatrix}^{-1}\n    \\begin{pmatrix}\n        \\hat \\theta_1-\\hat \\theta_p\\\\\n        \\vdots\\\\\n        \\hat \\theta_{p-1}-\\hat \\theta_p\n    \\end{pmatrix}\\\\\n    & \\underset{H_0}{\\sim} \\chi_{p-1}^2\n\\end{align*}\\]\nCaso particular (p=2):\nCon la hipótesis nula \\(H_0: S_1(t_0)=S_2(t_0)\\):\n\\[Z=\\frac{\\hat S_1(t_0)-\\hat S_2(t_0)}{\\sqrt{\\hat V(\\hat S_1(t_0))+\\hat V(\\hat S_2(t_0))}}\\underset{H_0}{\\sim}N(0,1)\\] Nota: Si se quiere hacer comparaciones simultáneas (\\(k\\) en total, 2 a 2) se puede usar un factor de corrección de Bonferroni (Ejercicio)."
  },
  {
    "objectID": "PH.html#laboratorio",
    "href": "PH.html#laboratorio",
    "title": "3  Pruebas de Hipótesis",
    "section": "3.7 Laboratorio",
    "text": "3.7 Laboratorio\n\n3.7.1 Prueba de una muestra\nCarga de paquetes básicos:\n\nlibrary(survival)\nlibrary(KMsurv)\nlibrary(survMisc)\nlibrary(tidyverse)\n\nEste cálculo busca replicar el ejemplo 7.1 en donde se compara la mortalidad en una muestra de 26 pacientes psiquiátricos en Iowa con respecto a la mortalidad general de la población del mismo estado en el año 1960. Primero cargamos los datos:\n\ndata(\"psych\")\nhead(psych)\n\n  sex age time death\n1   2  51    1     1\n2   2  58    1     1\n3   2  55    2     1\n4   2  28   22     1\n5   1  21   30     0\n6   1  19   28     1\n\n\ny cargamos la información de la mortalidad de todo Iowa (1:Hombres, 2:Mujeres):\n\nIowa_mort <- read_csv('Iowa_1960.csv')\n\nRows: 60 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): Age, Survival_males, Survival_females\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncolnames(Iowa_mort) <- c('age','1','2')\nhead(Iowa_mort)\n\n# A tibble: 6 × 3\n    age   `1`   `2`\n  <dbl> <dbl> <dbl>\n1    18 0.964 0.974\n2    19 0.962 0.973\n3    20 0.961 0.973\n4    21 0.959 0.972\n5    22 0.957 0.972\n6    23 0.956 0.971\n\n\nDespués de algunos cambios, unimos las dos fuentes de información:\n\nIowa_mort <- Iowa_mort %>%\n  pivot_longer(-age,names_to = 'sex',values_to = 'Survival') %>%\n  mutate(sex=as.numeric(sex))\n\npsych <- psych %>% left_join(Iowa_mort) %>% mutate(age2=age+time)\n\nJoining with `by = join_by(sex, age)`\n\nhead(psych)\n\n  sex age time death Survival age2\n1   2  51    1     1  0.92756   52\n2   2  58    1     1  0.89304   59\n3   2  55    2     1  0.90942   57\n4   2  28   22     1  0.96805   50\n5   1  21   30     0  0.95919   51\n6   1  19   28     1  0.96246   47\n\n\nSe maneja dos distintas situaciones bajo estos datos censurados por la derecha: (1) truncamiento por la izquierda o (2) ningún truncamiento:\n\nattach(psych)\nsurv_7_1 <- Surv(time = age,time2 = age2,event = death,type = 'counting')\nsurv_7_1_b <- Surv(time = age2,event = death)\n\nSi queremos comparar las dos distribuciones sin asumir truncamiento por la izquierda se puede ejecutar:\n\nS_7_1_b <- survdiff(surv_7_1_b~offset(Survival))\nS_7_1_b\n\nCall:\nsurvdiff(formula = surv_7_1_b ~ offset(Survival))\n\n Observed  Expected         Z         p \n 1.40e+01  1.40e+00 -1.06e+01  1.89e-26 \n\n\nEn donde concluimos que la mortalidad de los pacientes es distinta a la resto del estado bajo los niveles de significancia usuales. En el caso de truncamiento por la izquierda, hacemos el cálculo de manera directa:\n\npsych <- psych %>% mutate(H=-log(Survival))\n\nIowa_mort <- Iowa_mort %>% select(age2=age,sex,Survival2=Survival)\n\npsych <- psych %>% left_join(Iowa_mort) %>%\n  mutate(H2=-log(Survival2)) %>%\n  mutate(dif=H2-H)\n\nJoining with `by = join_by(sex, age2)`\n\nOtau <- sum(psych$death)\n\nEtau <- sum(psych$dif)\n\nX2 <- (Otau-Etau)^2/Etau\n\nvalor_p <- pchisq(q = X2,df = 1,lower.tail = F)\nshow(valor_p)\n\n[1] 1.014724e-05\n\ndetach(psych)\n\nPor lo que llegamos a la misma conclusión.\n\n\n3.7.2 Prueba de dos muestras\nEl primer conjunto de datos mide la efectividad de dos técnicas distintas de colocación de catéteres en procedimientos de diálisis en riñones.\n\ndata(\"kidney\")\nhead(kidney)\n\n  time delta type\n1  1.5     1    1\n2  3.5     1    1\n3  4.5     1    1\n4  4.5     1    1\n5  5.5     1    1\n6  8.5     1    1\n\n\nPrimero estimamos las funciones de sobrevivencia según Kaplan-Meier:\n\nattach(kidney)\nlibrary(survminer)\n\nLoading required package: ggpubr\n\n\n\nAttaching package: 'survminer'\n\n\nThe following object is masked from 'package:survival':\n\n    myeloma\n\nsurv_7_2 <- Surv(time,event = delta)\nS_7_2 <- survfit(surv_7_2~type,data = kidney)\nggsurvplot(S_7_2)\n\n\n\n\nY comparamos las tasas de riesgo bajo los dos procedimientos bajo distintas escogencias de funciones de pesos \\(W(t)\\) (log-rank, Peto-Peto y tres posibilidades de escogencia de Fleming-Harrington):\n\nX_7_2_logrank <- survdiff(surv_7_2~type,data = kidney,rho = 0)\nX_7_2_logrank\n\nCall:\nsurvdiff(formula = surv_7_2 ~ type, data = kidney, rho = 0)\n\n        N Observed Expected (O-E)^2/E (O-E)^2/V\ntype=1 43       15       11      1.42      2.53\ntype=2 76       11       15      1.05      2.53\n\n Chisq= 2.5  on 1 degrees of freedom, p= 0.1 \n\nX_7_2_PetoPeto <- survdiff(surv_7_2~type,data = kidney,rho = 1)\nX_7_2_PetoPeto\n\nCall:\nsurvdiff(formula = surv_7_2 ~ type, data = kidney, rho = 1)\n\n        N Observed Expected (O-E)^2/E (O-E)^2/V\ntype=1 43     12.0     9.48     0.686      1.39\ntype=2 76     10.4    12.98     0.501      1.39\n\n Chisq= 1.4  on 1 degrees of freedom, p= 0.2 \n\nlibrary(FHtest) # http://www.bioconductor.org/packages/release/bioc/html/Icens.html\n\nLoading required package: interval\n\n\nLoading required package: perm\n\n\nLoading required package: Icens\n\n\nLoading required package: MLEcens\n\n\nDepends on Icens package available on bioconductor. \nTo install use for example:\ninstall.packages('BiocManager')\nBiocManager::install('Icens')\n\nX_7_2_FH1 <- FHtestrcc(surv_7_2~type,data = kidney,rho = 0,lambda=1)\nX_7_2_FH1\n\n\n    Two-sample test for right-censored data\n\nParameters: rho=0, lambda=1\nDistribution: counting process approach\n\nData: surv_7_2 by type\n\n        N Observed Expected   O-E (O-E)^2/E (O-E)^2/V\ntype=1 43    2.973     1.56  1.41      1.28      9.67\ntype=2 76    0.565     1.98 -1.41      1.01      9.67\n\nStatistic Z= -3.1, p-value= 0.00188\nAlternative hypothesis: survival functions not equal\n\nX_7_2_FH2 <- FHtestrcc(surv_7_2~type,data = kidney,rho = 1,lambda=0)\nX_7_2_FH2\n\n\n    Two-sample test for right-censored data\n\nParameters: rho=1, lambda=0\nDistribution: counting process approach\n\nData: surv_7_2 by type\n\n        N Observed Expected   O-E (O-E)^2/E (O-E)^2/V\ntype=1 43     12.0     9.48  2.55     0.686      1.39\ntype=2 76     10.4    12.98 -2.55     0.501      1.39\n\nStatistic Z= -1.2, p-value= 0.239\nAlternative hypothesis: survival functions not equal\n\nX_7_2_FH3 <- FHtestrcc(surv_7_2~type,data = kidney,rho = 1,lambda=1)\nX_7_2_FH3\n\n\n    Two-sample test for right-censored data\n\nParameters: rho=1, lambda=1\nDistribution: counting process approach\n\nData: surv_7_2 by type\n\n        N Observed Expected   O-E (O-E)^2/E (O-E)^2/V\ntype=1 43     2.21     1.19  1.02     0.875      9.83\ntype=2 76     0.48     1.50 -1.02     0.694      9.83\n\nStatistic Z= -3.1, p-value= 0.00171\nAlternative hypothesis: survival functions not equal\n\ndetach(kidney)\n\nNoten que bajo algunas escogencias de pesos no hay evidencia suficiente para rechazar la igualdad entre tasas de riesgos.\nEl ejemplo 7.3 del Klein busca comparar dos tasas de riesgo bajo un esquema de truncamiento por la izquierda. En este caso se usa los datos de la casa de retiro Channing, que anteriormente habíamos usado para comparar entre hombres y mujeres la sobrevivencia de adultos mayores. Ahora se busca probar \\(H_0:h_F(t)=h_M(t)\\) contra la alternativa de una cola \\(H_A:h_F(t)\\leq h_M(t)\\).\n\ndata(\"channing\")\nhead(channing)\n\n  obs death ageentry  age time gender\n1   1     1     1042 1172  130      2\n2   2     1      921 1040  119      2\n3   3     1      885 1003  118      2\n4   4     1      901 1018  117      2\n5   5     1      808  932  124      2\n6   6     1      915 1004   89      2\n\nattach(channing)\nsurv_7_3 <- Surv(time = ageentry,time2 = age,event = death,type = 'counting')\n\nWarning in Surv(time = ageentry, time2 = age, event = death, type =\n\"counting\"): Stop time must be > start time, NA created\n\nS_7_3 <- coxph(surv_7_3~gender)\nsummary(S_7_3)\n\nCall:\ncoxph(formula = surv_7_3 ~ gender)\n\n  n= 458, number of events= 176 \n   (4 observations deleted due to missingness)\n\n          coef exp(coef) se(coef)      z Pr(>|z|)  \ngender -0.3163    0.7289   0.1731 -1.827   0.0677 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n       exp(coef) exp(-coef) lower .95 upper .95\ngender    0.7289      1.372    0.5191     1.023\n\nConcordance= 0.528  (se = 0.018 )\nLikelihood ratio test= 3.17  on 1 df,   p=0.07\nWald test            = 3.34  on 1 df,   p=0.07\nScore (logrank) test = 3.36  on 1 df,   p=0.07\n\n\nEn este caso el estadístico de prueba corresponde al de la prueba Score (3.36). Como la prueba es de una cola, el valor p se puede calcular directamente:\n\npnorm(sqrt(3.36),lower.tail = F)\n\n[1] 0.03339903\n\ndetach(channing)\n\nLo que da evidencia de que bajo un nivel de confianza en la muestra del 95%, podríamos rechazar la hipótesis de que las dos tasas de riesgo son idénticas a favor de que de las mujeres es mayor a la de los hombres.\nEl ejemplo 7.4 usa los datos de 137 pacientes que iban a someterse a un transplante de médula ósea bajo tres distintas condiciones de leucemia (ALL, AML-low, AML-high). Vamos a comparar la sobrevivencia de los pacientes bajo estos tres grupos de riesgo.\n\ndata(\"bmt\")\nhead(bmt)\n\n  group   t1   t2 d1 d2 d3   ta da  tc dc tp dp z1 z2 z3 z4 z5 z6   z7 z8 z9\n1     1 2081 2081  0  0  0   67  1 121  1 13  1 26 33  1  0  1  1   98  0  1\n2     1 1602 1602  0  0  0 1602  0 139  1 18  1 21 37  1  1  0  0 1720  0  1\n3     1 1496 1496  0  0  0 1496  0 307  1 12  1 26 35  1  1  1  0  127  0  1\n4     1 1462 1462  0  0  0   70  1  95  1 13  1 17 21  0  1  0  0  168  0  1\n5     1 1433 1433  0  0  0 1433  0 236  1 12  1 32 36  1  1  1  1   93  0  1\n6     1 1377 1377  0  0  0 1377  0 123  1 12  1 22 31  1  1  1  1 2187  0  1\n  z10\n1   0\n2   0\n3   0\n4   0\n5   0\n6   0\n\n\nLas funciones de sobrevivencia estimadas se grafican:\n\nS_7_4 <- survfit(Surv(time=t2, event=d3) ~ group, data=bmt)\nggsurvplot(S_7_4)\n\n\n\n\ny probamos la hipótesis de la igualdad de tasas de riesgo entre los tres grupos, usando tres posibilidades de escogencia de parámetros de Fleming-Harrington, y bajo las opciones de log-rank y Gehan:\n\nb1 <- ten(Surv(time=t2, event=d3) ~ group, data=bmt)\npruebas_7_4 <- comp(b1, p=c(1, 0, 1), q=c(0, 1, 1))\n\n             chiSq df pChisq\n1          13.8037  2      6\nn          16.2407  2      1\nsqrtN      15.6529  2      5\nS1         15.7260  2      3\nS2         15.7781  2      2\nFH_p=1_q=0 15.6725  2      4\nFH_p=0_q=1  6.1097  2      8\nFH_p=1_q=1  9.9331  2      7\n$tft\n                     Q         Var        Z pNorm\n1             -10.6695     42.7801 -1.63127     6\nn           -1294.0000 439987.8847 -1.95081     1\nsqrtN        -118.1769   4202.2583 -1.82302     5\nS1             -9.2667     23.2023 -1.92379     3\nS2             -9.1996     22.7588 -1.92839     2\nFH_p=1_q=0     -9.3529     23.6462 -1.92339     4\nFH_p=0_q=1     -1.3166      4.5757 -0.61551     8\nFH_p=1_q=1     -1.0948      1.4957 -0.89516     7\n\n$scores\n[1] 1 2 3\n\n\nNote que en esta versión del paquete survMisc los valores p no son calculados correctamente. Por ejemplo, para el caso de la prueba con pesos de Gehan este se podría calcular como:\n\npchisq(16.2407,df = 2,lower.tail = F)\n\n[1] 0.0002974245\n\n\nPor lo tanto bajo los niveles de confianza usuales se rechaza la hipótesis de que las tres tasas de riesgo son iguales para cualquier \\(t\\)."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referencias",
    "section": "",
    "text": "Klein, John P., and Melvin L. Moeschberger. 2003. Survival analysis : techniques for censored and truncated\ndata. Springer.\n\n\nTsai, Wei-Yann, Nicholas P Jewell, and Mei-Cheng Wang. 1987. “A\nNote on the Product-Limit Estimator Under Right Censoring and Left\nTruncation.” Biometrika 74 (4): 883–86."
  }
]